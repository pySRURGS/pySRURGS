<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>pySRURGS API documentation</title>
<meta name="description" content="pySRURGS - Symbolic Regression by Uniform Random Global Search
Sohrab Towfighi (C) 2019-2020
License: GPL 3.0
https://github.com/pySRURGS/pySRURGS" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pySRURGS</code></h1>
</header>
<section id="section-intro">
<p>pySRURGS - Symbolic Regression by Uniform Random Global Search
Sohrab Towfighi (C) 2019-2020
License: GPL 3.0
<a href="https://github.com/pySRURGS/pySRURGS">https://github.com/pySRURGS/pySRURGS</a></p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#!/usr/bin/env python

&#39;&#39;&#39;
pySRURGS - Symbolic Regression by Uniform Random Global Search
Sohrab Towfighi (C) 2019-2020
License: GPL 3.0
https://github.com/pySRURGS/pySRURGS
&#39;&#39;&#39;

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.style
import multiprocessing as mp
from itertools import repeat
import collections
from sqlitedict import SqliteDict
import tabulate
import datetime
import sympy
from sympy import simplify, sympify, Symbol
import mpmath
import sys
import lmfit
import csv
import time
import pdb
import re
import os
import tqdm
import itertools
import parmap
import pandas
import argparse
import numpy as np
from result_class import Result
from math_funcs import (sympy_Sub, sympy_Div, sin, cos, tan, exp, log, sinh, 
                        cosh, tanh, sum, add, sub, mul, div, pow)
np.seterr(all=&#39;raise&#39;)
matplotlib.style.use(&#39;seaborn-colorblind&#39;)


&#39;&#39;&#39; GLOBALS &#39;&#39;&#39;
BIG_NUM = 1.79769313e+300
NUM_ITERS_LIMIT = (2**32-1)
ERASE_LINE = &#39;\x1b[2K&#39; # erase line command
fitting_param_prefix = &#39;begin_fitting_param_&#39;
fitting_param_suffix = &#39;_end_fitting_param&#39;
variable_prefix = &#39;begin_variable_&#39;
variable_suffix = &#39;_end_variable&#39;
path_to_toy_csv = &#39;./csv/toy_data_for_benchmark_gen.csv&#39;
benchmarks_x_domain = [0, 10]
benchmarks_fit_param_domain = [-10, 10]
benchmarks_dir = &#39;./csv/benchmarks&#39;
benchmarks_summary_tsv = &#39;./benchmarks_summary.tsv&#39;
memoize_funcs = False
randgen = np.random.RandomState()
defaults_dict = {&#39;funcs_arity_one&#39;: None,
                 &#39;funcs_arity_two&#39;: &#39;add,sub,mul,div,pow&#39;,
                 &#39;max_num_fit_params&#39;: 3,
                 &#39;max_permitted_trees&#39;: 1000,
                 &#39;path_to_db&#39;: None,
                 &#39;path_to_weights&#39;: None}
&#39;&#39;&#39; END GLOBALS &#39;&#39;&#39;
                 

def check_validity_suggested_functions(suggested_funcs, arity):
    &#39;&#39;&#39;
    Takes a list of suggested functions to use in the search space and checks
    that they are valid.

    Parameters
    ----------
    suggested_funcs: list
        A list of strings.
        In case of `arity==1`, permitted values are [&#39;sin&#39;,&#39;cos&#39;,&#39;tan&#39;,&#39;exp&#39;,
                                                     &#39;log&#39;,&#39;tanh&#39;,&#39;sinh&#39;,&#39;cosh&#39;,
                                                     None]
        In case of `arity==2`, permitted values are [&#39;add&#39;,&#39;sub&#39;,&#39;mul&#39;,&#39;div&#39;,
                                                     &#39;pow&#39;, None]

    Returns
    -------
    suggested_funcs: list

    Raises
    ------
    Exception, if any of the suggested funcs is not in the permitted list
    &#39;&#39;&#39;
    valid_funcs_arity_1 = [&#39;sin&#39;, &#39;cos&#39;, &#39;tan&#39;, &#39;exp&#39;, &#39;log&#39;, &#39;tanh&#39;, &#39;sinh&#39;, 
                           &#39;cosh&#39;, None]
    valid_funcs_arity_2 = [&#39;add&#39;, &#39;sub&#39;, &#39;mul&#39;, &#39;div&#39;, &#39;pow&#39;, None]
    if arity == 1:
        if suggested_funcs != [&#39;,&#39;]:
            for func in suggested_funcs:
                if func not in valid_funcs_arity_1:
                    msg = &#34;Your suggested function of arity 1: &#34; + func
                    msg += &#34; is not in the list of valid functions&#34;
                    msg += &#34; &#34; + str(valid_funcs_arity_1)
                    raise Exception(msg)
        else:
            suggested_funcs = []
    elif arity == 2:
        for func in suggested_funcs:
            if func not in valid_funcs_arity_2:
                msg = &#34;Your suggested function of arity 2: &#34; + func
                msg += &#34; is not in the list of valid functions&#34;
                msg += &#34; &#34; + str(valid_funcs_arity_2)
                raise Exception(msg)
    return suggested_funcs
                 
if defaults_dict[&#39;funcs_arity_two&#39;] is None:
    default_n_funcs = []
else:
    default_n_funcs = check_validity_suggested_functions(
                                 defaults_dict[&#39;funcs_arity_two&#39;].split(&#39;,&#39;), 2)
if defaults_dict[&#39;funcs_arity_one&#39;] is None:
    default_f_funcs = []
else:
    default_f_funcs = check_validity_suggested_functions(
                                 defaults_dict[&#39;funcs_arity_one&#39;].split(&#39;,&#39;), 1)


def is_csv_valid(filepath):
    try:
        with open(filepath, &#39;r&#39;) as csv_file:               
            dialect = csv.Sniffer().sniff(csv_file.read(1024))
    except Exception as e:
        print(&#34;Error encountering while reading: &#34;, filepath)
        print(e)
        exit(2)


class Dataset(object):
    &#34;&#34;&#34;
    An object used to store the dataset of this symbolic regression
    problem.

    Parameters
    ----------
    path_to_csv_file: string
       Absolute or relative path to the CSV file for the numerical data. The
       rightmost column of the CSV file should be the dependent variable.
       The CSV file should have a header of column names and should NOT
       have a leftmost index column.

    int_max_params: int
        The maximum number of fitting parameters specified in the symbolic
        regression problem. Same as `max_num_fit_params`.

    path_to_weights: string 
        An absolute or relative path to the CSV for weights of the data points 
        in the CSV found in `path_to_csv`. If `None`, will assume all data 
        points are equally weighted.

    Returns
    -------
    self
        A pySRURGS.Dataset object, which houses a variety of attributes 
        including the numerical data, the sympy namespace, the data dict used in 
        evaluating the equation string, etc.
    &#34;&#34;&#34;

    def __init__(self, 
                 path_to_csv_file, 
                 int_max_params=defaults_dict[&#39;max_num_fit_params&#39;], 
                 path_to_weights=None):
        (dataframe, header_labels) = self.load_csv_data(path_to_csv_file)
        if path_to_weights is not None:
            (weights_df, empty_labels) = self.load_csv_data(path_to_weights)
            self._data_weights = weights_df.values
        else: 
            self._data_weights = None
        self._int_max_params = int_max_params
        self._dataframe = dataframe
        self._header_labels = header_labels
        x_data, x_labels, x_properties = self.get_independent_data()
        y_data, y_label, y_properties = self.get_dependent_data()
        self._x_data = x_data
        self._x_labels = x_labels
        self._y_data = y_data
        self._y_label = y_label        
        if np.std(self._y_data) == 0:
            raise Exception(&#34;The data is invalid. All y values are the same.&#34;)
        self._param_names = [make_parameter_name(x) for x in
                             range(0, self._int_max_params)]
        self._data_properties = dict()
        self._data_properties.update(x_properties)
        self._data_properties.update(y_properties)
        self._data_dict = self.get_data_dict()
        self._num_variables = len(self._x_labels)
        self._m_terminals = self._num_variables + int_max_params
        self._terminals_list = (create_parameter_list(int_max_params) +
                                create_variable_list(path_to_csv_file))        

    def make_sympy_namespace(self):
        sympy_namespace = {}
        for variable_name in self._x_labels:
            sympy_namespace[variable_name] = sympy.Symbol(variable_name)
        for param_name in self._param_names:
            sympy_namespace[param_name] = sympy.Symbol(param_name)
        sympy_namespace[&#39;add&#39;] = sympy.Add
        sympy_namespace[&#39;sub&#39;] = sympy_Sub
        sympy_namespace[&#39;mul&#39;] = sympy.Mul
        sympy_namespace[&#39;div&#39;] = sympy_Div
        sympy_namespace[&#39;pow&#39;] = sympy.Pow
        sympy_namespace[&#39;cos&#39;] = sympy.Function(&#39;cos&#39;)
        sympy_namespace[&#39;sin&#39;] = sympy.Function(&#39;sin&#39;)
        sympy_namespace[&#39;tan&#39;] = sympy.Function(&#39;tan&#39;)
        sympy_namespace[&#39;cosh&#39;] = sympy.Function(&#39;cosh&#39;)
        sympy_namespace[&#39;sinh&#39;] = sympy.Function(&#39;sinh&#39;)
        sympy_namespace[&#39;tanh&#39;] = sympy.Function(&#39;tanh&#39;)
        sympy_namespace[&#39;exp&#39;] = sympy.Function(&#39;exp&#39;)
        sympy_namespace[&#39;log&#39;] = sympy.Function(&#39;log&#39;)
        return sympy_namespace

    def load_csv_data(self, path_to_csv):
        dataframe = pandas.read_csv(path_to_csv)
        column_labels = dataframe.keys()
        return (dataframe, column_labels)

    def get_independent_data(self):
        &#39;&#39;&#39;
            Loads all data in self._dataframe except the rightmost column
        &#39;&#39;&#39;
        dataframe = self._dataframe
        header_labels = self._header_labels
        features = dataframe.iloc[:, :-1]
        features = np.array(features)
        labels = header_labels[:-1]
        properties = dict()
        for label in labels:
            properties.update(get_properties(dataframe[label], label))
        return (features, labels, properties)

    def get_dependent_data(self):
        &#39;&#39;&#39;
            Loads only the rightmost column from self._dataframe
        &#39;&#39;&#39;
        dataframe = self._dataframe
        header_labels = self._header_labels
        feature = dataframe.iloc[:, -1]
        feature = np.array(feature)
        label = header_labels[-1]
        properties = get_properties(dataframe[label], label)
        return (feature, label, properties)

    def get_data_dict(self):
        &#39;&#39;&#39;
            Creates a dictionary object which houses the values in the dataset 
            CSV. The variable names in the CSV become keys in this data_dict 
            dictionary.
        &#39;&#39;&#39;
        dataframe = self._dataframe
        data_dict = dict()
        for label in self._header_labels:
            data_dict[label] = np.array(dataframe[label].values).astype(float)
            check_for_nans(data_dict[label])
        return data_dict


class SymbolicRegressionConfig(object):
    &#34;&#34;&#34;
    An object used to store the configuration of this symbolic regression
    problem.

    Parameters
    ----------

    path_to_csv: string
        An absolute or relative path to the dataset CSV file. Usually, this
        file ends in a &#39;.csv&#39; extension.

    path_to_db: string
        An absolute or relative path to where the code can save an output
        database file. Usually, this file ends in a &#39;.db&#39; extension.

    n_functions: list
       A list with elements from the set [&#39;add&#39;,&#39;sub&#39;,&#39;mul&#39;,&#39;div&#39;,&#39;pow&#39;].
       Defines the functions of arity two that are permitted in this symbolic
       regression run. Default: [&#39;add&#39;,&#39;sub&#39;,&#39;mul&#39;,&#39;div&#39;, &#39;pow&#39;]

    f_functions: list
        A list with elements from the set [&#39;cos&#39;,&#39;sin&#39;,&#39;tan&#39;,&#39;cosh&#39;,&#39;sinh&#39;,
        &#39;tanh&#39;,&#39;exp&#39;,&#39;log&#39;]. Defines the functions of arity one that are
        permitted in this symbolic regression run.
        Default: []

    max_num_fit_params: int
        This specifies the length of the fitting parameters vector. Randomly
        generated equations can have up to `max_num_fit_params` independent
        fitting parameters. Default: 3

    max_permitted_trees: int
        This specifies the number of permitted unique binary trees, which
        determine the structure of random equations. pySRURGS will consider
        equations from [0 ... max_permitted_trees] during its search. Increasing
        this value increases the size of the search space. Default: 100

    path_to_weights: string 
        An absolute or relative path to the CSV for weights of the data points 
        in the CSV found in `path_to_csv`. If `None`, will assume all data 
        points are equally weighted.           
    
    Attributes
    ----------
    
    Most are simply the parameters which were passed in. Notably, there is the 
    dataset object, which is not a mere parameter.
    
    self._dataset
        A pySRURGS.Dataset object, which houses a variety of attributes 
        including the numerical data, the sympy namespace, the data dict used in 
        evaluating the equation string, etc.
    
    Returns
    -------
    self
        A pySRURGS.SymbolicRegressionConfig object, with attributes 
        self._path_to_csv, 
        self._path_to_db,
        self._n_functions, 
        self._f_functions, 
        self._max_num_fit_params, 
        self._max_permitted_trees,  
        self._path_to_weights, and 
        self._dataset.
    &#34;&#34;&#34;

    def __init__(self,
                 path_to_csv,
                 path_to_db,
                 n_functions=default_n_funcs,
                 f_functions=default_f_funcs,
                 max_num_fit_params=defaults_dict[&#39;max_num_fit_params&#39;],
                 max_permitted_trees=defaults_dict[&#39;max_permitted_trees&#39;],
                 path_to_weights=None):  
        if path_to_db is None:
            path_to_db = create_db_name(path_to_csv)
        self._n_functions = n_functions
        self._f_functions = f_functions
        self._max_num_fit_params = max_num_fit_params
        self._max_permitted_trees = max_permitted_trees        
        self._path_to_csv = path_to_csv
        self._path_to_db = path_to_db
        is_csv_valid(path_to_csv)
        self._path_to_weights = path_to_weights
        if path_to_weights is not None:
            is_csv_valid(path_to_weights)
        self._dataset = Dataset(path_to_csv, 
                                max_num_fit_params, 
                                path_to_weights)


def memoize(func):
    &#34;&#34;&#34;
    A memoize function that wraps other functions. Improves CPU performance at
    the cost of increased memory requirements.

    Parameters
    ----------
    func : function
        Will memoize the `func` provided `func` is deterministic in its outputs.

    Returns
    -------
    memoized_func: function
        A memoized wrapper around `func`
    &#34;&#34;&#34;
    cache = dict()

    def memoized_func(*args):
        if args in cache and memoize_funcs:
            return cache[args]
        result = func(*args)
        cache[args] = result
        return result
    return memoized_func


def has_nans(X):
    if np.any(np.isnan(X)):
        return True
    else:
        return False


def check_for_nans(X):
    if has_nans(X):
        raise Exception(&#34;Has NaNs&#34;)


def binary(num, pre=&#39;&#39;, length=16, spacer=0):
    &#39;&#39;&#39; 
        formats a number into binary:
        https://stackoverflow.com/a/16926270/3549879 
    &#39;&#39;&#39;
    return &#39;{0}{{:{1}&gt;{2}}}&#39;.format(pre, spacer, length).format(bin(num)[2:])


def make_variable_name(var):
    &#34;&#34;&#34;
    Converts a variable name to pySRURGS safe variable names. Prevents string
    manipulations on variable names from affecting function names.

    Parameters
    ----------
    var : string
        A variable name.

    Returns
    -------
    var_name: string
        `var` wrapped in the pySRURGS variable prefix and suffix.
    &#34;&#34;&#34;
    var_name = variable_prefix + str(var) + variable_suffix
    return var_name


def make_parameter_name(par):
    &#34;&#34;&#34;
    Converts a fitting parameter name to pySRURGS safe parameter name. Prevents
    string manipulations on parameter names from affecting function names.

    Parameters
    ----------
    par : string
        A variable name.

    Returns
    -------
    par_name: string
        `par` wrapped in the pySRURGS parameter prefix and suffix.
    &#34;&#34;&#34;
    par_name = fitting_param_prefix + str(par) + fitting_param_suffix
    return par_name


def remove_variable_tags(equation_string):
    &#34;&#34;&#34;
    Removes the pySRURGS variable prefix/suffix from an equation string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string

    Returns
    -------
    equation_string: string
        `equation_string` with the variable prefix and suffix removed.
    &#34;&#34;&#34;
    equation_string = equation_string.replace(variable_prefix, &#39;&#39;)
    equation_string = equation_string.replace(variable_suffix, &#39;&#39;)
    return equation_string


def remove_parameter_tags(equation_string):
    &#34;&#34;&#34;
    Removes the pySRURGS fitting parameter prefix/suffix from an equation 
    string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string

    Returns
    -------
    equation_string: string
        `equation_string` with the fitting parameter prefix and suffix removed.
    &#34;&#34;&#34;
    equation_string = equation_string.replace(fitting_param_prefix, &#39;&#39;)
    equation_string = equation_string.replace(fitting_param_suffix, &#39;&#39;)
    return equation_string


def remove_tags(equation_string):
    &#34;&#34;&#34;
    Removes the pySRURGS variable and fitting parameter prefix/suffix from an
    equation string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string

    Returns
    -------
    equation_string: string
        `equation_string` with the variable and fitting parameter prefixes and
        suffixes removed.
    &#34;&#34;&#34;
    equation_string = remove_parameter_tags(equation_string)
    equation_string = remove_variable_tags(equation_string)
    return equation_string


def remove_dict_tags(equation_string):
    &#34;&#34;&#34;
    Prior to numerically evaluating an equation string, we replace the variable
    and fitting parameter suffix/prefix with code to access values housed in
    dictionaries. This function removes that dictionary code from the equation
    string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string just prior to being numerically
        evaluated.

    Returns
    -------
    equation_string: string
        `equation_string` without dictionary access formatting.
    &#34;&#34;&#34;
    equation_string = equation_string.replace(&#39;df[&#34;&#39;, &#39;&#39;)
    equation_string = equation_string.replace(&#39;params[&#34;&#39;, &#39;&#39;)
    equation_string = equation_string.replace(&#39;&#34;].value&#39;, &#39;&#39;)
    equation_string = equation_string.replace(&#39;&#34;]&#39;, &#39;&#39;)
    return equation_string


def create_variable_list(m):
    &#34;&#34;&#34;
    Creates a list of all the variable names.

    Parameters
    ----------
    m : string (1) or int (2)
        (1) Absolute or relative path to a CSV file with a header
        (2) The number of independent variables in the dataset

    Returns
    -------
    my_vars: list
        A list with dataset variable names as elements.
    &#34;&#34;&#34;
    if type(m) == str:
        my_vars = pandas.read_csv(m).keys()[:-1].tolist()
        my_vars = [make_variable_name(x) for x in my_vars]
    if type(m) == int:
        my_vars = []
        for i in range(0, m):
            my_vars.append(make_variable_name(&#39;x&#39; + str(i)))
    return my_vars


def create_parameter_list(m):
    &#34;&#34;&#34;
    Creates a list of all the fitting parameter names.

    Parameters
    ----------
    m : int
        The number of fitting parameters in the symbolic regression problem

    Returns
    -------
    my_pars: list
        A list with fitting parameter names as elements.
    &#34;&#34;&#34;
    my_pars = []
    for i in range(0, m):
        my_pars.append(make_parameter_name(&#39;p&#39; + str(i)))
    return my_pars


@memoize
def get_bits(x):
    &#39;&#39;&#39; Gets the odd and even bits of a binary number in string format. Used by
    `get_left_right_bits`.
    &#39;&#39;&#39;
    # Get all even bits of x
    even_bits = x[::2]
    # Get all odd bits of x
    odd_bits = x[1::2]
    return odd_bits, even_bits


@memoize
def get_left_right_bits(my_int):
    &#34;&#34;&#34;
    Converts an integer to binary and returns two integers, representing the odd
    and even bits of its binary value.

    Parameters
    ----------
    my_int : integer

    Returns
    -------
    left_int: int
        An integer corresponding to the decimal representation of the odd bits
        of `my_int`&#39;s binary representation

    right_int: int
        An integer corresponding to the decimal representation of the even bits
        of `my_int`&#39;s binary representation
    &#34;&#34;&#34;
    # splits an integer into its odd and even bits - AKA left and right bits
    int_as_bin = binary(my_int)
    left_bin, right_bin = get_bits(int_as_bin)
    left_int = int(left_bin, 2)
    right_int = int(right_bin, 2)
    return left_int, right_int


def get_properties(dataframe, label):
    &#34;&#34;&#34;
    Returns a dictionary of statistical data around the data found in
    `dataframe[label]`

    Parameters
    ----------
    dataframe : pandas.DataFrame object

    label: a column name within `dataframe`

    Returns
    -------
    properties: dictionary
        A dictionary containing the mean, standard deviation, min, and max of
        the column.
    &#34;&#34;&#34;
    properties = dict()
    properties[label + &#39;_mean&#39;] = dataframe.mean()
    properties[label + &#39;_std&#39;] = dataframe.std()
    properties[label + &#39;_min&#39;] = dataframe.min()
    properties[label + &#39;_max&#39;] = dataframe.max()
    return properties


@memoize
def mempower(a, b):
    &#34;&#34;&#34;
    Same as pow, but able to handle extremely large values, and memoized.

    Parameters
    ----------
    a: int
    b: int

    Returns
    -------
    result: int
        `a ** b`
    &#34;&#34;&#34;
    result = mpmath.power(a, b)
    return result


def get_element_of_cartesian_product(*args, repeat=1, index=0):
    &#34;&#34;&#34;
    Access a specific element of a cartesian product, without needing to iterate
    through the entire product.

    Parameters
    ----------
    args: iterable
        A set of iterables whose cartesian product is being accessed

    repeat: int
        If `args` is only one object, `repeat` specifies the number of times
        to take the cartesian product with itself.

    index: int
        The index of the cartesian product which we want to access

    Returns
    -------
    ith_item: the `index`th element of the cartesian product
    &#34;&#34;&#34;
    pools = [tuple(pool) for pool in args] * repeat
    if len(pools) == 0:
        return []
    len_product = len(pools[0])
    len_pools = len(pools)
    for j in range(1, len_pools):
        len_product = len_product * len(pools[j])
    if index &gt;= len_product:
        raise Exception(&#34;index + 1 is bigger than the length of the product&#34;)
    index_list = []
    for j in range(0, len_pools):
        ith_pool_index = index
        denom = 1
        for k in range(j + 1, len_pools):
            denom = denom * len(pools[k])
        ith_pool_index = ith_pool_index // denom
        if j != 0:
            ith_pool_index = ith_pool_index % len(pools[j])
        index_list.append(ith_pool_index)
    ith_item = []
    for index in range(0, len_pools):
        ith_item.append(pools[index][index_list[index]])
    return ith_item


def simplify_equation_string(eqn_str, dataset):
    &#34;&#34;&#34;
    Simplify a pySRURGS equation string into a more human readable format

    Parameters
    ----------
    eqn_str: string
        pySRURGS equation string

    dataset: pySRURGS.Dataset
        The dataset object used to generate the `eqn_str`

    Returns
    -------
    eqn_str: string
        A simpler, more human readable version of `eqn_str`

    Notes
    -------
    Uses sympy to perform simplification. The dataset object specifies the sympy
    namespace.
    &#34;&#34;&#34;
    dataset._sympy_namespace = dataset.make_sympy_namespace()
    s = sympy.sympify(eqn_str, locals=dataset._sympy_namespace)
    try:
        eqn_str = str(sympy.simplify(s))
    except ValueError:
        pass
    if &#39;zoo&#39; in eqn_str:  # zoo (complex infinity) in sympy
        raise FloatingPointError
    eqn_str = remove_variable_tags(eqn_str)
    eqn_str = remove_parameter_tags(eqn_str)
    return eqn_str


def equation_generator_binary_tree(i, q, r, s, enumerator, SRconfig):
    &#34;&#34;&#34;
    Generates an equation string given the integers that specify an equation
    string in pySRURGS. Use `equation_generator_full_binary_tree` instead when 
    there are no functions of arity one permitted.

    Parameters
    ----------
    i: int
        Specifies the integer representation of the unique binary tree. Must be
        greater than 0.

    q: int
        Specifies the integer representation of the configuration of the
        functions of arity one. Must be greater than 0 and less than the number
        of possible configurations of functions of arity one, `G`: see
        `Enumerator.get_G` for details.

    r: int
        Specifies the integer representation of the configuration of the
        functions of arity two. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `A`: see
        `Enumerator.get_A` for details.

    s: int
        Specifies the integer representation of the configuration of the
        terminals. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `B`: see
        `Enumerator.get_B` for details.

    enumerator: pySRURGS.Enumerator
        The `Enumerator` object for the symbolic regression problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` for the symbolic regression problem

    Returns
    -------
    tree: string
        The equation string, without any simplifications
    &#34;&#34;&#34;
    en = enumerator
    dataset = SRconfig._dataset
    f = len(SRconfig._f_functions)
    n = len(SRconfig._n_functions)    
    m = dataset._m_terminals
    tree = ith_binary_tree(i)
    G = en.get_G(f, i)
    if q &gt;= G and not G == 0:
        raise Exception(&#34;q is an index that must be smaller than G&#34;)
    A = en.get_A(n, i)
    if r &gt;= A:
        raise Exception(&#34;r is an index that must be smaller than A&#34;)
    B = en.get_B(m, i)
    if s &gt;= B:
        raise Exception(&#34;s is an index that must be smaller than B&#34;)
    l_i = en.get_l_i(i)
    k_i = en.get_k_i(i)
    j_i = en.get_j_i(i)
    # of all the possible configurations of arity 1 functions, we pick the
    # configuration at index q
    f_func_config = get_element_of_cartesian_product(SRconfig._f_functions,
                                                     repeat=l_i, index=q)
    # of all the possible configurations of arity 2 functions, we pick the
    # configuration at index r
    n_func_config = get_element_of_cartesian_product(SRconfig._n_functions,
                                                     repeat=k_i, index=r)
    # of all the possible configurations of terminals, we pick the
    # configuration at index s
    term_config = get_element_of_cartesian_product(dataset._terminals_list,
                                                   repeat=j_i, index=s)
    orig_tree = tree
    # the trees are generated in the form [. , .] where . denotes a leaf,
    # and the square brackets indicate a function
    # we do some string replacements here, according to the determined
    # configurations to build the equation as a string
    for z in range(0, len(n_func_config)):
        func = n_func_config[z]
        tree = tree.replace(&#39;[&#39;, func + &#39;(&#39;, 1)
        tree = tree.replace(&#39;]&#39;, &#39;)&#39;, 1)    
    for z in range(0, len(f_func_config)):
        func = f_func_config[z]
        tree = tree.replace(&#39;|&#39;, func + &#39;(&#39;, 1)
        tree = tree.replace(&#39;|&#39;, &#39;)&#39;, 1)
    func_tree = tree
    for z in range(0, len(term_config)):
        term = term_config[z]
        tree = tree.replace(&#39;.&#39;, term, 1)
    return tree


def equation_generator_full_binary_tree(i, r, s, enumerator, SRconfig):
    &#34;&#34;&#34;
    Generates an equation string given the integers that specify an equation
    string in pySRURGS. Use `equation_generator_binary_tree` instead when there 
    are functions of arity one permitted.

    Parameters
    ----------
    i: int
        Specifies the integer representation of the unique binary tree. Must be
        greater than 0.

    r: int
        Specifies the integer representation of the configuration of the
        functions of arity two. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `A`: see
        `Enumerator.get_A` for details.

    s: int
        Specifies the integer representation of the configuration of the
        terminals. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `B`: see
        `Enumerator.get_B` for details.

    enumerator: pySRURGS.EnumeratorFullBinaryTree
        The `EnumeratorFullBinaryTree` object for the symbolic regression 
        problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` for the symbolic regression problem

    Returns
    -------
    tree: string
        The equation string, without any simplifications
    &#34;&#34;&#34;
    en = enumerator
    dataset = SRconfig._dataset
    n = len(SRconfig._n_functions)    
    m = dataset._m_terminals
    tree = ith_full_binary_tree(i)
    A = en.get_A(n, i)
    if r &gt;= A:
        raise Exception(&#34;r is an index that must be smaller than A&#34;)
    B = en.get_B(m, i)
    if s &gt;= B:
        raise Exception(&#34;s is an index that must be smaller than B&#34;)
    k_i = en.get_k_i(i)
    j_i = en.get_j_i(i)
    n_func_config = get_element_of_cartesian_product(SRconfig._n_functions,
                                                     repeat=k_i,
                                                     index=r)
    term_config = get_element_of_cartesian_product(dataset._terminals_list,
                                                   repeat=j_i, index=s)
    orig_tree = tree
    for z in range(0, len(n_func_config)):
        func = n_func_config[z]
        tree = tree.replace(&#39;[&#39;, func + &#39;(&#39;, 1)
        tree = tree.replace(&#39;]&#39;, &#39;)&#39;, 1)
    func_tree = tree
    for z in range(0, len(term_config)):
        term = term_config[z]
        tree = tree.replace(&#39;.&#39;, term, 1)
    return tree


def random_equation_binary_tree(N, cum_weights, enumerator, SRconfig,
                                details=False, i=None):
    &#34;&#34;&#34;
    Generates a random equation string. Generating the random numbers which
    specify the equation, then passes those as arguments to equation_generator.
    Use `random_equation_full_binary_tree` instead when there are no functions 
    of arity one permitted.

    Parameters
    ----------
    N: int
        Specifies the number of unique binary trees permitted in our search. The
        search considers trees mapping from the integer domain [0 ... `N`-1].

    cum_weights: array like
        Specifies the probability that an integer in [0 ... `N`-1] will be
        randomly selected. Should add to 1. pySRURGS gives preference to larger
        values of `N` because they result in more possible equations and we want
        to give each equation uniform probability of selection.

    enumerator: pySRURGS.Enumerator
        The `EnumeratorFullBinaryTree` object for the symbolic regression 
        problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` for the symbolic regression problem

    details: Boolean
        Determines the output type
        
    i: int (default: None)
        If not none, specifies which binary tree to use

    Returns
    -------
    if `details` == False:
        equation_string: string
            A randomly generated pySRURGS equation string
    if `details` == True:
        [equation_string, N, n, f, m, i, q, r, s]
    &#34;&#34;&#34;
    dataset = SRconfig._dataset
    n = len(SRconfig._n_functions) # number of functions of arity 2
    f = len(SRconfig._f_functions) # number of functions of arity 1
    m = dataset._m_terminals # number of different terminals    
    if i is None:
        i = randgen.choice(range(0, N), p=cum_weights)
    q = enumerator.get_q(f, i) # get the q^th configuration of arity 1 functions
    r = enumerator.get_r(n, i) # get the r^th configuration of arity 2 functions
    s = enumerator.get_s(m, i) # get the s^th configuration of terminals
    equation_string = equation_generator_binary_tree(i, q, r, s, enumerator, 
                                                     SRconfig)
    if not details:
        return equation_string
    else:
        result = [equation_string, N, n, f, m, i, q, r, s]
        return result


def random_equation_full_binary_tree(N, cum_weights, enumerator, 
                                     SRconfig, details=False, i=None):
    &#34;&#34;&#34;
    Generates a random equation string. Generating the random numbers which
    specify the equation, then passes those as arguments to equation_generator.
    Use `random_equation_binary_tree` instead when there are functions of arity 
    one permitted.

    Parameters
    ----------
    N: int
        Specifies the number of unique binary trees permitted in our search. The
        search considers trees mapping from the integer domain [0 ... `N`-1].

    cum_weights: array like
        Specifies the probability that an integer in [0 ... `N`-1] will be
        randomly selected. Should add to 1. pySRURGS gives preference to larger
        values of `N` because they result in more possible equations and we want
        to give each equation uniform probability of selection.

    enumerator: pySRURGS.EnumeratorFullBinaryTree
        The `EnumeratorFullBinaryTree` object for the symbolic regression 
        problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` object for the symbolic regression 
        problem

    details: Boolean
        Determines the output type

    i: int (default: None)
        If not none, specifies which full binary tree to use

    Returns
    -------
    if `details` == False:
        equation_string: string
            A randomly generated pySRURGS equation string
    if `details` == True:
        [equation_string, N, n, m, i, q, r, s]
    &#34;&#34;&#34;
    dataset = SRconfig._dataset
    n = len(SRconfig._n_functions) # number of functions of arity 2
    m = dataset._m_terminals # number of different terminals    
    if i is None:
        i = randgen.choice(range(0, N), p=cum_weights)
    r = enumerator.get_r(n, i) # get the r^th configuration of arity 2 functions
    s = enumerator.get_s(m, i) # get the s^th configuration of terminals
    equation_string = equation_generator_full_binary_tree(i, r, s, enumerator, 
                                                          SRconfig)
    if not details:
        return equation_string
    else:
        result = [equation_string, N, n, m, i, r, s]
        return result


class EnumeratorBinaryTree(object):
    &#34;&#34;&#34;
    An object housing methods for enumeration of the symbolic regression
    problem. Use `EnumeratorFullBinaryTree` instead when no functions of arity 
    one permitted.

    Returns
    -------
    self
        A pySRURGS.Enumerator object which houses various methods for the
        enumeration of the problem space.

    Example
    --------

    &gt;&gt;&gt; import pySRURGS
    &gt;&gt;&gt; en = pySRURGS.Enumerator()
    &gt;&gt;&gt; en.get_M(1000, 5, 5, 5)
    &#34;&#34;&#34;

    @memoize
    def get_M(self, N, f, n, m):
        &#34;&#34;&#34;
        Calculate the total number of equations for this symbolic regression
        problem. Use get_M from `EnumeratorFullBinaryTree` instead if the number 
        of functions of arity one permitted is zero.

        Parameters
        ----------
        N: int
            Specifies the number of unique binary trees permitted in our search.
            We consider trees mapping from the integer domain [0 ... `N`-1].


        f: int
            The number of functions of arity one permitted

        n: int
            The number of functions of arity two permitted

        m: int
            The number of terminals in the problem (includes variables and
            fitting parameters)

        Returns
        -------
        M: int (mpfmath format)
            The number of possible equations in this symbolic regression problem
        &#34;&#34;&#34;
        def get_count(i):
            l_i = self.get_l_i(i)
            k_i = self.get_k_i(i)
            j_i = self.get_j_i(i)
            count = mempower(n, k_i) * mempower(m, j_i) * mempower(f, l_i)
            return count
        M = mpmath.nsum(get_count, [0, N - 1])
        return M

    @memoize
    def get_G(self, f, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the functions of arity
        one for the binary tree mapped from the integer `i`.  Use get_G from
        `EnumeratorFullBinaryTree` instead if the number of functions of arity 
        one permitted is zero.

        Parameters
        ----------
        f: int
            The number of functions of arity one permitted

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        G: int (mpfmath format)
            The number of possible configurations of functions of arity one
        &#34;&#34;&#34;
        l = self.get_l_i(i)
        G = mempower(f, l)
        return G

    def get_A(self, n, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the functions of arity
        two for the binary tree mapped from the integer `i`.  Use get_A from
        `EnumeratorFullBinaryTree` instead if the number of functions of arity 
        one permitted is zero.

        Parameters
        ----------
        n: int
            The number of functions of arity two permitted

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        A: int (mpfmath format)
            The number of possible configurations of functions of arity two
        &#34;&#34;&#34;
        k = self.get_k_i(i)
        A = mempower(n, k)
        return A

    @memoize
    def get_B(self, m, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the terminals for the
        binary tree mapped from the integer `i`.  Use get_B from
        `EnumeratorFullBinaryTree` instead if the number of functions of arity 
        one permitted is zero.

        Parameters
        ----------
        m: int
            The number of terminals including variables and fitting parameters

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        B: int (mpfmath format)
            The number of possible configurations of terminals
        &#34;&#34;&#34;
        j = self.get_j_i(i)
        B = mempower(m, j)
        return B

    def get_q(self, f, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `G` - 1, inclusive &#39;&#39;&#39;
        G = self.get_G(f, i)
        try:
            q = randgen.randint(0, G - 1, dtype=np.int64)
        except ValueError as e:
            if G == 1:
                q = 0
            else:
                print(e)
                raise ValueError
        return q

    def get_r(self, n, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `A` - 1, inclusive &#39;&#39;&#39;
        A = self.get_A(n, i)
        try:
            r = randgen.randint(0, A - 1, dtype=np.int64)
        except ValueError as e:
            if A == 1:
                r = 0
            else:
                print(e)
                raise ValueError
        return r

    def get_s(self, m, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `B` - 1, inclusive &#39;&#39;&#39;
        B = self.get_B(m, i)
        try:
            s = randgen.randint(0, B - 1, dtype=np.int64)
        except ValueError as e:
            if B == 1:
                s = 0
            else:
                print(e)
                raise ValueError
        return s

    @memoize
    def get_l_i(self, i):
        &#39;&#39;&#39;
            from `f` functions of arity one, pick `l_i `
            `l_i` is the number of non-leaf nodes of arity one
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            l_i = 0
        elif i == 1:
            l_i = 0
        elif i == 2:
            l_i = 1
        else:
            left_int, right_int = get_left_right_bits(i)
            left_l_i = self.get_l_i(left_int)
            right_l_i = self.get_l_i(right_int)
            l_i = left_l_i + right_l_i + 1
        return l_i

    @memoize
    def get_k_i(self, i):
        &#39;&#39;&#39;
            from `n` functions of arity two, pick `k_i`
            `k_i` is the number of non-leaf nodes
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            k_i = 0
        elif i == 1:
            k_i = 1
        elif i == 2:
            k_i = 0
        else:
            left_int, right_int = get_left_right_bits(i)
            left_k_i = self.get_k_i(left_int)
            right_k_i = self.get_k_i(right_int)
            k_i = left_k_i + right_k_i + 1
        return k_i

    @memoize
    def get_j_i(self, i):
        &#39;&#39;&#39;
            from `m` terminals, pick `j_i`
            `j_i` is the number of leafs in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            j_i = 1
        elif i == 1:
            j_i = 2
        elif i == 2:
            j_i = 1
        else:
            left_int, right_int = get_left_right_bits(i)
            left_j_i = self.get_j_i(left_int)
            right_j_i = self.get_j_i(right_int)
            j_i = left_j_i + right_j_i
        return j_i


class EnumeratorFullBinaryTree(object):
    &#34;&#34;&#34;
    An object housing methods for enumeration of the symbolic regression
    problem. Use `EnumeratorBinaryTree` instead when functions of arity one are permitted.

    Returns
    -------
    Enumerator
        A pySRURGS.EnumeratorFullBinaryTree object which houses various methods for the
        enumeration of the problem space for case where only functions of arity
        two are permitted.

    Example
    --------

    &gt;&gt;&gt; import pySRURGS
    &gt;&gt;&gt; en = pySRURGS.EnumeratorFullBinaryTree()
    &gt;&gt;&gt; en.get_M(1000, 5, 5)
    &#34;&#34;&#34;

    @memoize
    def get_M(self, N, n, m):
        &#34;&#34;&#34;
        Calculate the total number of equations for this symbolic regression
        problem. Use get_M from `EnumeratorBinaryTree` instead if any functions
        of arity one are permitted.

        Parameters
        ----------
        N: int
            Specifies the number of unique binary trees permitted in our search.
            We consider trees mapping from the integer domain [0 ... `N`-1].

        n: int
            The number of functions of arity two permitted

        m: int
            The number of terminals in the problem (includes variables and
            fitting parameters)

        Returns
        -------
        M: int (mpfmath format)
            The number of possible equations in this symbolic regression problem
        &#34;&#34;&#34;
        def get_count(i):
            k_i = self.get_k_i(i)
            j_i = self.get_j_i(i)
            count = mempower(n, k_i) * mempower(m, j_i)
            return count
        M = mpmath.nsum(get_count, [0, N - 1])
        return M

    @memoize
    def get_A(self, n, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the functions of arity
        two for the binary tree mapped from the integer `i`.  Use get_A from
        `EnumeratorBinaryTree` instead if the number of functions of arity one permitted
        is not zero.

        Parameters
        ----------
        n: int
            The number of functions of arity two permitted

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        A: int (mpfmath format)
            The number of possible configurations of functions of arity two
        &#34;&#34;&#34;
        k = self.get_k_i(i)
        A = mempower(n, k)
        return A

    @memoize
    def get_B(self, m, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the terminals for the
        binary tree mapped from the integer `i`.  Use get_B from
        `EnumeratorBinaryTree` instead if the number of functions of arity one permitted
        is not zero.

        Parameters
        ----------
        m: int
            The number of terminals including variables and fitting parameters

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        B: int (mpfmath format)
            The number of possible configurations of terminals
        &#34;&#34;&#34;
        j = self.get_j_i(i)
        B = mempower(m, j)
        return B

    def get_r(self, n, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `A` - 1, inclusive &#39;&#39;&#39;
        A = self.get_A(n, i)
        try:
            r = randgen.randint(0, A - 1, dtype=np.int64)
        except ValueError as e:
            if A == 1:
                r = 0
            else:
                print(e)
                raise ValueError
        return r

    def get_s(self, m, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `B` - 1, inclusive &#39;&#39;&#39;        
        B = self.get_B(m, i)
        try:
            s = randgen.randint(0, B - 1, dtype=np.int64)
        except ValueError as e:
            if B == 1:
                s = 0
            else:
                print(e)
                raise ValueError
        return s

    @memoize
    def get_k_i(self, i):
        &#39;&#39;&#39;
            from `n` functions of arity two, pick `k_i`
            `k_i` is the number of non-leaf nodes
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            k_i = 0
        elif i == 1:
            k_i = 1
        else:
            left_int, right_int = get_left_right_bits(i - 1)
            left_k_i = self.get_k_i(left_int)
            right_k_i = self.get_k_i(right_int)
            k_i = left_k_i + right_k_i + 1
        return k_i

    @memoize
    def get_j_i(self, i):
        &#39;&#39;&#39;
            from `m` terminals, pick `j_i`
            `j_i` is the number of leafs
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            j_i = 1
        elif i == 1:
            j_i = 2
        else:
            left_int, right_int = get_left_right_bits(i - 1)
            left_j_i = self.get_j_i(left_int)
            right_j_i = self.get_j_i(right_int)
            j_i = left_j_i + right_j_i
        return j_i


def create_fitting_parameters(max_params, param_values=None):
    &#34;&#34;&#34;
    Creates the lmfit.Parameters object based on the number of fitting 
    parameters permitted in this symbolic regression problem.

    Parameters
    ----------
    max_params: int
        The maximum number of fitting parameters. Same as `max_num_fit_params`.

    param_values: None OR (numpy.array of length max_params)
        Specifies the values of the fitting parameters. If none, will default
        to an array of ones, which are to be optimized later.

    Returns
    -------
    params: lmfit.Parameters
        Fitting parameter names specified as [&#39;p&#39; + str(integer) for integer
        in range(0, max_params)]
    &#34;&#34;&#34;
    params = lmfit.Parameters()
    for int_param in range(0, max_params):
        param_name = &#39;p&#39; + str(int_param)
        param_init_value = np.float(1)
        params.add(param_name, param_init_value)
    if param_values is not None:
        for int_param in range(0, max_params):
            param_name = &#39;p&#39; + str(int_param)
            params[param_name].value = param_values[int_param]
    return params


def eval_equation(params, function_string, SRconfig, mode=&#39;residual&#39;):
    &#34;&#34;&#34;
    Evaluates the equation numerically.

    Parameters
    ----------
    params: lmfit.Parameters
        The lmfit.parameters object used to optimize fitting parameters

    function_string: string
        The equation string in dictionary code tags in place.
        Use `clean_funcstring` to put in place the dictionary code tags.

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    mode: string
        &#39;residual&#39; or &#39;y_calc&#39;.

    Returns
    -------
    output: array like
        An array of residuals or predicted dependent variable values, depending
        on the value of `mode`.
    &#34;&#34;&#34;
    my_data = SRconfig._dataset
    len_data = len(my_data._y_data)
    df = my_data._data_dict
    pd = params.valuesdict()
    y_label = my_data._y_label
    independent_var_vector = df[y_label]
    # residual = [BIG_NUM] * len(df[y_label])
    if mode == &#39;residual&#39;:
        eval_string = &#39;(&#39; + function_string + &#39;) -  df[&#34;&#39; + y_label + &#39;&#34;]&#39;
        residual = eval(eval_string)
        output = residual
    elif mode == &#39;y_calc&#39;:
        y_value = eval(function_string)
        output = y_value
    elif type(mode) == dict:
        df = mode
        y_value = eval(function_string)
        output = y_value    
    if np.size(output) == 1:
        # if model only has parameters and no data variables, we can have a
        # situation where output is a single constant
        output = np.resize(output, np.size(independent_var_vector))
    return output


def clean_funcstring_params(funcstring):
    &#34;&#34;&#34;
    Replaces the pySRURGS fitting parameter prefix/suffix from an equation
    string with the dictionary codes needed to numerically evaluate the equation
    string.

    Parameters
    ----------
    funcstring : string
        A pySRURGS generated equation string

    Returns
    -------
    funcstring: string
        `funcstring` with the fitting parameters&#39; prefix and suffix replaced
        with the dictionary tags.
    &#34;&#34;&#34;
    funcstring = funcstring.replace(fitting_param_prefix, &#39;params[&#34;&#39;)
    funcstring = funcstring.replace(fitting_param_suffix, &#39;&#34;].value&#39;)
    return funcstring


def clean_funcstring_vars(funcstring):
    &#34;&#34;&#34;
    Replaces the pySRURGS variable prefix/suffix from an equation
    string with the dictionary codes needed to numerically evaluate the equation
    string.

    Parameters
    ----------
    funcstring : string
        A pySRURGS generated equation string

    Returns
    -------
    funcstring: string
        `funcstring` with the variables&#39; prefix and suffix replaced with
        the dictionary tags.
    &#34;&#34;&#34;
    funcstring = funcstring.replace(variable_prefix, &#39;df[&#34;&#39;)
    funcstring = funcstring.replace(variable_suffix, &#39;&#34;]&#39;)
    return funcstring


def clean_funcstring(funcstring):
    &#34;&#34;&#34;
    Replaces the pySRURGS variables&#39; and fitting parameters&#39; prefix/suffix from
    an equation string with the dictionary codes needed to numerically evaluate
    the equation string.

    Parameters
    ----------
    funcstring : string
        A pySRURGS generated equation string

    Returns
    -------
    funcstring: string
        `funcstring` with the variables&#39; and fitting parameters&#39; prefix and
        suffix replaced with the dictionary tags.
    &#34;&#34;&#34;
    funcstring = clean_funcstring_vars(funcstring)
    funcstring = clean_funcstring_params(funcstring)
    return funcstring


def check_goodness_of_fit(individual, params, SRconfig):
    &#34;&#34;&#34;
    Calculates metrics to assess the goodness of fit. Does so by first
    optimizing the fitting parameters.

    Parameters
    ----------
    individual : string (or, alternatively, a DEAP individual object)
        A pySRURGS generated equation string

    params: lmfit.Parameters

    SRconfig: pySRURGS.SymbolicRegressionConfig

    Returns
    -------
    result: tuple
        (sum_of_squared_residuals, sum_of_squared_totals, R2,
         params_dict_to_store, residual)
    &#34;&#34;&#34;
    my_data = SRconfig._dataset
    # If funcstring is a tree, transform to string
    funcstring = str(individual)
    funcstring = clean_funcstring(funcstring)
    # Evaluate the sum of squared difference between the expression
    if len(params) &gt; 0:
        result = lmfit.minimize(eval_equation, params,
                                args=(funcstring, SRconfig),
                                method=&#39;leastsq&#39;, 
                                nan_policy=&#39;propagate&#39;)
        residual = result.residual
        y_calc = eval_equation(result.params, 
                               funcstring, 
                               SRconfig,
                               mode=&#39;y_calc&#39;)
        params_dict_to_store = result.params
    else:
        residual = eval_equation(params, funcstring, SRconfig)
        y_calc = eval_equation(params, funcstring, SRconfig, mode=&#39;y_calc&#39;)
        params_dict_to_store = params
    avg_y_data = np.average(my_data._y_data)
    sum_of_squared_residuals = sum(pow(residual, 2))
    sum_of_squared_totals = sum(pow(y_calc - avg_y_data, 2))
    R2 = 1 - sum_of_squared_residuals / sum_of_squared_totals
    result = (sum_of_squared_residuals,
              sum_of_squared_totals,
              R2,
              params_dict_to_store,
              residual)
    return result


@memoize
def ith_binary_tree(i):
    &#34;&#34;&#34;
    Generates the `i`th binary tree. Use ith_full_binary_tree when no functions
    of arity one are permitted.

    Parameters
    ----------
    i: int
        A non-negative integer which will be used to map to a unique binary tree

    Returns
    -------
    tree: string
        The binary tree represented using [.,.] to represent a full binary tree,
        |.| to represent functions of arity one, and &#39;.&#39; to represent terminals.
    &#34;&#34;&#34;
    if i == 0:
        tree = &#39;.&#39;
    elif i == 1:
        tree = &#39;[., .]&#39;
    elif i == 2:
        tree = &#39;|.|&#39;
    else:
        left_int, right_int = get_left_right_bits(i)
        left = ith_binary_tree(left_int)
        right = ith_binary_tree(right_int)
        tree = &#39;[&#39; + left + &#39;, &#39; + right + &#39;]&#39;
    return tree


@memoize
def ith_full_binary_tree(i):
    &#34;&#34;&#34;
    Generates the `i`th binary tree. Use ith_binary_tree when functions
    of arity one are permitted.

    Parameters
    ----------
    i: int
        A non-negative integer which will be used to map to a unique binary tree

    Returns
    -------
    tree: string
        The binary tree represented using [.,.] to represent a full binary tree,
        and &#39;.&#39; to represent terminals.
    &#34;&#34;&#34;
    if i == 0:
        tree = &#39;.&#39;
    elif i == 1:
        tree = &#39;[., .]&#39;
    else:
        left_int, right_int = get_left_right_bits(i - 1)
        left = ith_full_binary_tree(left_int)
        right = ith_full_binary_tree(right_int)
        tree = &#39;[&#39; + left + &#39;, &#39; + right + &#39;]&#39;
    return tree


@memoize
def get_cum_weights_binary_tree(N, f, n, m, enumerator):
    &#34;&#34;&#34;
    Generates the relative probabilities of selecting the `i`th binary tree.
    Sums to 1. Ensures that each equation has equal probability of selection.
    Gives increasing probability with increasing `i`, because larger values
    of `i` correspond to more complex trees which permit more equations.
    Use `get_cum_weights_full_binary_tree` when functions of arity one are not permitted.

    Parameters
    ----------
    N: int
        Specifies the number of unique binary trees permitted in our search.
        We consider trees mapping from the integer domain [0 ... `N`-1].

    f: int
        The number of functions of arity one permitted

    n: int
        The number of functions of arity two permitted

    m: int
        The number of terminals in the problem (includes variables and
        fitting parameters)

    enumerator: pySRURGS.EnumeratorBinaryTree
        The enumerator of the symbolic regression problem

    Returns
    -------
    cum_weights: numpy.array
        The relative probability of selecting `i` in the range(0,N)
        to ensure that the equations from the corresponding binary trees
        have equal probability of selection
    &#34;&#34;&#34;
    en = enumerator
    weights = [en.get_G(f,i) * en.get_A(n,i) * en.get_B(m, i) for i in 
               range(0, N)]
    cum_weights = np.array(weights) / np.sum(weights)
    cum_weights = cum_weights.astype(np.float64)
    return cum_weights


@memoize
def get_cum_weights_full_binary_tree(N, n, m, enumerator):
    &#34;&#34;&#34;
    Generates the relative probabilities of selecting the `i`th binary tree.
    Sums to 1. Ensures that each equation has equal probability of selection.
    Gives increasing probability with increasing `i`, because larger values
    of `i` correspond to more complex trees which permit more equations.
    Use `get_cum_weights_binary_tree` when functions of arity one are permitted.

    Parameters
    ----------
    N: int
        Specifies the number of unique binary trees permitted in our search.
        We consider trees mapping from the integer domain [0 ... `N`-1].

    n: int
        The number of functions of arity two permitted

    m: int
        The number of terminals in the problem (includes variables and
        fitting parameters)

    enumerator: pySRURGS.EnumeratorFullBinaryTree
        The enumerator of the symbolic regression problem

    Returns
    -------
    cum_weights: numpy.array
        The relative probability of selecting `i` in the range(0,N)
        to ensure that the equations from the corresponding binary trees
        have equal probability of selection
    &#34;&#34;&#34;
    en = enumerator
    weights = [en.get_A(n, i) * en.get_B(m, i) for i in range(0, N)]
    cum_weights = np.array(weights) / np.sum(weights)
    cum_weights = cum_weights.astype(np.float64)
    return cum_weights


class ResultList(object):
    &#34;&#34;&#34;
    Stores multiple results from a pySRURGS run. Typically, is loaded from the
    SqliteDict database file. `self._results` needs to be generated by appending
    `Result` objects to it.

    Returns
    -------
    self: ResultList
    &#34;&#34;&#34;

    def __init__(self):
        self._results = []

    def sort(self):
        &#34;&#34;&#34;
        Sorts the results in the result list by decreasing value of mean squared
        error.
        &#34;&#34;&#34;
        self._results = sorted(self._results, key=lambda x: x._MSE)

    def print(self, y_data, top=5, mode=&#39;succinct&#39;):
        &#34;&#34;&#34;
        Prints the Normalized Mean Squared Error, R^2, Equation (simplified),
        and Parameters values for the top results_dict. Run `self.sort` prior
        to executing `self.print`.

        Parameters
        ----------
        y_data: array like
            The dependent variable&#39;s data from the pySRURGS.Dataset object

        top: int
            The number of results to display. Will be the best models if
            `self.sort` has been run prior to printing.

        mode: string
            &#39;succinct&#39; or &#39;detailed&#39; depending on whether you want to see
            the difficult to read original equation string

        Returns
        -------
        table_string: string
            A table housing the Normalized Mean Squared Error, R^2,
            Equation (simplified), and Parameters values in the
            tabulate package format.
        &#34;&#34;&#34;
        table = []
        header = [&#34;Normalized Mean Squared Error&#34;, &#34;R^2&#34;,
                  &#34;Equation, simplified&#34;, &#34;Parameters&#34;]
        num_eqn = int(np.min((top, len(self._results))))
        for i in range(0, num_eqn):
            row = self._results[i].summarize(mode)
            row[0] = row[0] / np.std(y_data)
            table.append(row)
        table_string = tabulate.tabulate(table, headers=header)
        print(table_string)


def initialize_db(path_to_db):
    &#39;&#39;&#39;
        Initializes the SqliteDict database file with an initial null value
        for the &#39;best_result&#39; key
    &#39;&#39;&#39;
    with SqliteDict(path_to_db, autocommit=True) as results_dict:
        try:
            results_dict[&#39;best_result&#39;]
        except KeyError:
            results_dict[&#39;best_result&#39;] = Result(
                None, None, np.inf, None, None)
    return


def uniform_random_global_search_once(seed, SRconfig):
    &#34;&#34;&#34;
    Runs pySRURGS once against the CSV file

    Parameters
    ----------
    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    seed: int (or None)
        Sets the seed of the pseudorandom number generator. Will make results
        reproducible if not None.

    Returns
    -------
    y_calc: array like
        The predicted values of the dependent variable

    &#34;&#34;&#34;    
    (f, n, m, cum_weights, N, dataset, enumerator, _, _) = setup(SRconfig)
    valid = False
    if seed is not None:
        randgen.seed(seed)
    while valid == False:
        if f == 0:
            eqn_str = random_equation_full_binary_tree(N, cum_weights, 
                                                       enumerator, SRconfig)
        else:
            eqn_str = random_equation_binary_tree(N, cum_weights, enumerator, 
                                                  SRconfig)
        try:
            simple_eqn = simplify_equation_string(eqn_str, dataset)
            path_to_db = SRconfig._path_to_db
            initialize_db(path_to_db)
            params = create_fitting_parameters(dataset._int_max_params)
            (sum_of_squared_residuals, sum_of_squared_totals,
             R2, params_fitted,
             residual) = check_goodness_of_fit(eqn_str, params, SRconfig)
            if np.isnan(R2) or np.isnan(sum_of_squared_totals):
                raise FloatingPointError
            valid = True
        except FloatingPointError:
            pass
    MSE = sum_of_squared_residuals
    result = Result(simple_eqn, eqn_str, MSE, R2, params_fitted)
    return result


def uniform_random_global_search_once_to_queue(seed, SRconfig, queue):
    &#39;&#39;&#39;
        Runs uniform random global search once, then takes the result and puts 
        it in a queue so that it can be committed in a multiprocessing safe 
        fashion
    &#39;&#39;&#39;
    result = uniform_random_global_search_once(seed, SRconfig)
    queue.put(result)    


def uniform_random_global_search_once_to_db(seed, SRconfig):
    &#39;&#39;&#39;
        Runs uniform random global search once, then takes the result and saves 
        it immediately to the database
    &#39;&#39;&#39;
    result = uniform_random_global_search_once(seed, SRconfig)
    path_to_db = SRconfig._path_to_db
    with SqliteDict(SRconfig._path_to_db, autocommit=False) as results_dict:
        simple_eqn = result._simple_equation
        results_dict[simple_eqn] = result
        results_dict.commit()    

def solution_saving_worker(queue, n_items, output_db):
    &#34;&#34;&#34;
        Takes solutions from the queue of evaluated solutions, 
        then saves them to the database.
    &#34;&#34;&#34;
    checkpoint = int(n_items/100) + 1
    with SqliteDict(output_db, autocommit=False) as results_dict:
        for j in range(0, n_items):
            result = queue.get()
            simple_eqn = result._simple_equation
            results_dict[simple_eqn] = result
            if j == checkpoint:
                print(&#39;  Saving results to db: &#39; + str(j/n_items))
                results_dict.commit()
        results_dict.commit()    


def generate_benchmark(benchmark_name, SRconfig):
    &#34;&#34;&#34;
    Generate a random symbolic regression benchmark problem.

    Parameters
    ----------
    benchmark_name: string
        A string that denotes the name of the problem. Typically, an integer
        set as a string will do.

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem.

    Returns
    -------
    None


    Notes
    -----
    Saves a CSV file to: `benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_train.csv&#39;`
    Saves a CSV file to: `benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_test.csv&#39;`
    Saves a human readable text file to:
            `benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_params.txt&#39;`

    `benchmarks_dir` is a global variable typically set to &#39;./benchmarks&#39;
    &#34;&#34;&#34;
    (f, n, m, cum_weights, N, dataset,
     enumerator, n_functions, f_functions) = setup(SRconfig)
    valid = False
    while valid == False:
        print(ERASE_LINE + &#34;Iterating...&#34;, end=&#39;\r&#39;)
        try:
            # specify the equation
            if f == 0:
                eqn_details = random_equation_full_binary_tree(N, cum_weights,
                                             enumerator, SRconfig, details=True)
            else:
                eqn_details = random_equation_binary_tree(N, cum_weights,
                                             enumerator, SRconfig, details=True)
            eqn_original = eqn_details[0]
            eqn_simple = simplify_equation_string(eqn_original, dataset)
            eqn_specifiers = eqn_details[1:]
            # create the fitting parameters values
            fitting_parameters = (randgen.random_sample((5)) - 0.5) * 20
            fit_param_list = create_fitting_parameters(5)
            for i in range(0, 5):
                fit_param_list[&#39;p&#39; + str(i)].value = fitting_parameters[i]
            eqn_original_cleaned = clean_funcstring(eqn_original)
            # create the training dataset
            for zz in range(0, 2):  # 1st iteration, train. 2nd iteration, test.
                sample_dataset = np.zeros((100, 6))
                for j in range(0, 5):
                    sample_dataset[:, j] = randgen.random_sample((100,)) * 10
                dataset._dataframe = pandas.DataFrame(sample_dataset)
                dataset._dataframe.columns = dataset._x_labels.tolist() + \
                    [dataset._y_label]
                dataset._data_dict = dataset.get_data_dict()
                # calculate y for the sample problem
                y_calc = eval_equation(fit_param_list, eqn_original_cleaned,
                                       SRconfig, mode=&#39;y_calc&#39;)
                dataset._dataframe[dataset._y_label] = y_calc
                # save the test and train sets to file
                if zz == 0:
                    path1 = benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_train.csv&#39;
                else:
                    path1 = benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_test.csv&#39;
                dataset._dataframe.to_csv(path1, index=False)
                # test to see that the dataset can be loaded
                dataset_test = Dataset(path1, 5)
                path2 = benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_params.txt&#39;
                # save the problem parameters to a text file
                with open(path2, &#34;w&#34;) as text_file:
                    msg = &#39;Permitted variables: &#39; + \
                        str(dataset._x_labels.tolist()) + &#39;\n&#39;
                    msg += &#39;Permitted fitting parameters: &#39; + \
                        str(list(fit_param_list.keys())) + &#39;\n&#39;
                    msg += &#39;Fitting parameters: &#39;
                    msg += str(np.array(fit_param_list)) + &#39;\n&#39;
                    msg += &#39;Permitted functions: &#39; + \
                        str(f_functions + n_functions) + &#39;\n&#39;
                    msg += &#39;Simplified equation: &#39; + str(eqn_simple) + &#39;\n&#39;
                    eqn_original = remove_variable_tags(eqn_original)
                    eqn_original = remove_parameter_tags(eqn_original)
                    msg += &#39;Raw equation: &#39; + str(eqn_original) + &#39;\n&#39;
                    text_file.write(msg)
            valid = True
            if eqn_simple == &#39;0&#39;:
                valid = False
        except Exception as e:
            print(ERASE_LINE + str(e), end=&#39;\r&#39;)
            valid = False


def setup(SR_config):
    &#34;&#34;&#34;
    Returns the values stored in SR_config for use in the algorithm
        
    Parameters
    ----------

    SR_config: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    Returns
    -------
    result: tuple
        (f, n, m, cum_weights, N, dataset, enumerator, n_funcs, f_funcs)


    Notes
    -----
    f : int
        The number of functions of arity one in the problem

    n: int
        The number of functions of arity two in the problem

    cum_weights: array like
        The relative weight of selecting the binary trees from 0 to N-1, 
        calculated to ensure equal probabilty of selecting each equation.

    N: int
        The number of unique binary trees permitted in the search. Same as
        `max_permitted_trees`.

    dataset: pySRURGS.Dataset
        The dataset object for the problem.

    enumerator: pySRURGS.EnumeratorBinaryTree OR 
                pySRURGS.EnumeratorFullBinaryTree (if `f_funcs` == 0)

    n_funcs: list
        A list of strings of the functions of arity two permitted in this search

    f_funcs: list
        A list of strings of the functions of arity one permitted in this search
    &#34;&#34;&#34;
    # reads the configuration, the csv file, and creates needed objects
    N = SR_config._max_permitted_trees
    n = len(SR_config._n_functions)  # the number of functions of arity 2
    n_funcs = SR_config._n_functions
    f_funcs = SR_config._f_functions
    f = len(SR_config._f_functions)  # the number of functions of arity 1
    num_fit_param = SR_config._max_num_fit_params
    dataset = SR_config._dataset
    m = dataset._m_terminals  # the number of vars + number of fit params
    if f == 0:
        enumerator = EnumeratorFullBinaryTree()
        cum_weights = get_cum_weights_full_binary_tree(N, n, m, enumerator)
    else:
        enumerator = EnumeratorBinaryTree()
        cum_weights = get_cum_weights_binary_tree(N, f, n, m, enumerator)
    return (f, n, m, cum_weights, N, dataset, enumerator, n_funcs, f_funcs)


def create_db_name(path_to_csv, additional_name=None):
    &#39;&#39;&#39;
    Generates a name of a SqliteDict file based on the CSV filename

    Parameters
    ----------
    path_to_csv: string
        An absolute or relative path to the CSV for the problem.

    additional_name: string
        An additional specifier used in generating the database file name

    Returns
    -------
    db_name: string
        A filepath starting with &#39;./db/&#39; and matching with the CSV file name
        with an optional `additional_name` within the file name. Ends in &#39;.db&#39;.
    &#39;&#39;&#39;
    csv_basename = os.path.basename(path_to_csv)
    csv_name = csv_basename[:-4]
    if additional_name is not None:
        db_name = &#39;./db/&#39; + csv_name + additional_name + &#39;.db&#39;
    else:
        db_name = &#39;./db/&#39; + csv_name + &#39;.db&#39;
    return db_name


def get_resultlist(path_to_db):
    &#39;&#39;&#39;
    Loads the ResultList of a previous run of pySRURGS.
    Skips the `best_result` key. 

    Parameters
    ----------
    path_to_db: string
        An absolute or relative path to the SqliteDict database file.

    Returns
    -------
    result_list: pySRURGS.ResultList
        An unsorted ResultList object for the previously run problem
    &#39;&#39;&#39;
    result_list = ResultList()
    with SqliteDict(path_to_db) as results_dict:
        keys = results_dict.keys()        
        for eqn in keys:
            if eqn == &#39;best_result&#39;:
                continue
            result = results_dict[eqn]
            result_list._results.append(result)
    return result_list


def compile_results(SRconfig, print_mode=True):
    &#39;&#39;&#39;
    Reads from the generated SqliteDict file to determine the best stored models

    Parameters
    ----------
    SRconfig: pySRUGS.SymbolicRegressionConfig
        The symbolic regression problem&#39;s configuration object       

    print_mode: Boolean
        If true, prints to screen. If false, does not.

    Returns
    -------
    result_list: pySRURGS.ResultList 
        Compiling all the results found in the `path_to_db` database file
    &#39;&#39;&#39;
    dataset = SRconfig._dataset
    path_to_db = SRconfig._path_to_db
    result_list = get_resultlist(path_to_db)
    result_list.sort()
    if print_mode == True:
        result_list.print(dataset._y_data)
    return result_list


def count_results(path_to_db):
    &#39;&#39;&#39;
    Reads the generated SqliteDict file to determine the number of generated 
    models

    Parameters
    ----------
    path_to_db: string
        An absolute or relative path to the SqliteDict database file.

    Returns
    -------
    n_results: int
        The number of results in the ResultList
    &#39;&#39;&#39;
    result_list = get_resultlist(path_to_db)
    n_results = len(result_list._results)
    return n_results


def plot_results(SRconfig, output_dir=&#39;./image/&#39;):
    &#39;&#39;&#39;
    Reads the generated SqliteDict file to determine the best model,
    then plots it against the raw data. saves the figure to &#39;./image/plot.png&#39;
    and &#39;./image/plot.svg&#39;. Only works for univariate data.

    Parameters
    ----------
    SRconfig: pySRUGS.SymbolicRegressionConfig
        The symbolic regression problem&#39;s configuration object

    Returns
    -------
    None

    Raises
    ------
    Exception, if data is not univariate.

    &#39;&#39;&#39;
    path_to_csv = SRconfig._path_to_csv
    path_to_db = SRconfig._path_to_db
    dataset = SRconfig._dataset
    result_list = get_resultlist(path_to_db)
    result_list.sort()
    best_model = result_list._results[0]
    param_values = best_model._params
    equation_string = best_model._equation
    num_params = len(param_values)
    params_obj = create_fitting_parameters(num_params,
                                           param_values=param_values)
    evaluatable_equation_string = equation_string
    eval_eqn_string = clean_funcstring(equation_string)
    plt.figure(figsize=(3.14, 2))
    if len(dataset._x_labels) == 1:
        data_dict = dict()
        xlabel = dataset._x_labels[0]
        data_dict[xlabel] = np.linspace(np.min(dataset._x_data),
                                        np.max(dataset._x_data))
        y_calc = eval_equation(params_obj, eval_eqn_string, SRconfig, 
                               mode=data_dict)
        plt.plot(data_dict[xlabel], y_calc, &#39;b-&#39;,
                 label=dataset._y_label + &#39; calculated&#39;)
        plt.plot(dataset._x_data, dataset._y_data, &#39;ro&#39;,
                 label=dataset._y_label + &#39; original data&#39;)
        plt.ylabel(dataset._y_label)
        plt.xlabel(dataset._x_labels[0])
    else:
        xlabel = &#39;y_predicted&#39;
        ylabel = &#39;y_observed&#39;
        y_pred = eval_equation(params_obj, eval_eqn_string, SRconfig)
        y_calc = y_pred / dataset._y_data
        plt.plot(dataset._y_data, y_calc, &#39;bo&#39;,
                 label=&#34;Prediction Error&#34;)
        plt.ylabel(ylabel)
        plt.xlabel(xlabel)
    plt.legend()
    plt.tight_layout()
    output_files = [&#39;plot.eps&#39;, &#39;plot.svg&#39;, &#39;plot.png&#39;]
    for img in output_files:
        output_path = os.path.join(output_dir, img)
        if os.path.isfile(output_path):
            os.remove(output_path)   
        plt.savefig(output_path)


def generate_benchmarks_SRconfigs():
    &#39;&#39;&#39;
    Generates two SymbolicRegressionConfig objects for the generation of 100
    randomly generated symbolic regression problems.
    First SRconfig is simpler than the second in that the second permits
    functions of arity one.

    Parameters
    ----------
    None

    Returns
    -------
    result: tuple
      (SR_config1, SR_config2)      
    &#39;&#39;&#39;
    SR_config1 = SymbolicRegressionConfig(path_to_toy_csv, 
                                          None,
                                          n_functions=[&#39;add&#39;, &#39;sub&#39;, &#39;mul&#39;, 
                                                       &#39;div&#39;],
                                          f_functions=[],
                                          max_num_fit_params=5,
                                          max_permitted_trees=200)
    SR_config2 = SymbolicRegressionConfig(path_to_toy_csv, 
                                          None,
                                          n_functions=[&#39;add&#39;, &#39;sub&#39;, &#39;mul&#39;, 
                                                       &#39;div&#39;, &#39;pow&#39;], 
                                          f_functions=[&#39;sin&#39;, &#39;sinh&#39;, &#39;log&#39;], 
                                          max_num_fit_params=5, 
                                          max_permitted_trees=200)
    result = (SR_config1, SR_config2)
    return result


def generate_benchmarks():
    &#39;&#39;&#39;
    Generates 100 randomly generated symbolic regression problems. The first
    twentry problems are simpler than the latter 80, in that the latter 80
    permit functions of arity one in the search space.

    Parameters
    ----------
    None

    Returns
    -------
    None

    Notes
    ------
    Benchmark problems are saved in the `benchmarks_dir` filepath
    `benchmarks_dir` is a global variable.
    &#39;&#39;&#39;
    SR_config1, SR_config2 = generate_benchmarks_SRconfigs()
    # first set is from 0 - 19 inclusive
    for z in range(0, 20):
        print(ERASE_LINE + &#34;Generating benchmark:&#34;, z, &#34;out of:&#34;, 99, end=&#34;\r&#34;)
        generate_benchmark(str(z), SR_config1)
    for z in range(20, 100):
        print(ERASE_LINE + &#34;Generating benchmark:&#34;, z, &#34;out of:&#34;, 99, end=&#34;\r&#34;)
        generate_benchmark(str(z), SR_config2)
    print(&#34;Outputting a summary to &#34;, benchmarks_summary_tsv)
    read_benchmarks()


def read_benchmarks():
    &#39;&#39;&#39;
    Reads the benchmark problems and generates a summary tab separated value 
    file.

    Parameters
    ----------
    None

    Returns
    -------
    None

    Notes
    ------
    Benchmark problems&#39; summary is saved in `benchmarks_summary_tsv` filepath
    `benchmarks_summary_tsv` is a global variable.
    &#39;&#39;&#39;
    with open(benchmarks_summary_tsv, &#39;w&#39;) as benchmarks_file:
        wrtr = csv.writer(benchmarks_file, delimiter=&#39;\t&#39;, lineterminator=&#39;\n&#39;)
        for i in range(0, 100):
            param_file = benchmarks_dir + &#39;/&#39; + str(i) + &#39;_params.txt&#39;
            with open(param_file) as pfile:
                param_file_lines = pfile.readlines()
                for line in param_file_lines:
                    if &#39;Simplified equation:&#39; in line:
                        true_equation = line.replace(
                            &#39;Simplified equation: &#39;, &#39;&#39;).strip()
                        true_equation = true_equation.replace(&#39; &#39;, &#39;&#39;)
                    if &#39;Raw equation:&#39; in line:
                        raw_equation = line.replace(
                            &#39;Raw equation: &#39;, &#39;&#39;).strip()
                        raw_equation = raw_equation.replace(&#39;&#34;&#39;, &#39;&#39;)
                        raw_equation = raw_equation.replace(&#39; &#39;, &#39;&#39;)
                row = [i, true_equation, raw_equation]
                wrtr.writerow(row)


def count_number_equations(SRconfig):
    &#39;&#39;&#39;
    Counts the number of possible equations in this problem. A wrapper function
    around EnumeratorBinaryTree.get_M / EnumeratorFullBinaryTree.get_M.

    Parameters
    ----------
    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression problem configuration object

    Returns
    -------
    number_possible_equations: int
    &#39;&#39;&#39;
    (f, n, m, cum_weights, N, dataset, enumerator, _, _) = setup(SRconfig)
    if f == 0:
        number_possible_equations = enumerator.get_M(N, n, m)
    else:
        number_possible_equations = enumerator.get_M(N, f, n, m)
    return number_possible_equations


def exhaustive_search(SRconfig, queue=None):
    &#39;&#39;&#39;
    Runs a brute-force/exhaustive symbolic regression search against the CSV
    file. WARNING, unless you specify a very simple problem, this computation
    will indefinitely. Consider using the `count_number_equations` function
    to first determine how many equations you will be considering.

    Parameters
    ----------
    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    queue: multiprocessing.Manager.Queue OR None
        If exists, will treat as multiprocessing, if None, will treat as 
        single core processing

    Returns
    -------
    None
    
    # TODO 
    for the case of i == 0, the number of operator/function configurations 
    will be zero, so this exhaustive search will skip that case. Fix this in 
    the future.
    
    &#39;&#39;&#39;
    warning_string = &#34;&#34;&#34;
    WARNING: you are running an exhaustive search on a large search space.
    Are you sure you want to do this?!
    &#34;&#34;&#34;
    path_to_db = SRconfig._path_to_db
    path_to_csv = SRconfig._path_to_csv
    path_to_weights = SRconfig._path_to_weights
    num_equations = count_number_equations(SRconfig)
    print(&#34;Number of equations: &#34;, num_equations)
    if num_equations &gt; 50000:
        print(warning_string)        
        print(&#34;Waiting 10 seconds for user to break with ctrl-c, otherwise will run.&#34;)
        time.sleep(10)
    if ((&#39;add&#39; not in SRconfig._n_functions and
         &#39;sub&#39; not in SRconfig._n_functions) or
            SRconfig._max_num_fit_params == 0):
        msg = &#34;Exhaustive search needs `add` or `sub` and &gt;=1 fit parameter to be truly exhaustive&#34;
        raise Exception(msg)
    (f, n, m, _, N, dataset, enumerator, _, _) = setup(SRconfig)
    initialize_db(path_to_db)
    # we need to have two streams here, the first for the case where there are
    # functions of arity one permitted, the second for the case where there are
    # no functions of arity one permitted. Within each stream, we need to have
    # a substream for single processing and a substream for multiprocessing
    results = ResultList()
    if f &gt; 0:  # functions of arity one present
        for i in range(0, N):
            G = int(enumerator.get_G(f, i))
            A = int(enumerator.get_A(n, i))
            B = int(enumerator.get_B(m, i))
            if queue is None:  # single processor substream
                for r in range(0, A):
                    for s in range(0, B):
                        for q in range(0, G):
                            index_tuple = (q, r, s)
                            print(&#34;i:&#34;, i, &#34;q:&#34;, q, &#34;r:&#34;, r, &#34;s:&#34;, s, end=&#39;\r&#39;)
                            check_equation_at_specified_indices_to_db(
                                                                index_tuple, i,                                                                
                                                                SRconfig)
            else:  # multiprocessing substream
                iterator = itertools.product(range(0, G), range(0, A), range(
                                                                          0, B))
                iterator = list(iterator)
                num_solns = len(iterator)
                runner = mp.Process(target=solution_saving_worker, 
                                           args=(queue, num_solns, path_to_db))
                runner.start()
                parmap.map(check_equation_at_specified_indices_to_queue,
                           iterator, i, SRconfig, queue, pm_pbar=True)
                runner.join()
    elif f == 0:  # functions of arity one absent
        for i in range(0, N):
            A = int(enumerator.get_A(n, i))
            B = int(enumerator.get_B(m, i))
            if queue is None:  # single processor substream
                for r in range(0, A):
                    for s in range(0, B):
                        index_tuple = (r, s)
                        print(&#34;i:&#34;, i, &#34;r:&#34;, r, &#34;s:&#34;, s, 
                              end=&#39;\r&#39;)
                        check_equation_at_specified_indices_to_db(
                                                            index_tuple, i,
                                                            SRconfig)
            else:  # multiprocessing substream
                iterator = itertools.product(range(0, A), range(0, B))
                iterator = list(iterator)
                num_solns = len(iterator)
                runner = mp.Process(target=solution_saving_worker, 
                           args=(queue, num_solns, path_to_db))
                runner.start()
                parmap.map(check_equation_at_specified_indices_to_queue,
                           iterator, i, SRconfig, queue, pm_pbar=True)
                runner.join()


def check_equation_at_specified_indices(index_tuple, i, SRconfig):
    &#39;&#39;&#39;
    The indices specified gets mapped into the pySRURGS enumeration scheme and
    the corresponding equation gets evaluated against the dataset.

    Parameters
    ----------
    index_tuple: tuple housing (q,r,s) or (r,s) if there are zero functions
                 of arity one

        q: int
            the index specifying which configuration of functions of arity one
            to use within [0, G-1]

        r: int
            the index specifying which configuration of functions of arity two
            to use within [0, A-1]

        s: int
            the index specifying which configuration of terminals to use within
            [0, B-1]

    i: int
        the index specifying which binary tree to consider within [0, N-1]

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    Returns
    -------
    result: pySRURGS.Result or None (if floating point error)
    &#39;&#39;&#39;
    path_to_csv = SRconfig._path_to_csv
    path_to_db = SRconfig._path_to_db
    (f, n, m, _, N, dataset, enumerator, _, _) = setup(SRconfig)
    if len(index_tuple) == 3:
        q, r, s = index_tuple
    elif len(index_tuple) == 2:
        r, s = index_tuple
    else:
        raise Exception(&#34;Invalid length to index_tuple&#34;)
    if f &gt; 0:
        eqn_str = equation_generator_binary_tree(i, q, r, s, enumerator, 
                                                 SRconfig)
    else:
        eqn_str = equation_generator_full_binary_tree(i, r, s, enumerator, 
                                                      SRconfig)
    try:
        try:
            simple_eqn = simplify_equation_string(eqn_str, dataset)
        except BaseException:
            pdb.set_trace()
        initialize_db(path_to_db)
        params = create_fitting_parameters(dataset._int_max_params)
        (sum_of_squared_residuals, sum_of_squared_totals,
         R2, params_fitted,
         residual) = check_goodness_of_fit(eqn_str, params, SRconfig)
        if np.isnan(R2) or np.isnan(sum_of_squared_totals):
            raise FloatingPointError
        valid = True
    except FloatingPointError:
        return None
    MSE = sum_of_squared_residuals
    result = Result(simple_eqn, eqn_str, MSE, R2, params_fitted)
    return result


def check_equation_at_specified_indices_to_queue(index_tuple, i, SRconfig, 
                                                 queue):
    &#39;&#39;&#39;
        runs check_equation_at_specified_indices then puts the result in a 
        queue for later push to the database
    &#39;&#39;&#39;
    result = check_equation_at_specified_indices(index_tuple, i, SRconfig)
    queue.put(result)
    

def check_equation_at_specified_indices_to_db(index_tuple, i, SRconfig):
    &#39;&#39;&#39;
        runs check_equation_at_specified_indices then puts the result in a 
        queue for later push to the database
    &#39;&#39;&#39;
    result = check_equation_at_specified_indices(index_tuple, i, SRconfig)
    with SqliteDict(SRconfig._path_to_db, autocommit=False) as results_dict:
        simple_eqn = result._simple_equation
        results_dict[simple_eqn] = result
        results_dict.commit()    


if __name__ == &#39;__main__&#39;:
    # Read the doc string at the top of this script.
    # Run this script in terminal with &#39;-h&#39; as an argument.
    parser = argparse.ArgumentParser(
        prog=&#39;pySRURGS.py&#39;,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument(
        &#34;train&#34;,
        help=&#34;absolute or relative file path to the csv file housing the training data. The rightmost column of the CSV file should be the dependent variable.&#34;)
    parser.add_argument(
        &#34;iters&#34;,
        help=&#34;the number of equations to be attempted in this run&#34;,
        type=int)
    # TODO parser.add_argument(&#34;-test&#34;, help=&#34;absolute or relative file path
    # to the csv file housing the testing data&#34;)
    parser.add_argument(
        &#34;-memoize_funcs&#34;,
        help=&#34;memoize the computations. If you are running large `iters` and you do not have massive ram, do not use this option.&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-single&#34;,
        help=&#34;run in single processing mode&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-count&#34;,
        help=&#34;Instead of doing symbolic regression, just count out how many possible equations for this configuration. No other processing performed.&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-benchmarks&#34;,
        help=&#34;Instead of doing symbolic regression, generate the 100 benchmark problems. No other processing performed.&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-deterministic&#34;,
        help=&#34;If set, the pseudorandom number generator will act in a predictable manner and pySRURGS will produce reproducible results.&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-plotting&#34;,
        help=&#34;plot the best model against the data to ./image/plot.png and ./image/plot.svg - note only works for univariate datasets&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-exhaustive&#34;,
        help=&#34;instead of running pure random search, do an exhaustive search. Be careful about running this as it may run forever. `iters` gets ignored.&#34;,
        action=&#34;store_true&#34;)
    parser.add_argument(
        &#34;-funcs_arity_two&#34;,
        help=&#34;a comma separated string listing the functions of arity two you want to be considered. Permitted:add,sub,mul,div,pow&#34;,
        default=defaults_dict[&#39;funcs_arity_two&#39;])
    parser.add_argument(
        &#34;-funcs_arity_one&#34;,
        help=&#34;a comma separated string listing the functions of arity one you want to be considered. Permitted:sin,cos,tan,exp,log,sinh,cosh,tanh&#34;)
    parser.add_argument(
        &#34;-max_num_fit_params&#34;,
        help=&#34;the maximum number of fitting parameters permitted in the generated models&#34;,
        default=defaults_dict[&#39;max_num_fit_params&#39;],
        type=int)
    parser.add_argument(
        &#34;-max_permitted_trees&#34;,
        help=&#34;the number of unique binary trees that are permitted in the generated models - binary trees define the form of the equation, increasing this number tends to increase the complexity of generated equations&#34;,
        default=defaults_dict[&#39;max_permitted_trees&#39;],
        type=int)
    parser.add_argument(
        &#34;-path_to_db&#34;,
        help=&#34;the absolute or relative path to the database file where we will save results. If not set, will save database file to ./db directory with same name as the csv file.&#34;,
        default=defaults_dict[&#39;path_to_db&#39;])
    parser.add_argument(
        &#34;-path_to_weights&#34;,
        help=&#34;the absolute or relative path to the CSV file where we store the weights for each point in the dataset. The CSV file should be a single column of non-negative numerical data without a header. If not set, weights are equal to one for all data points.&#34;,
        default=defaults_dict[&#39;path_to_weights&#39;])
    if len(sys.argv) &lt; 2:
        parser.print_usage()
        sys.exit(1)
    arguments = parser.parse_args()
    single_processing_mode = arguments.single
    path_to_csv = arguments.train
    max_attempts = arguments.iters
    count_M = arguments.count
    deterministic = arguments.deterministic
    if deterministic:
        randgen.seed(0)
    benchmarks = arguments.benchmarks
    exhaustive = arguments.exhaustive
    path_to_db = arguments.path_to_db
    path_to_weights = arguments.path_to_weights
    n_funcs = arguments.funcs_arity_two
    n_funcs = n_funcs.split(&#39;,&#39;)
    n_funcs = check_validity_suggested_functions(n_funcs, 2)
    f_funcs = arguments.funcs_arity_one
    if f_funcs is None or f_funcs == &#39;&#39;:
        f_funcs = []
    else:
        f_funcs = f_funcs.split(&#39;,&#39;)
        f_funcs = check_validity_suggested_functions(f_funcs, 1)
    plotting = arguments.plotting
    memoize_funcs = arguments.memoize_funcs
    max_num_fit_params = arguments.max_num_fit_params
    max_permitted_trees = arguments.max_permitted_trees
    SRconfig = SymbolicRegressionConfig(path_to_csv, 
                                        path_to_db, 
                                        n_funcs, 
                                        f_funcs, 
                                        max_num_fit_params, 
                                        max_permitted_trees, 
                                        path_to_weights)
    num_flags = np.sum([exhaustive, count_M, benchmarks])
    if num_flags &gt; 1:
        msg = &#34;You are only permitted to have one of these options:&#34;
        msg += &#39;[exhaustive, count_M, benchmarks]; &#39;
        msg += &#39;you have &#39; + str(num_flags) + &#34; of them&#34;
        raise Exception(msg)
    if benchmarks:
        generate_benchmarks()
        exit(0)
    if count_M:
        count_number_equations(path_to_csv, SRconfig)
        exit(0)
    os.makedirs(&#39;./db&#39;, exist_ok=True)
    manager = mp.Manager()
    queue = manager.Queue()
    if exhaustive == True:
        if not single_processing_mode:
            print(&#34;Running exhaustive search in multi processor mode&#34;)
            exhaustive_search(SRconfig, queue)
        elif single_processing_mode:
            print(&#34;Running exhaustive search in single processor mode&#34;)
            exhaustive_search(SRconfig)
        else:
            raise(&#34;Invalid mode&#34;)
    else:
        if not single_processing_mode:
            print(&#34;Running in multi processor mode&#34;)
            if max_attempts &gt; NUM_ITERS_LIMIT:
                msg = &#34;Multiprocessing mode cannot accommodate more than &#34;
                msg += &#34;NUM_ITERS_LIMIT iterations&#34;
                raise Exception(msg)
            if deterministic:
                seed_list = list(range(0, max_attempts))
            else:
                current_time = int(time.time())
                seeds = np.arange(0, max_attempts)
                seeds = seeds*current_time % NUM_ITERS_LIMIT                
                seed_list = seeds.tolist()
            runner = mp.Process(target=solution_saving_worker, 
                                       args=(queue, max_attempts, path_to_db))
            runner.start()
            results = parmap.map(uniform_random_global_search_once_to_queue,
                                 seed_list,
                                 SRconfig,
                                 queue,
                                 pm_pbar=True)
            runner.join()
        elif single_processing_mode:
            print(&#34;Running in single processor mode&#34;)
            for i in tqdm.tqdm(range(0, max_attempts)):
                uniform_random_global_search_once_to_db(None,
                                                        SRconfig)
        else:
            raise(&#34;Invalid mode&#34;)
    compile_results(SRconfig)
    if plotting:
        plot_results(SRconfig)</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="pySRURGS.defaults_dict"><code class="name">var <span class="ident">defaults_dict</span></code></dt>
<dd>
<section class="desc"><p>END GLOBALS</p></section>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pySRURGS.binary"><code class="name flex">
<span>def <span class="ident">binary</span></span>(<span>num, pre='', length=16, spacer=0)</span>
</code></dt>
<dd>
<section class="desc"><p>formats a number into binary:
<a href="https://stackoverflow.com/a/16926270/3549879">https://stackoverflow.com/a/16926270/3549879</a></p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def binary(num, pre=&#39;&#39;, length=16, spacer=0):
    &#39;&#39;&#39; 
        formats a number into binary:
        https://stackoverflow.com/a/16926270/3549879 
    &#39;&#39;&#39;
    return &#39;{0}{{:{1}&gt;{2}}}&#39;.format(pre, spacer, length).format(bin(num)[2:])</code></pre>
</details>
</dd>
<dt id="pySRURGS.check_equation_at_specified_indices"><code class="name flex">
<span>def <span class="ident">check_equation_at_specified_indices</span></span>(<span>index_tuple, i, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>The indices specified gets mapped into the pySRURGS enumeration scheme and
the corresponding equation gets evaluated against the dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>index_tuple</code></strong> :&ensp;<code>tuple</code> <code>housing</code> (<code>q</code>,<code>r</code>,<code>s</code>) or (<code>r</code>,<code>s</code>) <code>if</code> <code>there</code> <code>are</code> <code>zero</code> <code>functions</code></dt>
<dd>
<p>of arity one</p>
<p>q: int
the index specifying which configuration of functions of arity one
to use within [0, G-1]</p>
<p>r: int
the index specifying which configuration of functions of arity two
to use within [0, A-1]</p>
<p>s: int
the index specifying which configuration of terminals to use within
[0, B-1]</p>
</dd>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code></dt>
<dd>the index specifying which binary tree to consider within [0, N-1]</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression configuration object for this problem</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>pySRURGS.Result</code> or <code>None</code> (<code>if</code> <code>floating</code> <code>point</code> <code>error</code>)</dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_equation_at_specified_indices(index_tuple, i, SRconfig):
    &#39;&#39;&#39;
    The indices specified gets mapped into the pySRURGS enumeration scheme and
    the corresponding equation gets evaluated against the dataset.

    Parameters
    ----------
    index_tuple: tuple housing (q,r,s) or (r,s) if there are zero functions
                 of arity one

        q: int
            the index specifying which configuration of functions of arity one
            to use within [0, G-1]

        r: int
            the index specifying which configuration of functions of arity two
            to use within [0, A-1]

        s: int
            the index specifying which configuration of terminals to use within
            [0, B-1]

    i: int
        the index specifying which binary tree to consider within [0, N-1]

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    Returns
    -------
    result: pySRURGS.Result or None (if floating point error)
    &#39;&#39;&#39;
    path_to_csv = SRconfig._path_to_csv
    path_to_db = SRconfig._path_to_db
    (f, n, m, _, N, dataset, enumerator, _, _) = setup(SRconfig)
    if len(index_tuple) == 3:
        q, r, s = index_tuple
    elif len(index_tuple) == 2:
        r, s = index_tuple
    else:
        raise Exception(&#34;Invalid length to index_tuple&#34;)
    if f &gt; 0:
        eqn_str = equation_generator_binary_tree(i, q, r, s, enumerator, 
                                                 SRconfig)
    else:
        eqn_str = equation_generator_full_binary_tree(i, r, s, enumerator, 
                                                      SRconfig)
    try:
        try:
            simple_eqn = simplify_equation_string(eqn_str, dataset)
        except BaseException:
            pdb.set_trace()
        initialize_db(path_to_db)
        params = create_fitting_parameters(dataset._int_max_params)
        (sum_of_squared_residuals, sum_of_squared_totals,
         R2, params_fitted,
         residual) = check_goodness_of_fit(eqn_str, params, SRconfig)
        if np.isnan(R2) or np.isnan(sum_of_squared_totals):
            raise FloatingPointError
        valid = True
    except FloatingPointError:
        return None
    MSE = sum_of_squared_residuals
    result = Result(simple_eqn, eqn_str, MSE, R2, params_fitted)
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.check_equation_at_specified_indices_to_db"><code class="name flex">
<span>def <span class="ident">check_equation_at_specified_indices_to_db</span></span>(<span>index_tuple, i, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>runs check_equation_at_specified_indices then puts the result in a
queue for later push to the database</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_equation_at_specified_indices_to_db(index_tuple, i, SRconfig):
    &#39;&#39;&#39;
        runs check_equation_at_specified_indices then puts the result in a 
        queue for later push to the database
    &#39;&#39;&#39;
    result = check_equation_at_specified_indices(index_tuple, i, SRconfig)
    with SqliteDict(SRconfig._path_to_db, autocommit=False) as results_dict:
        simple_eqn = result._simple_equation
        results_dict[simple_eqn] = result
        results_dict.commit()    </code></pre>
</details>
</dd>
<dt id="pySRURGS.check_equation_at_specified_indices_to_queue"><code class="name flex">
<span>def <span class="ident">check_equation_at_specified_indices_to_queue</span></span>(<span>index_tuple, i, SRconfig, queue)</span>
</code></dt>
<dd>
<section class="desc"><p>runs check_equation_at_specified_indices then puts the result in a
queue for later push to the database</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_equation_at_specified_indices_to_queue(index_tuple, i, SRconfig, 
                                                 queue):
    &#39;&#39;&#39;
        runs check_equation_at_specified_indices then puts the result in a 
        queue for later push to the database
    &#39;&#39;&#39;
    result = check_equation_at_specified_indices(index_tuple, i, SRconfig)
    queue.put(result)</code></pre>
</details>
</dd>
<dt id="pySRURGS.check_for_nans"><code class="name flex">
<span>def <span class="ident">check_for_nans</span></span>(<span>X)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_for_nans(X):
    if has_nans(X):
        raise Exception(&#34;Has NaNs&#34;)</code></pre>
</details>
</dd>
<dt id="pySRURGS.check_goodness_of_fit"><code class="name flex">
<span>def <span class="ident">check_goodness_of_fit</span></span>(<span>individual, params, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculates metrics to assess the goodness of fit. Does so by first
optimizing the fitting parameters.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>individual</code></strong> :&ensp;<code>string</code> (or, <code>alternatively</code>, <code>a</code> <code>DEAP</code> <code>individual</code> <code>object</code>)</dt>
<dd>A pySRURGS generated equation string</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>lmfit.Parameters</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>tuple</code></dt>
<dd>(sum_of_squared_residuals, sum_of_squared_totals, R2,
params_dict_to_store, residual)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_goodness_of_fit(individual, params, SRconfig):
    &#34;&#34;&#34;
    Calculates metrics to assess the goodness of fit. Does so by first
    optimizing the fitting parameters.

    Parameters
    ----------
    individual : string (or, alternatively, a DEAP individual object)
        A pySRURGS generated equation string

    params: lmfit.Parameters

    SRconfig: pySRURGS.SymbolicRegressionConfig

    Returns
    -------
    result: tuple
        (sum_of_squared_residuals, sum_of_squared_totals, R2,
         params_dict_to_store, residual)
    &#34;&#34;&#34;
    my_data = SRconfig._dataset
    # If funcstring is a tree, transform to string
    funcstring = str(individual)
    funcstring = clean_funcstring(funcstring)
    # Evaluate the sum of squared difference between the expression
    if len(params) &gt; 0:
        result = lmfit.minimize(eval_equation, params,
                                args=(funcstring, SRconfig),
                                method=&#39;leastsq&#39;, 
                                nan_policy=&#39;propagate&#39;)
        residual = result.residual
        y_calc = eval_equation(result.params, 
                               funcstring, 
                               SRconfig,
                               mode=&#39;y_calc&#39;)
        params_dict_to_store = result.params
    else:
        residual = eval_equation(params, funcstring, SRconfig)
        y_calc = eval_equation(params, funcstring, SRconfig, mode=&#39;y_calc&#39;)
        params_dict_to_store = params
    avg_y_data = np.average(my_data._y_data)
    sum_of_squared_residuals = sum(pow(residual, 2))
    sum_of_squared_totals = sum(pow(y_calc - avg_y_data, 2))
    R2 = 1 - sum_of_squared_residuals / sum_of_squared_totals
    result = (sum_of_squared_residuals,
              sum_of_squared_totals,
              R2,
              params_dict_to_store,
              residual)
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.check_validity_suggested_functions"><code class="name flex">
<span>def <span class="ident">check_validity_suggested_functions</span></span>(<span>suggested_funcs, arity)</span>
</code></dt>
<dd>
<section class="desc"><p>Takes a list of suggested functions to use in the search space and checks
that they are valid.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>suggested_funcs</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of strings.
In case of <code>arity==1</code>, permitted values are ['sin','cos','tan','exp',
'log','tanh','sinh','cosh',
None]
In case of <code>arity==2</code>, permitted values are ['add','sub','mul','div',
'pow', None]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>suggested_funcs</code></strong> :&ensp;<code>list</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code>, <code>if</code> <code>any</code> of <code>the</code> <code>suggested</code> <code>funcs</code> <code>is</code> <code>not</code> <code>in</code> <code>the</code> <code>permitted</code> <code>list</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_validity_suggested_functions(suggested_funcs, arity):
    &#39;&#39;&#39;
    Takes a list of suggested functions to use in the search space and checks
    that they are valid.

    Parameters
    ----------
    suggested_funcs: list
        A list of strings.
        In case of `arity==1`, permitted values are [&#39;sin&#39;,&#39;cos&#39;,&#39;tan&#39;,&#39;exp&#39;,
                                                     &#39;log&#39;,&#39;tanh&#39;,&#39;sinh&#39;,&#39;cosh&#39;,
                                                     None]
        In case of `arity==2`, permitted values are [&#39;add&#39;,&#39;sub&#39;,&#39;mul&#39;,&#39;div&#39;,
                                                     &#39;pow&#39;, None]

    Returns
    -------
    suggested_funcs: list

    Raises
    ------
    Exception, if any of the suggested funcs is not in the permitted list
    &#39;&#39;&#39;
    valid_funcs_arity_1 = [&#39;sin&#39;, &#39;cos&#39;, &#39;tan&#39;, &#39;exp&#39;, &#39;log&#39;, &#39;tanh&#39;, &#39;sinh&#39;, 
                           &#39;cosh&#39;, None]
    valid_funcs_arity_2 = [&#39;add&#39;, &#39;sub&#39;, &#39;mul&#39;, &#39;div&#39;, &#39;pow&#39;, None]
    if arity == 1:
        if suggested_funcs != [&#39;,&#39;]:
            for func in suggested_funcs:
                if func not in valid_funcs_arity_1:
                    msg = &#34;Your suggested function of arity 1: &#34; + func
                    msg += &#34; is not in the list of valid functions&#34;
                    msg += &#34; &#34; + str(valid_funcs_arity_1)
                    raise Exception(msg)
        else:
            suggested_funcs = []
    elif arity == 2:
        for func in suggested_funcs:
            if func not in valid_funcs_arity_2:
                msg = &#34;Your suggested function of arity 2: &#34; + func
                msg += &#34; is not in the list of valid functions&#34;
                msg += &#34; &#34; + str(valid_funcs_arity_2)
                raise Exception(msg)
    return suggested_funcs</code></pre>
</details>
</dd>
<dt id="pySRURGS.clean_funcstring"><code class="name flex">
<span>def <span class="ident">clean_funcstring</span></span>(<span>funcstring)</span>
</code></dt>
<dd>
<section class="desc"><p>Replaces the pySRURGS variables' and fitting parameters' prefix/suffix from
an equation string with the dictionary codes needed to numerically evaluate
the equation string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>funcstring</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>funcstring</code></strong> :&ensp;<code>string</code></dt>
<dd><code>funcstring</code> with the variables' and fitting parameters' prefix and
suffix replaced with the dictionary tags.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_funcstring(funcstring):
    &#34;&#34;&#34;
    Replaces the pySRURGS variables&#39; and fitting parameters&#39; prefix/suffix from
    an equation string with the dictionary codes needed to numerically evaluate
    the equation string.

    Parameters
    ----------
    funcstring : string
        A pySRURGS generated equation string

    Returns
    -------
    funcstring: string
        `funcstring` with the variables&#39; and fitting parameters&#39; prefix and
        suffix replaced with the dictionary tags.
    &#34;&#34;&#34;
    funcstring = clean_funcstring_vars(funcstring)
    funcstring = clean_funcstring_params(funcstring)
    return funcstring</code></pre>
</details>
</dd>
<dt id="pySRURGS.clean_funcstring_params"><code class="name flex">
<span>def <span class="ident">clean_funcstring_params</span></span>(<span>funcstring)</span>
</code></dt>
<dd>
<section class="desc"><p>Replaces the pySRURGS fitting parameter prefix/suffix from an equation
string with the dictionary codes needed to numerically evaluate the equation
string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>funcstring</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>funcstring</code></strong> :&ensp;<code>string</code></dt>
<dd><code>funcstring</code> with the fitting parameters' prefix and suffix replaced
with the dictionary tags.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_funcstring_params(funcstring):
    &#34;&#34;&#34;
    Replaces the pySRURGS fitting parameter prefix/suffix from an equation
    string with the dictionary codes needed to numerically evaluate the equation
    string.

    Parameters
    ----------
    funcstring : string
        A pySRURGS generated equation string

    Returns
    -------
    funcstring: string
        `funcstring` with the fitting parameters&#39; prefix and suffix replaced
        with the dictionary tags.
    &#34;&#34;&#34;
    funcstring = funcstring.replace(fitting_param_prefix, &#39;params[&#34;&#39;)
    funcstring = funcstring.replace(fitting_param_suffix, &#39;&#34;].value&#39;)
    return funcstring</code></pre>
</details>
</dd>
<dt id="pySRURGS.clean_funcstring_vars"><code class="name flex">
<span>def <span class="ident">clean_funcstring_vars</span></span>(<span>funcstring)</span>
</code></dt>
<dd>
<section class="desc"><p>Replaces the pySRURGS variable prefix/suffix from an equation
string with the dictionary codes needed to numerically evaluate the equation
string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>funcstring</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>funcstring</code></strong> :&ensp;<code>string</code></dt>
<dd><code>funcstring</code> with the variables' prefix and suffix replaced with
the dictionary tags.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clean_funcstring_vars(funcstring):
    &#34;&#34;&#34;
    Replaces the pySRURGS variable prefix/suffix from an equation
    string with the dictionary codes needed to numerically evaluate the equation
    string.

    Parameters
    ----------
    funcstring : string
        A pySRURGS generated equation string

    Returns
    -------
    funcstring: string
        `funcstring` with the variables&#39; prefix and suffix replaced with
        the dictionary tags.
    &#34;&#34;&#34;
    funcstring = funcstring.replace(variable_prefix, &#39;df[&#34;&#39;)
    funcstring = funcstring.replace(variable_suffix, &#39;&#34;]&#39;)
    return funcstring</code></pre>
</details>
</dd>
<dt id="pySRURGS.compile_results"><code class="name flex">
<span>def <span class="ident">compile_results</span></span>(<span>SRconfig, print_mode=True)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads from the generated SqliteDict file to determine the best stored models</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>SRconfig</code></strong> :&ensp;<code>pySRUGS.SymbolicRegressionConfig</code></dt>
<dd>The symbolic regression problem's configuration object</dd>
<dt><strong><code>print_mode</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>If true, prints to screen. If false, does not.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result_list</code></strong> :&ensp;<a title="pySRURGS.ResultList" href="#pySRURGS.ResultList"><code>ResultList</code></a></dt>
<dd>Compiling all the results found in the <code>path_to_db</code> database file</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compile_results(SRconfig, print_mode=True):
    &#39;&#39;&#39;
    Reads from the generated SqliteDict file to determine the best stored models

    Parameters
    ----------
    SRconfig: pySRUGS.SymbolicRegressionConfig
        The symbolic regression problem&#39;s configuration object       

    print_mode: Boolean
        If true, prints to screen. If false, does not.

    Returns
    -------
    result_list: pySRURGS.ResultList 
        Compiling all the results found in the `path_to_db` database file
    &#39;&#39;&#39;
    dataset = SRconfig._dataset
    path_to_db = SRconfig._path_to_db
    result_list = get_resultlist(path_to_db)
    result_list.sort()
    if print_mode == True:
        result_list.print(dataset._y_data)
    return result_list</code></pre>
</details>
</dd>
<dt id="pySRURGS.count_number_equations"><code class="name flex">
<span>def <span class="ident">count_number_equations</span></span>(<span>SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Counts the number of possible equations in this problem. A wrapper function
around EnumeratorBinaryTree.get_M / EnumeratorFullBinaryTree.get_M.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression problem configuration object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>number_possible_equations</code></strong> :&ensp;<code>int</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_number_equations(SRconfig):
    &#39;&#39;&#39;
    Counts the number of possible equations in this problem. A wrapper function
    around EnumeratorBinaryTree.get_M / EnumeratorFullBinaryTree.get_M.

    Parameters
    ----------
    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression problem configuration object

    Returns
    -------
    number_possible_equations: int
    &#39;&#39;&#39;
    (f, n, m, cum_weights, N, dataset, enumerator, _, _) = setup(SRconfig)
    if f == 0:
        number_possible_equations = enumerator.get_M(N, n, m)
    else:
        number_possible_equations = enumerator.get_M(N, f, n, m)
    return number_possible_equations</code></pre>
</details>
</dd>
<dt id="pySRURGS.count_results"><code class="name flex">
<span>def <span class="ident">count_results</span></span>(<span>path_to_db)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads the generated SqliteDict file to determine the number of generated
models</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path_to_db</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to the SqliteDict database file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>n_results</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of results in the ResultList</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_results(path_to_db):
    &#39;&#39;&#39;
    Reads the generated SqliteDict file to determine the number of generated 
    models

    Parameters
    ----------
    path_to_db: string
        An absolute or relative path to the SqliteDict database file.

    Returns
    -------
    n_results: int
        The number of results in the ResultList
    &#39;&#39;&#39;
    result_list = get_resultlist(path_to_db)
    n_results = len(result_list._results)
    return n_results</code></pre>
</details>
</dd>
<dt id="pySRURGS.create_db_name"><code class="name flex">
<span>def <span class="ident">create_db_name</span></span>(<span>path_to_csv, additional_name=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a name of a SqliteDict file based on the CSV filename</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path_to_csv</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to the CSV for the problem.</dd>
<dt><strong><code>additional_name</code></strong> :&ensp;<code>string</code></dt>
<dd>An additional specifier used in generating the database file name</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>db_name</code></strong> :&ensp;<code>string</code></dt>
<dd>A filepath starting with './db/' and matching with the CSV file name
with an optional <code>additional_name</code> within the file name. Ends in '.db'.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_db_name(path_to_csv, additional_name=None):
    &#39;&#39;&#39;
    Generates a name of a SqliteDict file based on the CSV filename

    Parameters
    ----------
    path_to_csv: string
        An absolute or relative path to the CSV for the problem.

    additional_name: string
        An additional specifier used in generating the database file name

    Returns
    -------
    db_name: string
        A filepath starting with &#39;./db/&#39; and matching with the CSV file name
        with an optional `additional_name` within the file name. Ends in &#39;.db&#39;.
    &#39;&#39;&#39;
    csv_basename = os.path.basename(path_to_csv)
    csv_name = csv_basename[:-4]
    if additional_name is not None:
        db_name = &#39;./db/&#39; + csv_name + additional_name + &#39;.db&#39;
    else:
        db_name = &#39;./db/&#39; + csv_name + &#39;.db&#39;
    return db_name</code></pre>
</details>
</dd>
<dt id="pySRURGS.create_fitting_parameters"><code class="name flex">
<span>def <span class="ident">create_fitting_parameters</span></span>(<span>max_params, param_values=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates the lmfit.Parameters object based on the number of fitting
parameters permitted in this symbolic regression problem.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>max_params</code></strong> :&ensp;<code>int</code></dt>
<dd>The maximum number of fitting parameters. Same as <code>max_num_fit_params</code>.</dd>
<dt><strong><code>param_values</code></strong> :&ensp;<code>None</code> <code>OR</code> (<code>numpy.array</code> of <code>length</code> <code>max_params</code>)</dt>
<dd>Specifies the values of the fitting parameters. If none, will default
to an array of ones, which are to be optimized later.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>lmfit.Parameters</code></dt>
<dd>Fitting parameter names specified as ['p' + str(integer) for integer
in range(0, max_params)]</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_fitting_parameters(max_params, param_values=None):
    &#34;&#34;&#34;
    Creates the lmfit.Parameters object based on the number of fitting 
    parameters permitted in this symbolic regression problem.

    Parameters
    ----------
    max_params: int
        The maximum number of fitting parameters. Same as `max_num_fit_params`.

    param_values: None OR (numpy.array of length max_params)
        Specifies the values of the fitting parameters. If none, will default
        to an array of ones, which are to be optimized later.

    Returns
    -------
    params: lmfit.Parameters
        Fitting parameter names specified as [&#39;p&#39; + str(integer) for integer
        in range(0, max_params)]
    &#34;&#34;&#34;
    params = lmfit.Parameters()
    for int_param in range(0, max_params):
        param_name = &#39;p&#39; + str(int_param)
        param_init_value = np.float(1)
        params.add(param_name, param_init_value)
    if param_values is not None:
        for int_param in range(0, max_params):
            param_name = &#39;p&#39; + str(int_param)
            params[param_name].value = param_values[int_param]
    return params</code></pre>
</details>
</dd>
<dt id="pySRURGS.create_parameter_list"><code class="name flex">
<span>def <span class="ident">create_parameter_list</span></span>(<span>m)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates a list of all the fitting parameter names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>m</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of fitting parameters in the symbolic regression problem</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>my_pars</code></strong> :&ensp;<code>list</code></dt>
<dd>A list with fitting parameter names as elements.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_parameter_list(m):
    &#34;&#34;&#34;
    Creates a list of all the fitting parameter names.

    Parameters
    ----------
    m : int
        The number of fitting parameters in the symbolic regression problem

    Returns
    -------
    my_pars: list
        A list with fitting parameter names as elements.
    &#34;&#34;&#34;
    my_pars = []
    for i in range(0, m):
        my_pars.append(make_parameter_name(&#39;p&#39; + str(i)))
    return my_pars</code></pre>
</details>
</dd>
<dt id="pySRURGS.create_variable_list"><code class="name flex">
<span>def <span class="ident">create_variable_list</span></span>(<span>m)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates a list of all the variable names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>m</code></strong> :&ensp;<code>string</code> (<code>1</code>) or <code>int</code> (<code>2</code>)</dt>
<dd>(1) Absolute or relative path to a CSV file with a header
(2) The number of independent variables in the dataset</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>my_vars</code></strong> :&ensp;<code>list</code></dt>
<dd>A list with dataset variable names as elements.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_variable_list(m):
    &#34;&#34;&#34;
    Creates a list of all the variable names.

    Parameters
    ----------
    m : string (1) or int (2)
        (1) Absolute or relative path to a CSV file with a header
        (2) The number of independent variables in the dataset

    Returns
    -------
    my_vars: list
        A list with dataset variable names as elements.
    &#34;&#34;&#34;
    if type(m) == str:
        my_vars = pandas.read_csv(m).keys()[:-1].tolist()
        my_vars = [make_variable_name(x) for x in my_vars]
    if type(m) == int:
        my_vars = []
        for i in range(0, m):
            my_vars.append(make_variable_name(&#39;x&#39; + str(i)))
    return my_vars</code></pre>
</details>
</dd>
<dt id="pySRURGS.equation_generator_binary_tree"><code class="name flex">
<span>def <span class="ident">equation_generator_binary_tree</span></span>(<span>i, q, r, s, enumerator, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates an equation string given the integers that specify an equation
string in pySRURGS. Use <a title="pySRURGS.equation_generator_full_binary_tree" href="#pySRURGS.equation_generator_full_binary_tree"><code>equation_generator_full_binary_tree()</code></a> instead when
there are no functions of arity one permitted.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the unique binary tree. Must be
greater than 0.</dd>
<dt><strong><code>q</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the configuration of the
functions of arity one. Must be greater than 0 and less than the number
of possible configurations of functions of arity one, <code>G</code>: see
<code>Enumerator.get_G</code> for details.</dd>
<dt><strong><code>r</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the configuration of the
functions of arity two. Must be greater than 0 and less than the number
of possible configurations of functions of arity two, <code>A</code>: see
<code>Enumerator.get_A</code> for details.</dd>
<dt><strong><code>s</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the configuration of the
terminals. Must be greater than 0 and less than the number
of possible configurations of functions of arity two, <code>B</code>: see
<code>Enumerator.get_B</code> for details.</dd>
<dt><strong><code>enumerator</code></strong> :&ensp;<code>pySRURGS.Enumerator</code></dt>
<dd>The <code>Enumerator</code> object for the symbolic regression problem</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The <a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a> for the symbolic regression problem</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tree</code></strong> :&ensp;<code>string</code></dt>
<dd>The equation string, without any simplifications</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def equation_generator_binary_tree(i, q, r, s, enumerator, SRconfig):
    &#34;&#34;&#34;
    Generates an equation string given the integers that specify an equation
    string in pySRURGS. Use `equation_generator_full_binary_tree` instead when 
    there are no functions of arity one permitted.

    Parameters
    ----------
    i: int
        Specifies the integer representation of the unique binary tree. Must be
        greater than 0.

    q: int
        Specifies the integer representation of the configuration of the
        functions of arity one. Must be greater than 0 and less than the number
        of possible configurations of functions of arity one, `G`: see
        `Enumerator.get_G` for details.

    r: int
        Specifies the integer representation of the configuration of the
        functions of arity two. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `A`: see
        `Enumerator.get_A` for details.

    s: int
        Specifies the integer representation of the configuration of the
        terminals. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `B`: see
        `Enumerator.get_B` for details.

    enumerator: pySRURGS.Enumerator
        The `Enumerator` object for the symbolic regression problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` for the symbolic regression problem

    Returns
    -------
    tree: string
        The equation string, without any simplifications
    &#34;&#34;&#34;
    en = enumerator
    dataset = SRconfig._dataset
    f = len(SRconfig._f_functions)
    n = len(SRconfig._n_functions)    
    m = dataset._m_terminals
    tree = ith_binary_tree(i)
    G = en.get_G(f, i)
    if q &gt;= G and not G == 0:
        raise Exception(&#34;q is an index that must be smaller than G&#34;)
    A = en.get_A(n, i)
    if r &gt;= A:
        raise Exception(&#34;r is an index that must be smaller than A&#34;)
    B = en.get_B(m, i)
    if s &gt;= B:
        raise Exception(&#34;s is an index that must be smaller than B&#34;)
    l_i = en.get_l_i(i)
    k_i = en.get_k_i(i)
    j_i = en.get_j_i(i)
    # of all the possible configurations of arity 1 functions, we pick the
    # configuration at index q
    f_func_config = get_element_of_cartesian_product(SRconfig._f_functions,
                                                     repeat=l_i, index=q)
    # of all the possible configurations of arity 2 functions, we pick the
    # configuration at index r
    n_func_config = get_element_of_cartesian_product(SRconfig._n_functions,
                                                     repeat=k_i, index=r)
    # of all the possible configurations of terminals, we pick the
    # configuration at index s
    term_config = get_element_of_cartesian_product(dataset._terminals_list,
                                                   repeat=j_i, index=s)
    orig_tree = tree
    # the trees are generated in the form [. , .] where . denotes a leaf,
    # and the square brackets indicate a function
    # we do some string replacements here, according to the determined
    # configurations to build the equation as a string
    for z in range(0, len(n_func_config)):
        func = n_func_config[z]
        tree = tree.replace(&#39;[&#39;, func + &#39;(&#39;, 1)
        tree = tree.replace(&#39;]&#39;, &#39;)&#39;, 1)    
    for z in range(0, len(f_func_config)):
        func = f_func_config[z]
        tree = tree.replace(&#39;|&#39;, func + &#39;(&#39;, 1)
        tree = tree.replace(&#39;|&#39;, &#39;)&#39;, 1)
    func_tree = tree
    for z in range(0, len(term_config)):
        term = term_config[z]
        tree = tree.replace(&#39;.&#39;, term, 1)
    return tree</code></pre>
</details>
</dd>
<dt id="pySRURGS.equation_generator_full_binary_tree"><code class="name flex">
<span>def <span class="ident">equation_generator_full_binary_tree</span></span>(<span>i, r, s, enumerator, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates an equation string given the integers that specify an equation
string in pySRURGS. Use <a title="pySRURGS.equation_generator_binary_tree" href="#pySRURGS.equation_generator_binary_tree"><code>equation_generator_binary_tree()</code></a> instead when there
are functions of arity one permitted.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the unique binary tree. Must be
greater than 0.</dd>
<dt><strong><code>r</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the configuration of the
functions of arity two. Must be greater than 0 and less than the number
of possible configurations of functions of arity two, <code>A</code>: see
<code>Enumerator.get_A</code> for details.</dd>
<dt><strong><code>s</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the integer representation of the configuration of the
terminals. Must be greater than 0 and less than the number
of possible configurations of functions of arity two, <code>B</code>: see
<code>Enumerator.get_B</code> for details.</dd>
<dt><strong><code>enumerator</code></strong> :&ensp;<a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a></dt>
<dd>The <a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a> object for the symbolic regression
problem</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The <a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a> for the symbolic regression problem</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>tree</code></strong> :&ensp;<code>string</code></dt>
<dd>The equation string, without any simplifications</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def equation_generator_full_binary_tree(i, r, s, enumerator, SRconfig):
    &#34;&#34;&#34;
    Generates an equation string given the integers that specify an equation
    string in pySRURGS. Use `equation_generator_binary_tree` instead when there 
    are functions of arity one permitted.

    Parameters
    ----------
    i: int
        Specifies the integer representation of the unique binary tree. Must be
        greater than 0.

    r: int
        Specifies the integer representation of the configuration of the
        functions of arity two. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `A`: see
        `Enumerator.get_A` for details.

    s: int
        Specifies the integer representation of the configuration of the
        terminals. Must be greater than 0 and less than the number
        of possible configurations of functions of arity two, `B`: see
        `Enumerator.get_B` for details.

    enumerator: pySRURGS.EnumeratorFullBinaryTree
        The `EnumeratorFullBinaryTree` object for the symbolic regression 
        problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` for the symbolic regression problem

    Returns
    -------
    tree: string
        The equation string, without any simplifications
    &#34;&#34;&#34;
    en = enumerator
    dataset = SRconfig._dataset
    n = len(SRconfig._n_functions)    
    m = dataset._m_terminals
    tree = ith_full_binary_tree(i)
    A = en.get_A(n, i)
    if r &gt;= A:
        raise Exception(&#34;r is an index that must be smaller than A&#34;)
    B = en.get_B(m, i)
    if s &gt;= B:
        raise Exception(&#34;s is an index that must be smaller than B&#34;)
    k_i = en.get_k_i(i)
    j_i = en.get_j_i(i)
    n_func_config = get_element_of_cartesian_product(SRconfig._n_functions,
                                                     repeat=k_i,
                                                     index=r)
    term_config = get_element_of_cartesian_product(dataset._terminals_list,
                                                   repeat=j_i, index=s)
    orig_tree = tree
    for z in range(0, len(n_func_config)):
        func = n_func_config[z]
        tree = tree.replace(&#39;[&#39;, func + &#39;(&#39;, 1)
        tree = tree.replace(&#39;]&#39;, &#39;)&#39;, 1)
    func_tree = tree
    for z in range(0, len(term_config)):
        term = term_config[z]
        tree = tree.replace(&#39;.&#39;, term, 1)
    return tree</code></pre>
</details>
</dd>
<dt id="pySRURGS.eval_equation"><code class="name flex">
<span>def <span class="ident">eval_equation</span></span>(<span>params, function_string, SRconfig, mode='residual')</span>
</code></dt>
<dd>
<section class="desc"><p>Evaluates the equation numerically.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>params</code></strong> :&ensp;<code>lmfit.Parameters</code></dt>
<dd>The lmfit.parameters object used to optimize fitting parameters</dd>
<dt><strong><code>function_string</code></strong> :&ensp;<code>string</code></dt>
<dd>The equation string in dictionary code tags in place.
Use <a title="pySRURGS.clean_funcstring" href="#pySRURGS.clean_funcstring"><code>clean_funcstring()</code></a> to put in place the dictionary code tags.</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression configuration object for this problem</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>string</code></dt>
<dd>'residual' or 'y_calc'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>output</code></strong> :&ensp;<code>array</code> <code>like</code></dt>
<dd>An array of residuals or predicted dependent variable values, depending
on the value of <code>mode</code>.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_equation(params, function_string, SRconfig, mode=&#39;residual&#39;):
    &#34;&#34;&#34;
    Evaluates the equation numerically.

    Parameters
    ----------
    params: lmfit.Parameters
        The lmfit.parameters object used to optimize fitting parameters

    function_string: string
        The equation string in dictionary code tags in place.
        Use `clean_funcstring` to put in place the dictionary code tags.

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    mode: string
        &#39;residual&#39; or &#39;y_calc&#39;.

    Returns
    -------
    output: array like
        An array of residuals or predicted dependent variable values, depending
        on the value of `mode`.
    &#34;&#34;&#34;
    my_data = SRconfig._dataset
    len_data = len(my_data._y_data)
    df = my_data._data_dict
    pd = params.valuesdict()
    y_label = my_data._y_label
    independent_var_vector = df[y_label]
    # residual = [BIG_NUM] * len(df[y_label])
    if mode == &#39;residual&#39;:
        eval_string = &#39;(&#39; + function_string + &#39;) -  df[&#34;&#39; + y_label + &#39;&#34;]&#39;
        residual = eval(eval_string)
        output = residual
    elif mode == &#39;y_calc&#39;:
        y_value = eval(function_string)
        output = y_value
    elif type(mode) == dict:
        df = mode
        y_value = eval(function_string)
        output = y_value    
    if np.size(output) == 1:
        # if model only has parameters and no data variables, we can have a
        # situation where output is a single constant
        output = np.resize(output, np.size(independent_var_vector))
    return output</code></pre>
</details>
</dd>
<dt id="pySRURGS.exhaustive_search"><code class="name flex">
<span>def <span class="ident">exhaustive_search</span></span>(<span>SRconfig, queue=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs a brute-force/exhaustive symbolic regression search against the CSV
file. WARNING, unless you specify a very simple problem, this computation
will indefinitely. Consider using the <a title="pySRURGS.count_number_equations" href="#pySRURGS.count_number_equations"><code>count_number_equations()</code></a> function
to first determine how many equations you will be considering.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression configuration object for this problem</dd>
<dt><strong><code>queue</code></strong> :&ensp;<code>multiprocessing.Manager.Queue</code> <code>OR</code> <code>None</code></dt>
<dd>If exists, will treat as multiprocessing, if None, will treat as
single core processing</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl>
<h1 id="todo">TODO</h1>
<dl>
<dt><code>for</code> <code>the</code> <code>case</code> of <code>i</code> == <code>0</code>, <code>the</code> <code>number</code> of <code>operator</code>/<code>function</code> <code>configurations</code></dt>
<dd>&nbsp;</dd>
<dt><code>will</code> <code>be</code> <code>zero</code>, <code>so</code> <code>this</code> <code>exhaustive</code> <code>search</code> <code>will</code> <code>skip</code> <code>that</code> <code>case.</code> <code>Fix</code> <code>this</code> <code>in</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>the future.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exhaustive_search(SRconfig, queue=None):
    &#39;&#39;&#39;
    Runs a brute-force/exhaustive symbolic regression search against the CSV
    file. WARNING, unless you specify a very simple problem, this computation
    will indefinitely. Consider using the `count_number_equations` function
    to first determine how many equations you will be considering.

    Parameters
    ----------
    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    queue: multiprocessing.Manager.Queue OR None
        If exists, will treat as multiprocessing, if None, will treat as 
        single core processing

    Returns
    -------
    None
    
    # TODO 
    for the case of i == 0, the number of operator/function configurations 
    will be zero, so this exhaustive search will skip that case. Fix this in 
    the future.
    
    &#39;&#39;&#39;
    warning_string = &#34;&#34;&#34;
    WARNING: you are running an exhaustive search on a large search space.
    Are you sure you want to do this?!
    &#34;&#34;&#34;
    path_to_db = SRconfig._path_to_db
    path_to_csv = SRconfig._path_to_csv
    path_to_weights = SRconfig._path_to_weights
    num_equations = count_number_equations(SRconfig)
    print(&#34;Number of equations: &#34;, num_equations)
    if num_equations &gt; 50000:
        print(warning_string)        
        print(&#34;Waiting 10 seconds for user to break with ctrl-c, otherwise will run.&#34;)
        time.sleep(10)
    if ((&#39;add&#39; not in SRconfig._n_functions and
         &#39;sub&#39; not in SRconfig._n_functions) or
            SRconfig._max_num_fit_params == 0):
        msg = &#34;Exhaustive search needs `add` or `sub` and &gt;=1 fit parameter to be truly exhaustive&#34;
        raise Exception(msg)
    (f, n, m, _, N, dataset, enumerator, _, _) = setup(SRconfig)
    initialize_db(path_to_db)
    # we need to have two streams here, the first for the case where there are
    # functions of arity one permitted, the second for the case where there are
    # no functions of arity one permitted. Within each stream, we need to have
    # a substream for single processing and a substream for multiprocessing
    results = ResultList()
    if f &gt; 0:  # functions of arity one present
        for i in range(0, N):
            G = int(enumerator.get_G(f, i))
            A = int(enumerator.get_A(n, i))
            B = int(enumerator.get_B(m, i))
            if queue is None:  # single processor substream
                for r in range(0, A):
                    for s in range(0, B):
                        for q in range(0, G):
                            index_tuple = (q, r, s)
                            print(&#34;i:&#34;, i, &#34;q:&#34;, q, &#34;r:&#34;, r, &#34;s:&#34;, s, end=&#39;\r&#39;)
                            check_equation_at_specified_indices_to_db(
                                                                index_tuple, i,                                                                
                                                                SRconfig)
            else:  # multiprocessing substream
                iterator = itertools.product(range(0, G), range(0, A), range(
                                                                          0, B))
                iterator = list(iterator)
                num_solns = len(iterator)
                runner = mp.Process(target=solution_saving_worker, 
                                           args=(queue, num_solns, path_to_db))
                runner.start()
                parmap.map(check_equation_at_specified_indices_to_queue,
                           iterator, i, SRconfig, queue, pm_pbar=True)
                runner.join()
    elif f == 0:  # functions of arity one absent
        for i in range(0, N):
            A = int(enumerator.get_A(n, i))
            B = int(enumerator.get_B(m, i))
            if queue is None:  # single processor substream
                for r in range(0, A):
                    for s in range(0, B):
                        index_tuple = (r, s)
                        print(&#34;i:&#34;, i, &#34;r:&#34;, r, &#34;s:&#34;, s, 
                              end=&#39;\r&#39;)
                        check_equation_at_specified_indices_to_db(
                                                            index_tuple, i,
                                                            SRconfig)
            else:  # multiprocessing substream
                iterator = itertools.product(range(0, A), range(0, B))
                iterator = list(iterator)
                num_solns = len(iterator)
                runner = mp.Process(target=solution_saving_worker, 
                           args=(queue, num_solns, path_to_db))
                runner.start()
                parmap.map(check_equation_at_specified_indices_to_queue,
                           iterator, i, SRconfig, queue, pm_pbar=True)
                runner.join()</code></pre>
</details>
</dd>
<dt id="pySRURGS.generate_benchmark"><code class="name flex">
<span>def <span class="ident">generate_benchmark</span></span>(<span>benchmark_name, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Generate a random symbolic regression benchmark problem.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>benchmark_name</code></strong> :&ensp;<code>string</code></dt>
<dd>A string that denotes the name of the problem. Typically, an integer
set as a string will do.</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression configuration object for this problem.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Saves a CSV file to: <code>benchmarks_dir + '/' + benchmark_name + '_train.csv'</code>
Saves a CSV file to: <code>benchmarks_dir + '/' + benchmark_name + '_test.csv'</code>
Saves a human readable text file to:
<code>benchmarks_dir + '/' + benchmark_name + '_params.txt'</code></p>
<p><code>benchmarks_dir</code> is a global variable typically set to './benchmarks'</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_benchmark(benchmark_name, SRconfig):
    &#34;&#34;&#34;
    Generate a random symbolic regression benchmark problem.

    Parameters
    ----------
    benchmark_name: string
        A string that denotes the name of the problem. Typically, an integer
        set as a string will do.

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem.

    Returns
    -------
    None


    Notes
    -----
    Saves a CSV file to: `benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_train.csv&#39;`
    Saves a CSV file to: `benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_test.csv&#39;`
    Saves a human readable text file to:
            `benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_params.txt&#39;`

    `benchmarks_dir` is a global variable typically set to &#39;./benchmarks&#39;
    &#34;&#34;&#34;
    (f, n, m, cum_weights, N, dataset,
     enumerator, n_functions, f_functions) = setup(SRconfig)
    valid = False
    while valid == False:
        print(ERASE_LINE + &#34;Iterating...&#34;, end=&#39;\r&#39;)
        try:
            # specify the equation
            if f == 0:
                eqn_details = random_equation_full_binary_tree(N, cum_weights,
                                             enumerator, SRconfig, details=True)
            else:
                eqn_details = random_equation_binary_tree(N, cum_weights,
                                             enumerator, SRconfig, details=True)
            eqn_original = eqn_details[0]
            eqn_simple = simplify_equation_string(eqn_original, dataset)
            eqn_specifiers = eqn_details[1:]
            # create the fitting parameters values
            fitting_parameters = (randgen.random_sample((5)) - 0.5) * 20
            fit_param_list = create_fitting_parameters(5)
            for i in range(0, 5):
                fit_param_list[&#39;p&#39; + str(i)].value = fitting_parameters[i]
            eqn_original_cleaned = clean_funcstring(eqn_original)
            # create the training dataset
            for zz in range(0, 2):  # 1st iteration, train. 2nd iteration, test.
                sample_dataset = np.zeros((100, 6))
                for j in range(0, 5):
                    sample_dataset[:, j] = randgen.random_sample((100,)) * 10
                dataset._dataframe = pandas.DataFrame(sample_dataset)
                dataset._dataframe.columns = dataset._x_labels.tolist() + \
                    [dataset._y_label]
                dataset._data_dict = dataset.get_data_dict()
                # calculate y for the sample problem
                y_calc = eval_equation(fit_param_list, eqn_original_cleaned,
                                       SRconfig, mode=&#39;y_calc&#39;)
                dataset._dataframe[dataset._y_label] = y_calc
                # save the test and train sets to file
                if zz == 0:
                    path1 = benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_train.csv&#39;
                else:
                    path1 = benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_test.csv&#39;
                dataset._dataframe.to_csv(path1, index=False)
                # test to see that the dataset can be loaded
                dataset_test = Dataset(path1, 5)
                path2 = benchmarks_dir + &#39;/&#39; + benchmark_name + &#39;_params.txt&#39;
                # save the problem parameters to a text file
                with open(path2, &#34;w&#34;) as text_file:
                    msg = &#39;Permitted variables: &#39; + \
                        str(dataset._x_labels.tolist()) + &#39;\n&#39;
                    msg += &#39;Permitted fitting parameters: &#39; + \
                        str(list(fit_param_list.keys())) + &#39;\n&#39;
                    msg += &#39;Fitting parameters: &#39;
                    msg += str(np.array(fit_param_list)) + &#39;\n&#39;
                    msg += &#39;Permitted functions: &#39; + \
                        str(f_functions + n_functions) + &#39;\n&#39;
                    msg += &#39;Simplified equation: &#39; + str(eqn_simple) + &#39;\n&#39;
                    eqn_original = remove_variable_tags(eqn_original)
                    eqn_original = remove_parameter_tags(eqn_original)
                    msg += &#39;Raw equation: &#39; + str(eqn_original) + &#39;\n&#39;
                    text_file.write(msg)
            valid = True
            if eqn_simple == &#39;0&#39;:
                valid = False
        except Exception as e:
            print(ERASE_LINE + str(e), end=&#39;\r&#39;)
            valid = False</code></pre>
</details>
</dd>
<dt id="pySRURGS.generate_benchmarks"><code class="name flex">
<span>def <span class="ident">generate_benchmarks</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates 100 randomly generated symbolic regression problems. The first
twentry problems are simpler than the latter 80, in that the latter 80
permit functions of arity one in the search space.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Benchmark problems are saved in the <code>benchmarks_dir</code> filepath
<code>benchmarks_dir</code> is a global variable.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_benchmarks():
    &#39;&#39;&#39;
    Generates 100 randomly generated symbolic regression problems. The first
    twentry problems are simpler than the latter 80, in that the latter 80
    permit functions of arity one in the search space.

    Parameters
    ----------
    None

    Returns
    -------
    None

    Notes
    ------
    Benchmark problems are saved in the `benchmarks_dir` filepath
    `benchmarks_dir` is a global variable.
    &#39;&#39;&#39;
    SR_config1, SR_config2 = generate_benchmarks_SRconfigs()
    # first set is from 0 - 19 inclusive
    for z in range(0, 20):
        print(ERASE_LINE + &#34;Generating benchmark:&#34;, z, &#34;out of:&#34;, 99, end=&#34;\r&#34;)
        generate_benchmark(str(z), SR_config1)
    for z in range(20, 100):
        print(ERASE_LINE + &#34;Generating benchmark:&#34;, z, &#34;out of:&#34;, 99, end=&#34;\r&#34;)
        generate_benchmark(str(z), SR_config2)
    print(&#34;Outputting a summary to &#34;, benchmarks_summary_tsv)
    read_benchmarks()</code></pre>
</details>
</dd>
<dt id="pySRURGS.generate_benchmarks_SRconfigs"><code class="name flex">
<span>def <span class="ident">generate_benchmarks_SRconfigs</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates two SymbolicRegressionConfig objects for the generation of 100
randomly generated symbolic regression problems.
First SRconfig is simpler than the second in that the second permits
functions of arity one.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>tuple</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>(SR_config1, SR_config2)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_benchmarks_SRconfigs():
    &#39;&#39;&#39;
    Generates two SymbolicRegressionConfig objects for the generation of 100
    randomly generated symbolic regression problems.
    First SRconfig is simpler than the second in that the second permits
    functions of arity one.

    Parameters
    ----------
    None

    Returns
    -------
    result: tuple
      (SR_config1, SR_config2)      
    &#39;&#39;&#39;
    SR_config1 = SymbolicRegressionConfig(path_to_toy_csv, 
                                          None,
                                          n_functions=[&#39;add&#39;, &#39;sub&#39;, &#39;mul&#39;, 
                                                       &#39;div&#39;],
                                          f_functions=[],
                                          max_num_fit_params=5,
                                          max_permitted_trees=200)
    SR_config2 = SymbolicRegressionConfig(path_to_toy_csv, 
                                          None,
                                          n_functions=[&#39;add&#39;, &#39;sub&#39;, &#39;mul&#39;, 
                                                       &#39;div&#39;, &#39;pow&#39;], 
                                          f_functions=[&#39;sin&#39;, &#39;sinh&#39;, &#39;log&#39;], 
                                          max_num_fit_params=5, 
                                          max_permitted_trees=200)
    result = (SR_config1, SR_config2)
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_bits"><code class="name flex">
<span>def <span class="ident">get_bits</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_cum_weights_binary_tree"><code class="name flex">
<span>def <span class="ident">get_cum_weights_binary_tree</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_cum_weights_full_binary_tree"><code class="name flex">
<span>def <span class="ident">get_cum_weights_full_binary_tree</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_element_of_cartesian_product"><code class="name flex">
<span>def <span class="ident">get_element_of_cartesian_product</span></span>(<span>*args, repeat=1, index=0)</span>
</code></dt>
<dd>
<section class="desc"><p>Access a specific element of a cartesian product, without needing to iterate
through the entire product.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>args</code></strong> :&ensp;<code>iterable</code></dt>
<dd>A set of iterables whose cartesian product is being accessed</dd>
<dt><strong><code>repeat</code></strong> :&ensp;<code>int</code></dt>
<dd>If <code>args</code> is only one object, <code>repeat</code> specifies the number of times
to take the cartesian product with itself.</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>The index of the cartesian product which we want to access</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ith_item</code></strong> :&ensp;<code>the</code> <code>`index```th</code> <code>element</code> of <code>the</code> <code>cartesian</code> <code>product</code></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_element_of_cartesian_product(*args, repeat=1, index=0):
    &#34;&#34;&#34;
    Access a specific element of a cartesian product, without needing to iterate
    through the entire product.

    Parameters
    ----------
    args: iterable
        A set of iterables whose cartesian product is being accessed

    repeat: int
        If `args` is only one object, `repeat` specifies the number of times
        to take the cartesian product with itself.

    index: int
        The index of the cartesian product which we want to access

    Returns
    -------
    ith_item: the `index`th element of the cartesian product
    &#34;&#34;&#34;
    pools = [tuple(pool) for pool in args] * repeat
    if len(pools) == 0:
        return []
    len_product = len(pools[0])
    len_pools = len(pools)
    for j in range(1, len_pools):
        len_product = len_product * len(pools[j])
    if index &gt;= len_product:
        raise Exception(&#34;index + 1 is bigger than the length of the product&#34;)
    index_list = []
    for j in range(0, len_pools):
        ith_pool_index = index
        denom = 1
        for k in range(j + 1, len_pools):
            denom = denom * len(pools[k])
        ith_pool_index = ith_pool_index // denom
        if j != 0:
            ith_pool_index = ith_pool_index % len(pools[j])
        index_list.append(ith_pool_index)
    ith_item = []
    for index in range(0, len_pools):
        ith_item.append(pools[index][index_list[index]])
    return ith_item</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_left_right_bits"><code class="name flex">
<span>def <span class="ident">get_left_right_bits</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_properties"><code class="name flex">
<span>def <span class="ident">get_properties</span></span>(<span>dataframe, label)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns a dictionary of statistical data around the data found in
<code>dataframe[label]</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataframe</code></strong> :&ensp;<code>pandas.DataFrame</code> <code>object</code></dt>
<dd>&nbsp;</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>a</code> <code>column</code> <code>name</code> <code>within</code> <code>dataframe</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>properties</code></strong> :&ensp;<code>dictionary</code></dt>
<dd>A dictionary containing the mean, standard deviation, min, and max of
the column.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_properties(dataframe, label):
    &#34;&#34;&#34;
    Returns a dictionary of statistical data around the data found in
    `dataframe[label]`

    Parameters
    ----------
    dataframe : pandas.DataFrame object

    label: a column name within `dataframe`

    Returns
    -------
    properties: dictionary
        A dictionary containing the mean, standard deviation, min, and max of
        the column.
    &#34;&#34;&#34;
    properties = dict()
    properties[label + &#39;_mean&#39;] = dataframe.mean()
    properties[label + &#39;_std&#39;] = dataframe.std()
    properties[label + &#39;_min&#39;] = dataframe.min()
    properties[label + &#39;_max&#39;] = dataframe.max()
    return properties</code></pre>
</details>
</dd>
<dt id="pySRURGS.get_resultlist"><code class="name flex">
<span>def <span class="ident">get_resultlist</span></span>(<span>path_to_db)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads the ResultList of a previous run of pySRURGS.
Skips the <code>best_result</code> key. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path_to_db</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to the SqliteDict database file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result_list</code></strong> :&ensp;<a title="pySRURGS.ResultList" href="#pySRURGS.ResultList"><code>ResultList</code></a></dt>
<dd>An unsorted ResultList object for the previously run problem</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_resultlist(path_to_db):
    &#39;&#39;&#39;
    Loads the ResultList of a previous run of pySRURGS.
    Skips the `best_result` key. 

    Parameters
    ----------
    path_to_db: string
        An absolute or relative path to the SqliteDict database file.

    Returns
    -------
    result_list: pySRURGS.ResultList
        An unsorted ResultList object for the previously run problem
    &#39;&#39;&#39;
    result_list = ResultList()
    with SqliteDict(path_to_db) as results_dict:
        keys = results_dict.keys()        
        for eqn in keys:
            if eqn == &#39;best_result&#39;:
                continue
            result = results_dict[eqn]
            result_list._results.append(result)
    return result_list</code></pre>
</details>
</dd>
<dt id="pySRURGS.has_nans"><code class="name flex">
<span>def <span class="ident">has_nans</span></span>(<span>X)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def has_nans(X):
    if np.any(np.isnan(X)):
        return True
    else:
        return False</code></pre>
</details>
</dd>
<dt id="pySRURGS.initialize_db"><code class="name flex">
<span>def <span class="ident">initialize_db</span></span>(<span>path_to_db)</span>
</code></dt>
<dd>
<section class="desc"><p>Initializes the SqliteDict database file with an initial null value
for the 'best_result' key</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def initialize_db(path_to_db):
    &#39;&#39;&#39;
        Initializes the SqliteDict database file with an initial null value
        for the &#39;best_result&#39; key
    &#39;&#39;&#39;
    with SqliteDict(path_to_db, autocommit=True) as results_dict:
        try:
            results_dict[&#39;best_result&#39;]
        except KeyError:
            results_dict[&#39;best_result&#39;] = Result(
                None, None, np.inf, None, None)
    return</code></pre>
</details>
</dd>
<dt id="pySRURGS.is_csv_valid"><code class="name flex">
<span>def <span class="ident">is_csv_valid</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def is_csv_valid(filepath):
    try:
        with open(filepath, &#39;r&#39;) as csv_file:               
            dialect = csv.Sniffer().sniff(csv_file.read(1024))
    except Exception as e:
        print(&#34;Error encountering while reading: &#34;, filepath)
        print(e)
        exit(2)</code></pre>
</details>
</dd>
<dt id="pySRURGS.ith_binary_tree"><code class="name flex">
<span>def <span class="ident">ith_binary_tree</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.ith_full_binary_tree"><code class="name flex">
<span>def <span class="ident">ith_full_binary_tree</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.make_parameter_name"><code class="name flex">
<span>def <span class="ident">make_parameter_name</span></span>(<span>par)</span>
</code></dt>
<dd>
<section class="desc"><p>Converts a fitting parameter name to pySRURGS safe parameter name. Prevents
string manipulations on parameter names from affecting function names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>par</code></strong> :&ensp;<code>string</code></dt>
<dd>A variable name.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>par_name</code></strong> :&ensp;<code>string</code></dt>
<dd><code>par</code> wrapped in the pySRURGS parameter prefix and suffix.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_parameter_name(par):
    &#34;&#34;&#34;
    Converts a fitting parameter name to pySRURGS safe parameter name. Prevents
    string manipulations on parameter names from affecting function names.

    Parameters
    ----------
    par : string
        A variable name.

    Returns
    -------
    par_name: string
        `par` wrapped in the pySRURGS parameter prefix and suffix.
    &#34;&#34;&#34;
    par_name = fitting_param_prefix + str(par) + fitting_param_suffix
    return par_name</code></pre>
</details>
</dd>
<dt id="pySRURGS.make_variable_name"><code class="name flex">
<span>def <span class="ident">make_variable_name</span></span>(<span>var)</span>
</code></dt>
<dd>
<section class="desc"><p>Converts a variable name to pySRURGS safe variable names. Prevents string
manipulations on variable names from affecting function names.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>var</code></strong> :&ensp;<code>string</code></dt>
<dd>A variable name.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>var_name</code></strong> :&ensp;<code>string</code></dt>
<dd><code>var</code> wrapped in the pySRURGS variable prefix and suffix.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_variable_name(var):
    &#34;&#34;&#34;
    Converts a variable name to pySRURGS safe variable names. Prevents string
    manipulations on variable names from affecting function names.

    Parameters
    ----------
    var : string
        A variable name.

    Returns
    -------
    var_name: string
        `var` wrapped in the pySRURGS variable prefix and suffix.
    &#34;&#34;&#34;
    var_name = variable_prefix + str(var) + variable_suffix
    return var_name</code></pre>
</details>
</dd>
<dt id="pySRURGS.memoize"><code class="name flex">
<span>def <span class="ident">memoize</span></span>(<span>func)</span>
</code></dt>
<dd>
<section class="desc"><p>A memoize function that wraps other functions. Improves CPU performance at
the cost of increased memory requirements.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>function</code></dt>
<dd>Will memoize the <code>func</code> provided <code>func</code> is deterministic in its outputs.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>memoized_func</code></strong> :&ensp;<code>function</code></dt>
<dd>A memoized wrapper around <code>func</code></dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoize(func):
    &#34;&#34;&#34;
    A memoize function that wraps other functions. Improves CPU performance at
    the cost of increased memory requirements.

    Parameters
    ----------
    func : function
        Will memoize the `func` provided `func` is deterministic in its outputs.

    Returns
    -------
    memoized_func: function
        A memoized wrapper around `func`
    &#34;&#34;&#34;
    cache = dict()

    def memoized_func(*args):
        if args in cache and memoize_funcs:
            return cache[args]
        result = func(*args)
        cache[args] = result
        return result
    return memoized_func</code></pre>
</details>
</dd>
<dt id="pySRURGS.mempower"><code class="name flex">
<span>def <span class="ident">mempower</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.plot_results"><code class="name flex">
<span>def <span class="ident">plot_results</span></span>(<span>SRconfig, output_dir='./image/')</span>
</code></dt>
<dd>
<section class="desc"><p>Reads the generated SqliteDict file to determine the best model,
then plots it against the raw data. saves the figure to './image/plot.png'
and './image/plot.svg'. Only works for univariate data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>SRconfig</code></strong> :&ensp;<code>pySRUGS.SymbolicRegressionConfig</code></dt>
<dd>The symbolic regression problem's configuration object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="raises">Raises</h2>
<p>Exception, if data is not univariate.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_results(SRconfig, output_dir=&#39;./image/&#39;):
    &#39;&#39;&#39;
    Reads the generated SqliteDict file to determine the best model,
    then plots it against the raw data. saves the figure to &#39;./image/plot.png&#39;
    and &#39;./image/plot.svg&#39;. Only works for univariate data.

    Parameters
    ----------
    SRconfig: pySRUGS.SymbolicRegressionConfig
        The symbolic regression problem&#39;s configuration object

    Returns
    -------
    None

    Raises
    ------
    Exception, if data is not univariate.

    &#39;&#39;&#39;
    path_to_csv = SRconfig._path_to_csv
    path_to_db = SRconfig._path_to_db
    dataset = SRconfig._dataset
    result_list = get_resultlist(path_to_db)
    result_list.sort()
    best_model = result_list._results[0]
    param_values = best_model._params
    equation_string = best_model._equation
    num_params = len(param_values)
    params_obj = create_fitting_parameters(num_params,
                                           param_values=param_values)
    evaluatable_equation_string = equation_string
    eval_eqn_string = clean_funcstring(equation_string)
    plt.figure(figsize=(3.14, 2))
    if len(dataset._x_labels) == 1:
        data_dict = dict()
        xlabel = dataset._x_labels[0]
        data_dict[xlabel] = np.linspace(np.min(dataset._x_data),
                                        np.max(dataset._x_data))
        y_calc = eval_equation(params_obj, eval_eqn_string, SRconfig, 
                               mode=data_dict)
        plt.plot(data_dict[xlabel], y_calc, &#39;b-&#39;,
                 label=dataset._y_label + &#39; calculated&#39;)
        plt.plot(dataset._x_data, dataset._y_data, &#39;ro&#39;,
                 label=dataset._y_label + &#39; original data&#39;)
        plt.ylabel(dataset._y_label)
        plt.xlabel(dataset._x_labels[0])
    else:
        xlabel = &#39;y_predicted&#39;
        ylabel = &#39;y_observed&#39;
        y_pred = eval_equation(params_obj, eval_eqn_string, SRconfig)
        y_calc = y_pred / dataset._y_data
        plt.plot(dataset._y_data, y_calc, &#39;bo&#39;,
                 label=&#34;Prediction Error&#34;)
        plt.ylabel(ylabel)
        plt.xlabel(xlabel)
    plt.legend()
    plt.tight_layout()
    output_files = [&#39;plot.eps&#39;, &#39;plot.svg&#39;, &#39;plot.png&#39;]
    for img in output_files:
        output_path = os.path.join(output_dir, img)
        if os.path.isfile(output_path):
            os.remove(output_path)   
        plt.savefig(output_path)</code></pre>
</details>
</dd>
<dt id="pySRURGS.random_equation_binary_tree"><code class="name flex">
<span>def <span class="ident">random_equation_binary_tree</span></span>(<span>N, cum_weights, enumerator, SRconfig, details=False, i=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random equation string. Generating the random numbers which
specify the equation, then passes those as arguments to equation_generator.
Use <a title="pySRURGS.random_equation_full_binary_tree" href="#pySRURGS.random_equation_full_binary_tree"><code>random_equation_full_binary_tree()</code></a> instead when there are no functions
of arity one permitted.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the number of unique binary trees permitted in our search. The
search considers trees mapping from the integer domain [0 &hellip; <code>N</code>-1].</dd>
<dt><strong><code>cum_weights</code></strong> :&ensp;<code>array</code> <code>like</code></dt>
<dd>Specifies the probability that an integer in [0 &hellip; <code>N</code>-1] will be
randomly selected. Should add to 1. pySRURGS gives preference to larger
values of <code>N</code> because they result in more possible equations and we want
to give each equation uniform probability of selection.</dd>
<dt><strong><code>enumerator</code></strong> :&ensp;<code>pySRURGS.Enumerator</code></dt>
<dd>The <a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a> object for the symbolic regression
problem</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The <a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a> for the symbolic regression problem</dd>
<dt><strong><code>details</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>Determines the output type</dd>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code> (default: <code>None</code>)</dt>
<dd>If not none, specifies which binary tree to use</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>if <code>details</code> == False:
equation_string: string
A randomly generated pySRURGS equation string
if <code>details</code> == True:
[equation_string, N, n, f, m, i, q, r, s]</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_equation_binary_tree(N, cum_weights, enumerator, SRconfig,
                                details=False, i=None):
    &#34;&#34;&#34;
    Generates a random equation string. Generating the random numbers which
    specify the equation, then passes those as arguments to equation_generator.
    Use `random_equation_full_binary_tree` instead when there are no functions 
    of arity one permitted.

    Parameters
    ----------
    N: int
        Specifies the number of unique binary trees permitted in our search. The
        search considers trees mapping from the integer domain [0 ... `N`-1].

    cum_weights: array like
        Specifies the probability that an integer in [0 ... `N`-1] will be
        randomly selected. Should add to 1. pySRURGS gives preference to larger
        values of `N` because they result in more possible equations and we want
        to give each equation uniform probability of selection.

    enumerator: pySRURGS.Enumerator
        The `EnumeratorFullBinaryTree` object for the symbolic regression 
        problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` for the symbolic regression problem

    details: Boolean
        Determines the output type
        
    i: int (default: None)
        If not none, specifies which binary tree to use

    Returns
    -------
    if `details` == False:
        equation_string: string
            A randomly generated pySRURGS equation string
    if `details` == True:
        [equation_string, N, n, f, m, i, q, r, s]
    &#34;&#34;&#34;
    dataset = SRconfig._dataset
    n = len(SRconfig._n_functions) # number of functions of arity 2
    f = len(SRconfig._f_functions) # number of functions of arity 1
    m = dataset._m_terminals # number of different terminals    
    if i is None:
        i = randgen.choice(range(0, N), p=cum_weights)
    q = enumerator.get_q(f, i) # get the q^th configuration of arity 1 functions
    r = enumerator.get_r(n, i) # get the r^th configuration of arity 2 functions
    s = enumerator.get_s(m, i) # get the s^th configuration of terminals
    equation_string = equation_generator_binary_tree(i, q, r, s, enumerator, 
                                                     SRconfig)
    if not details:
        return equation_string
    else:
        result = [equation_string, N, n, f, m, i, q, r, s]
        return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.random_equation_full_binary_tree"><code class="name flex">
<span>def <span class="ident">random_equation_full_binary_tree</span></span>(<span>N, cum_weights, enumerator, SRconfig, details=False, i=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random equation string. Generating the random numbers which
specify the equation, then passes those as arguments to equation_generator.
Use <a title="pySRURGS.random_equation_binary_tree" href="#pySRURGS.random_equation_binary_tree"><code>random_equation_binary_tree()</code></a> instead when there are functions of arity
one permitted.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code></dt>
<dd>Specifies the number of unique binary trees permitted in our search. The
search considers trees mapping from the integer domain [0 &hellip; <code>N</code>-1].</dd>
<dt><strong><code>cum_weights</code></strong> :&ensp;<code>array</code> <code>like</code></dt>
<dd>Specifies the probability that an integer in [0 &hellip; <code>N</code>-1] will be
randomly selected. Should add to 1. pySRURGS gives preference to larger
values of <code>N</code> because they result in more possible equations and we want
to give each equation uniform probability of selection.</dd>
<dt><strong><code>enumerator</code></strong> :&ensp;<a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a></dt>
<dd>The <a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a> object for the symbolic regression
problem</dd>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The <a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a> object for the symbolic regression
problem</dd>
<dt><strong><code>details</code></strong> :&ensp;<code>Boolean</code></dt>
<dd>Determines the output type</dd>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code> (default: <code>None</code>)</dt>
<dd>If not none, specifies which full binary tree to use</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>if <code>details</code> == False:
equation_string: string
A randomly generated pySRURGS equation string
if <code>details</code> == True:
[equation_string, N, n, m, i, q, r, s]</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def random_equation_full_binary_tree(N, cum_weights, enumerator, 
                                     SRconfig, details=False, i=None):
    &#34;&#34;&#34;
    Generates a random equation string. Generating the random numbers which
    specify the equation, then passes those as arguments to equation_generator.
    Use `random_equation_binary_tree` instead when there are functions of arity 
    one permitted.

    Parameters
    ----------
    N: int
        Specifies the number of unique binary trees permitted in our search. The
        search considers trees mapping from the integer domain [0 ... `N`-1].

    cum_weights: array like
        Specifies the probability that an integer in [0 ... `N`-1] will be
        randomly selected. Should add to 1. pySRURGS gives preference to larger
        values of `N` because they result in more possible equations and we want
        to give each equation uniform probability of selection.

    enumerator: pySRURGS.EnumeratorFullBinaryTree
        The `EnumeratorFullBinaryTree` object for the symbolic regression 
        problem

    SRconfig: pySRURGS.SymbolicRegressionConfig
        The `SymbolicRegressionConfig` object for the symbolic regression 
        problem

    details: Boolean
        Determines the output type

    i: int (default: None)
        If not none, specifies which full binary tree to use

    Returns
    -------
    if `details` == False:
        equation_string: string
            A randomly generated pySRURGS equation string
    if `details` == True:
        [equation_string, N, n, m, i, q, r, s]
    &#34;&#34;&#34;
    dataset = SRconfig._dataset
    n = len(SRconfig._n_functions) # number of functions of arity 2
    m = dataset._m_terminals # number of different terminals    
    if i is None:
        i = randgen.choice(range(0, N), p=cum_weights)
    r = enumerator.get_r(n, i) # get the r^th configuration of arity 2 functions
    s = enumerator.get_s(m, i) # get the s^th configuration of terminals
    equation_string = equation_generator_full_binary_tree(i, r, s, enumerator, 
                                                          SRconfig)
    if not details:
        return equation_string
    else:
        result = [equation_string, N, n, m, i, r, s]
        return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.read_benchmarks"><code class="name flex">
<span>def <span class="ident">read_benchmarks</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Reads the benchmark problems and generates a summary tab separated value
file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Benchmark problems' summary is saved in <code>benchmarks_summary_tsv</code> filepath
<code>benchmarks_summary_tsv</code> is a global variable.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_benchmarks():
    &#39;&#39;&#39;
    Reads the benchmark problems and generates a summary tab separated value 
    file.

    Parameters
    ----------
    None

    Returns
    -------
    None

    Notes
    ------
    Benchmark problems&#39; summary is saved in `benchmarks_summary_tsv` filepath
    `benchmarks_summary_tsv` is a global variable.
    &#39;&#39;&#39;
    with open(benchmarks_summary_tsv, &#39;w&#39;) as benchmarks_file:
        wrtr = csv.writer(benchmarks_file, delimiter=&#39;\t&#39;, lineterminator=&#39;\n&#39;)
        for i in range(0, 100):
            param_file = benchmarks_dir + &#39;/&#39; + str(i) + &#39;_params.txt&#39;
            with open(param_file) as pfile:
                param_file_lines = pfile.readlines()
                for line in param_file_lines:
                    if &#39;Simplified equation:&#39; in line:
                        true_equation = line.replace(
                            &#39;Simplified equation: &#39;, &#39;&#39;).strip()
                        true_equation = true_equation.replace(&#39; &#39;, &#39;&#39;)
                    if &#39;Raw equation:&#39; in line:
                        raw_equation = line.replace(
                            &#39;Raw equation: &#39;, &#39;&#39;).strip()
                        raw_equation = raw_equation.replace(&#39;&#34;&#39;, &#39;&#39;)
                        raw_equation = raw_equation.replace(&#39; &#39;, &#39;&#39;)
                row = [i, true_equation, raw_equation]
                wrtr.writerow(row)</code></pre>
</details>
</dd>
<dt id="pySRURGS.remove_dict_tags"><code class="name flex">
<span>def <span class="ident">remove_dict_tags</span></span>(<span>equation_string)</span>
</code></dt>
<dd>
<section class="desc"><p>Prior to numerically evaluating an equation string, we replace the variable
and fitting parameter suffix/prefix with code to access values housed in
dictionaries. This function removes that dictionary code from the equation
string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string just prior to being numerically
evaluated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd><code>equation_string</code> without dictionary access formatting.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_dict_tags(equation_string):
    &#34;&#34;&#34;
    Prior to numerically evaluating an equation string, we replace the variable
    and fitting parameter suffix/prefix with code to access values housed in
    dictionaries. This function removes that dictionary code from the equation
    string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string just prior to being numerically
        evaluated.

    Returns
    -------
    equation_string: string
        `equation_string` without dictionary access formatting.
    &#34;&#34;&#34;
    equation_string = equation_string.replace(&#39;df[&#34;&#39;, &#39;&#39;)
    equation_string = equation_string.replace(&#39;params[&#34;&#39;, &#39;&#39;)
    equation_string = equation_string.replace(&#39;&#34;].value&#39;, &#39;&#39;)
    equation_string = equation_string.replace(&#39;&#34;]&#39;, &#39;&#39;)
    return equation_string</code></pre>
</details>
</dd>
<dt id="pySRURGS.remove_parameter_tags"><code class="name flex">
<span>def <span class="ident">remove_parameter_tags</span></span>(<span>equation_string)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes the pySRURGS fitting parameter prefix/suffix from an equation
string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd><code>equation_string</code> with the fitting parameter prefix and suffix removed.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_parameter_tags(equation_string):
    &#34;&#34;&#34;
    Removes the pySRURGS fitting parameter prefix/suffix from an equation 
    string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string

    Returns
    -------
    equation_string: string
        `equation_string` with the fitting parameter prefix and suffix removed.
    &#34;&#34;&#34;
    equation_string = equation_string.replace(fitting_param_prefix, &#39;&#39;)
    equation_string = equation_string.replace(fitting_param_suffix, &#39;&#39;)
    return equation_string</code></pre>
</details>
</dd>
<dt id="pySRURGS.remove_tags"><code class="name flex">
<span>def <span class="ident">remove_tags</span></span>(<span>equation_string)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes the pySRURGS variable and fitting parameter prefix/suffix from an
equation string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd><code>equation_string</code> with the variable and fitting parameter prefixes and
suffixes removed.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_tags(equation_string):
    &#34;&#34;&#34;
    Removes the pySRURGS variable and fitting parameter prefix/suffix from an
    equation string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string

    Returns
    -------
    equation_string: string
        `equation_string` with the variable and fitting parameter prefixes and
        suffixes removed.
    &#34;&#34;&#34;
    equation_string = remove_parameter_tags(equation_string)
    equation_string = remove_variable_tags(equation_string)
    return equation_string</code></pre>
</details>
</dd>
<dt id="pySRURGS.remove_variable_tags"><code class="name flex">
<span>def <span class="ident">remove_variable_tags</span></span>(<span>equation_string)</span>
</code></dt>
<dd>
<section class="desc"><p>Removes the pySRURGS variable prefix/suffix from an equation string.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd>A pySRURGS generated equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>equation_string</code></strong> :&ensp;<code>string</code></dt>
<dd><code>equation_string</code> with the variable prefix and suffix removed.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_variable_tags(equation_string):
    &#34;&#34;&#34;
    Removes the pySRURGS variable prefix/suffix from an equation string.

    Parameters
    ----------
    equation_string : string
        A pySRURGS generated equation string

    Returns
    -------
    equation_string: string
        `equation_string` with the variable prefix and suffix removed.
    &#34;&#34;&#34;
    equation_string = equation_string.replace(variable_prefix, &#39;&#39;)
    equation_string = equation_string.replace(variable_suffix, &#39;&#39;)
    return equation_string</code></pre>
</details>
</dd>
<dt id="pySRURGS.setup"><code class="name flex">
<span>def <span class="ident">setup</span></span>(<span>SR_config)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns the values stored in SR_config for use in the algorithm</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>SR_config</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression configuration object for this problem</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>tuple</code></dt>
<dd>(f, n, m, cum_weights, N, dataset, enumerator, n_funcs, f_funcs)</dd>
</dl>
<h2 id="notes">Notes</h2>
<dl>
<dt><strong><code>f</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of functions of arity one in the problem</dd>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of functions of arity two in the problem</dd>
<dt><strong><code>cum_weights</code></strong> :&ensp;<code>array</code> <code>like</code></dt>
<dd>The relative weight of selecting the binary trees from 0 to N-1,
calculated to ensure equal probabilty of selecting each equation.</dd>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of unique binary trees permitted in the search. Same as
<code>max_permitted_trees</code>.</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<a title="pySRURGS.Dataset" href="#pySRURGS.Dataset"><code>Dataset</code></a></dt>
<dd>The dataset object for the problem.</dd>
<dt><strong><code>enumerator</code></strong> :&ensp;<a title="pySRURGS.EnumeratorBinaryTree" href="#pySRURGS.EnumeratorBinaryTree"><code>EnumeratorBinaryTree</code></a> <code>OR</code></dt>
<dd>pySRURGS.EnumeratorFullBinaryTree (if <code>f_funcs</code> == 0)</dd>
<dt><strong><code>n_funcs</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of strings of the functions of arity two permitted in this search</dd>
<dt><strong><code>f_funcs</code></strong> :&ensp;<code>list</code></dt>
<dd>A list of strings of the functions of arity one permitted in this search</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup(SR_config):
    &#34;&#34;&#34;
    Returns the values stored in SR_config for use in the algorithm
        
    Parameters
    ----------

    SR_config: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    Returns
    -------
    result: tuple
        (f, n, m, cum_weights, N, dataset, enumerator, n_funcs, f_funcs)


    Notes
    -----
    f : int
        The number of functions of arity one in the problem

    n: int
        The number of functions of arity two in the problem

    cum_weights: array like
        The relative weight of selecting the binary trees from 0 to N-1, 
        calculated to ensure equal probabilty of selecting each equation.

    N: int
        The number of unique binary trees permitted in the search. Same as
        `max_permitted_trees`.

    dataset: pySRURGS.Dataset
        The dataset object for the problem.

    enumerator: pySRURGS.EnumeratorBinaryTree OR 
                pySRURGS.EnumeratorFullBinaryTree (if `f_funcs` == 0)

    n_funcs: list
        A list of strings of the functions of arity two permitted in this search

    f_funcs: list
        A list of strings of the functions of arity one permitted in this search
    &#34;&#34;&#34;
    # reads the configuration, the csv file, and creates needed objects
    N = SR_config._max_permitted_trees
    n = len(SR_config._n_functions)  # the number of functions of arity 2
    n_funcs = SR_config._n_functions
    f_funcs = SR_config._f_functions
    f = len(SR_config._f_functions)  # the number of functions of arity 1
    num_fit_param = SR_config._max_num_fit_params
    dataset = SR_config._dataset
    m = dataset._m_terminals  # the number of vars + number of fit params
    if f == 0:
        enumerator = EnumeratorFullBinaryTree()
        cum_weights = get_cum_weights_full_binary_tree(N, n, m, enumerator)
    else:
        enumerator = EnumeratorBinaryTree()
        cum_weights = get_cum_weights_binary_tree(N, f, n, m, enumerator)
    return (f, n, m, cum_weights, N, dataset, enumerator, n_funcs, f_funcs)</code></pre>
</details>
</dd>
<dt id="pySRURGS.simplify_equation_string"><code class="name flex">
<span>def <span class="ident">simplify_equation_string</span></span>(<span>eqn_str, dataset)</span>
</code></dt>
<dd>
<section class="desc"><p>Simplify a pySRURGS equation string into a more human readable format</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>eqn_str</code></strong> :&ensp;<code>string</code></dt>
<dd>pySRURGS equation string</dd>
<dt><strong><code>dataset</code></strong> :&ensp;<a title="pySRURGS.Dataset" href="#pySRURGS.Dataset"><code>Dataset</code></a></dt>
<dd>The dataset object used to generate the <code>eqn_str</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>eqn_str</code></strong> :&ensp;<code>string</code></dt>
<dd>A simpler, more human readable version of <code>eqn_str</code></dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Uses sympy to perform simplification. The dataset object specifies the sympy
namespace.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simplify_equation_string(eqn_str, dataset):
    &#34;&#34;&#34;
    Simplify a pySRURGS equation string into a more human readable format

    Parameters
    ----------
    eqn_str: string
        pySRURGS equation string

    dataset: pySRURGS.Dataset
        The dataset object used to generate the `eqn_str`

    Returns
    -------
    eqn_str: string
        A simpler, more human readable version of `eqn_str`

    Notes
    -------
    Uses sympy to perform simplification. The dataset object specifies the sympy
    namespace.
    &#34;&#34;&#34;
    dataset._sympy_namespace = dataset.make_sympy_namespace()
    s = sympy.sympify(eqn_str, locals=dataset._sympy_namespace)
    try:
        eqn_str = str(sympy.simplify(s))
    except ValueError:
        pass
    if &#39;zoo&#39; in eqn_str:  # zoo (complex infinity) in sympy
        raise FloatingPointError
    eqn_str = remove_variable_tags(eqn_str)
    eqn_str = remove_parameter_tags(eqn_str)
    return eqn_str</code></pre>
</details>
</dd>
<dt id="pySRURGS.solution_saving_worker"><code class="name flex">
<span>def <span class="ident">solution_saving_worker</span></span>(<span>queue, n_items, output_db)</span>
</code></dt>
<dd>
<section class="desc"><p>Takes solutions from the queue of evaluated solutions,
then saves them to the database.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def solution_saving_worker(queue, n_items, output_db):
    &#34;&#34;&#34;
        Takes solutions from the queue of evaluated solutions, 
        then saves them to the database.
    &#34;&#34;&#34;
    checkpoint = int(n_items/100) + 1
    with SqliteDict(output_db, autocommit=False) as results_dict:
        for j in range(0, n_items):
            result = queue.get()
            simple_eqn = result._simple_equation
            results_dict[simple_eqn] = result
            if j == checkpoint:
                print(&#39;  Saving results to db: &#39; + str(j/n_items))
                results_dict.commit()
        results_dict.commit()    </code></pre>
</details>
</dd>
<dt id="pySRURGS.uniform_random_global_search_once"><code class="name flex">
<span>def <span class="ident">uniform_random_global_search_once</span></span>(<span>seed, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs pySRURGS once against the CSV file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>SRconfig</code></strong> :&ensp;<a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig"><code>SymbolicRegressionConfig</code></a></dt>
<dd>The symbolic regression configuration object for this problem</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code> (or <code>None</code>)</dt>
<dd>Sets the seed of the pseudorandom number generator. Will make results
reproducible if not None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>y_calc</code></strong> :&ensp;<code>array</code> <code>like</code></dt>
<dd>The predicted values of the dependent variable</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def uniform_random_global_search_once(seed, SRconfig):
    &#34;&#34;&#34;
    Runs pySRURGS once against the CSV file

    Parameters
    ----------
    SRconfig: pySRURGS.SymbolicRegressionConfig
        The symbolic regression configuration object for this problem

    seed: int (or None)
        Sets the seed of the pseudorandom number generator. Will make results
        reproducible if not None.

    Returns
    -------
    y_calc: array like
        The predicted values of the dependent variable

    &#34;&#34;&#34;    
    (f, n, m, cum_weights, N, dataset, enumerator, _, _) = setup(SRconfig)
    valid = False
    if seed is not None:
        randgen.seed(seed)
    while valid == False:
        if f == 0:
            eqn_str = random_equation_full_binary_tree(N, cum_weights, 
                                                       enumerator, SRconfig)
        else:
            eqn_str = random_equation_binary_tree(N, cum_weights, enumerator, 
                                                  SRconfig)
        try:
            simple_eqn = simplify_equation_string(eqn_str, dataset)
            path_to_db = SRconfig._path_to_db
            initialize_db(path_to_db)
            params = create_fitting_parameters(dataset._int_max_params)
            (sum_of_squared_residuals, sum_of_squared_totals,
             R2, params_fitted,
             residual) = check_goodness_of_fit(eqn_str, params, SRconfig)
            if np.isnan(R2) or np.isnan(sum_of_squared_totals):
                raise FloatingPointError
            valid = True
        except FloatingPointError:
            pass
    MSE = sum_of_squared_residuals
    result = Result(simple_eqn, eqn_str, MSE, R2, params_fitted)
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.uniform_random_global_search_once_to_db"><code class="name flex">
<span>def <span class="ident">uniform_random_global_search_once_to_db</span></span>(<span>seed, SRconfig)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs uniform random global search once, then takes the result and saves
it immediately to the database</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def uniform_random_global_search_once_to_db(seed, SRconfig):
    &#39;&#39;&#39;
        Runs uniform random global search once, then takes the result and saves 
        it immediately to the database
    &#39;&#39;&#39;
    result = uniform_random_global_search_once(seed, SRconfig)
    path_to_db = SRconfig._path_to_db
    with SqliteDict(SRconfig._path_to_db, autocommit=False) as results_dict:
        simple_eqn = result._simple_equation
        results_dict[simple_eqn] = result
        results_dict.commit()    </code></pre>
</details>
</dd>
<dt id="pySRURGS.uniform_random_global_search_once_to_queue"><code class="name flex">
<span>def <span class="ident">uniform_random_global_search_once_to_queue</span></span>(<span>seed, SRconfig, queue)</span>
</code></dt>
<dd>
<section class="desc"><p>Runs uniform random global search once, then takes the result and puts
it in a queue so that it can be committed in a multiprocessing safe
fashion</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def uniform_random_global_search_once_to_queue(seed, SRconfig, queue):
    &#39;&#39;&#39;
        Runs uniform random global search once, then takes the result and puts 
        it in a queue so that it can be committed in a multiprocessing safe 
        fashion
    &#39;&#39;&#39;
    result = uniform_random_global_search_once(seed, SRconfig)
    queue.put(result)    </code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pySRURGS.Dataset"><code class="flex name class">
<span>class <span class="ident">Dataset</span></span>
<span>(</span><span>path_to_csv_file, int_max_params=3, path_to_weights=None)</span>
</code></dt>
<dd>
<section class="desc"><p>An object used to store the dataset of this symbolic regression
problem.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path_to_csv_file</code></strong> :&ensp;<code>string</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>Absolute or relative path to the CSV file for the numerical data. The
rightmost column of the CSV file should be the dependent variable.
The CSV file should have a header of column names and should NOT
have a leftmost index column.</p>
<dl>
<dt><strong><code>int_max_params</code></strong> :&ensp;<code>int</code></dt>
<dd>The maximum number of fitting parameters specified in the symbolic
regression problem. Same as <code>max_num_fit_params</code>.</dd>
<dt><strong><code>path_to_weights</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to the CSV for weights of the data points
in the CSV found in <code>path_to_csv</code>. If <code>None</code>, will assume all data
points are equally weighted.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>A pySRURGS.Dataset object, which houses a variety of attributes
including the numerical data, the sympy namespace, the data dict used in
evaluating the equation string, etc.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Dataset(object):
    &#34;&#34;&#34;
    An object used to store the dataset of this symbolic regression
    problem.

    Parameters
    ----------
    path_to_csv_file: string
       Absolute or relative path to the CSV file for the numerical data. The
       rightmost column of the CSV file should be the dependent variable.
       The CSV file should have a header of column names and should NOT
       have a leftmost index column.

    int_max_params: int
        The maximum number of fitting parameters specified in the symbolic
        regression problem. Same as `max_num_fit_params`.

    path_to_weights: string 
        An absolute or relative path to the CSV for weights of the data points 
        in the CSV found in `path_to_csv`. If `None`, will assume all data 
        points are equally weighted.

    Returns
    -------
    self
        A pySRURGS.Dataset object, which houses a variety of attributes 
        including the numerical data, the sympy namespace, the data dict used in 
        evaluating the equation string, etc.
    &#34;&#34;&#34;

    def __init__(self, 
                 path_to_csv_file, 
                 int_max_params=defaults_dict[&#39;max_num_fit_params&#39;], 
                 path_to_weights=None):
        (dataframe, header_labels) = self.load_csv_data(path_to_csv_file)
        if path_to_weights is not None:
            (weights_df, empty_labels) = self.load_csv_data(path_to_weights)
            self._data_weights = weights_df.values
        else: 
            self._data_weights = None
        self._int_max_params = int_max_params
        self._dataframe = dataframe
        self._header_labels = header_labels
        x_data, x_labels, x_properties = self.get_independent_data()
        y_data, y_label, y_properties = self.get_dependent_data()
        self._x_data = x_data
        self._x_labels = x_labels
        self._y_data = y_data
        self._y_label = y_label        
        if np.std(self._y_data) == 0:
            raise Exception(&#34;The data is invalid. All y values are the same.&#34;)
        self._param_names = [make_parameter_name(x) for x in
                             range(0, self._int_max_params)]
        self._data_properties = dict()
        self._data_properties.update(x_properties)
        self._data_properties.update(y_properties)
        self._data_dict = self.get_data_dict()
        self._num_variables = len(self._x_labels)
        self._m_terminals = self._num_variables + int_max_params
        self._terminals_list = (create_parameter_list(int_max_params) +
                                create_variable_list(path_to_csv_file))        

    def make_sympy_namespace(self):
        sympy_namespace = {}
        for variable_name in self._x_labels:
            sympy_namespace[variable_name] = sympy.Symbol(variable_name)
        for param_name in self._param_names:
            sympy_namespace[param_name] = sympy.Symbol(param_name)
        sympy_namespace[&#39;add&#39;] = sympy.Add
        sympy_namespace[&#39;sub&#39;] = sympy_Sub
        sympy_namespace[&#39;mul&#39;] = sympy.Mul
        sympy_namespace[&#39;div&#39;] = sympy_Div
        sympy_namespace[&#39;pow&#39;] = sympy.Pow
        sympy_namespace[&#39;cos&#39;] = sympy.Function(&#39;cos&#39;)
        sympy_namespace[&#39;sin&#39;] = sympy.Function(&#39;sin&#39;)
        sympy_namespace[&#39;tan&#39;] = sympy.Function(&#39;tan&#39;)
        sympy_namespace[&#39;cosh&#39;] = sympy.Function(&#39;cosh&#39;)
        sympy_namespace[&#39;sinh&#39;] = sympy.Function(&#39;sinh&#39;)
        sympy_namespace[&#39;tanh&#39;] = sympy.Function(&#39;tanh&#39;)
        sympy_namespace[&#39;exp&#39;] = sympy.Function(&#39;exp&#39;)
        sympy_namespace[&#39;log&#39;] = sympy.Function(&#39;log&#39;)
        return sympy_namespace

    def load_csv_data(self, path_to_csv):
        dataframe = pandas.read_csv(path_to_csv)
        column_labels = dataframe.keys()
        return (dataframe, column_labels)

    def get_independent_data(self):
        &#39;&#39;&#39;
            Loads all data in self._dataframe except the rightmost column
        &#39;&#39;&#39;
        dataframe = self._dataframe
        header_labels = self._header_labels
        features = dataframe.iloc[:, :-1]
        features = np.array(features)
        labels = header_labels[:-1]
        properties = dict()
        for label in labels:
            properties.update(get_properties(dataframe[label], label))
        return (features, labels, properties)

    def get_dependent_data(self):
        &#39;&#39;&#39;
            Loads only the rightmost column from self._dataframe
        &#39;&#39;&#39;
        dataframe = self._dataframe
        header_labels = self._header_labels
        feature = dataframe.iloc[:, -1]
        feature = np.array(feature)
        label = header_labels[-1]
        properties = get_properties(dataframe[label], label)
        return (feature, label, properties)

    def get_data_dict(self):
        &#39;&#39;&#39;
            Creates a dictionary object which houses the values in the dataset 
            CSV. The variable names in the CSV become keys in this data_dict 
            dictionary.
        &#39;&#39;&#39;
        dataframe = self._dataframe
        data_dict = dict()
        for label in self._header_labels:
            data_dict[label] = np.array(dataframe[label].values).astype(float)
            check_for_nans(data_dict[label])
        return data_dict</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pySRURGS.Dataset.get_data_dict"><code class="name flex">
<span>def <span class="ident">get_data_dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Creates a dictionary object which houses the values in the dataset
CSV. The variable names in the CSV become keys in this data_dict
dictionary.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data_dict(self):
    &#39;&#39;&#39;
        Creates a dictionary object which houses the values in the dataset 
        CSV. The variable names in the CSV become keys in this data_dict 
        dictionary.
    &#39;&#39;&#39;
    dataframe = self._dataframe
    data_dict = dict()
    for label in self._header_labels:
        data_dict[label] = np.array(dataframe[label].values).astype(float)
        check_for_nans(data_dict[label])
    return data_dict</code></pre>
</details>
</dd>
<dt id="pySRURGS.Dataset.get_dependent_data"><code class="name flex">
<span>def <span class="ident">get_dependent_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads only the rightmost column from self._dataframe</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_dependent_data(self):
    &#39;&#39;&#39;
        Loads only the rightmost column from self._dataframe
    &#39;&#39;&#39;
    dataframe = self._dataframe
    header_labels = self._header_labels
    feature = dataframe.iloc[:, -1]
    feature = np.array(feature)
    label = header_labels[-1]
    properties = get_properties(dataframe[label], label)
    return (feature, label, properties)</code></pre>
</details>
</dd>
<dt id="pySRURGS.Dataset.get_independent_data"><code class="name flex">
<span>def <span class="ident">get_independent_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads all data in self._dataframe except the rightmost column</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_independent_data(self):
    &#39;&#39;&#39;
        Loads all data in self._dataframe except the rightmost column
    &#39;&#39;&#39;
    dataframe = self._dataframe
    header_labels = self._header_labels
    features = dataframe.iloc[:, :-1]
    features = np.array(features)
    labels = header_labels[:-1]
    properties = dict()
    for label in labels:
        properties.update(get_properties(dataframe[label], label))
    return (features, labels, properties)</code></pre>
</details>
</dd>
<dt id="pySRURGS.Dataset.load_csv_data"><code class="name flex">
<span>def <span class="ident">load_csv_data</span></span>(<span>self, path_to_csv)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_csv_data(self, path_to_csv):
    dataframe = pandas.read_csv(path_to_csv)
    column_labels = dataframe.keys()
    return (dataframe, column_labels)</code></pre>
</details>
</dd>
<dt id="pySRURGS.Dataset.make_sympy_namespace"><code class="name flex">
<span>def <span class="ident">make_sympy_namespace</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_sympy_namespace(self):
    sympy_namespace = {}
    for variable_name in self._x_labels:
        sympy_namespace[variable_name] = sympy.Symbol(variable_name)
    for param_name in self._param_names:
        sympy_namespace[param_name] = sympy.Symbol(param_name)
    sympy_namespace[&#39;add&#39;] = sympy.Add
    sympy_namespace[&#39;sub&#39;] = sympy_Sub
    sympy_namespace[&#39;mul&#39;] = sympy.Mul
    sympy_namespace[&#39;div&#39;] = sympy_Div
    sympy_namespace[&#39;pow&#39;] = sympy.Pow
    sympy_namespace[&#39;cos&#39;] = sympy.Function(&#39;cos&#39;)
    sympy_namespace[&#39;sin&#39;] = sympy.Function(&#39;sin&#39;)
    sympy_namespace[&#39;tan&#39;] = sympy.Function(&#39;tan&#39;)
    sympy_namespace[&#39;cosh&#39;] = sympy.Function(&#39;cosh&#39;)
    sympy_namespace[&#39;sinh&#39;] = sympy.Function(&#39;sinh&#39;)
    sympy_namespace[&#39;tanh&#39;] = sympy.Function(&#39;tanh&#39;)
    sympy_namespace[&#39;exp&#39;] = sympy.Function(&#39;exp&#39;)
    sympy_namespace[&#39;log&#39;] = sympy.Function(&#39;log&#39;)
    return sympy_namespace</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree"><code class="flex name class">
<span>class <span class="ident">EnumeratorBinaryTree</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>An object housing methods for enumeration of the symbolic regression
problem. Use <a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a> instead when no functions of arity
one permitted.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>A pySRURGS.Enumerator object which houses various methods for the
enumeration of the problem space.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code>&gt;&gt;&gt; import pySRURGS
&gt;&gt;&gt; en = pySRURGS.Enumerator()
&gt;&gt;&gt; en.get_M(1000, 5, 5, 5)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EnumeratorBinaryTree(object):
    &#34;&#34;&#34;
    An object housing methods for enumeration of the symbolic regression
    problem. Use `EnumeratorFullBinaryTree` instead when no functions of arity 
    one permitted.

    Returns
    -------
    self
        A pySRURGS.Enumerator object which houses various methods for the
        enumeration of the problem space.

    Example
    --------

    &gt;&gt;&gt; import pySRURGS
    &gt;&gt;&gt; en = pySRURGS.Enumerator()
    &gt;&gt;&gt; en.get_M(1000, 5, 5, 5)
    &#34;&#34;&#34;

    @memoize
    def get_M(self, N, f, n, m):
        &#34;&#34;&#34;
        Calculate the total number of equations for this symbolic regression
        problem. Use get_M from `EnumeratorFullBinaryTree` instead if the number 
        of functions of arity one permitted is zero.

        Parameters
        ----------
        N: int
            Specifies the number of unique binary trees permitted in our search.
            We consider trees mapping from the integer domain [0 ... `N`-1].


        f: int
            The number of functions of arity one permitted

        n: int
            The number of functions of arity two permitted

        m: int
            The number of terminals in the problem (includes variables and
            fitting parameters)

        Returns
        -------
        M: int (mpfmath format)
            The number of possible equations in this symbolic regression problem
        &#34;&#34;&#34;
        def get_count(i):
            l_i = self.get_l_i(i)
            k_i = self.get_k_i(i)
            j_i = self.get_j_i(i)
            count = mempower(n, k_i) * mempower(m, j_i) * mempower(f, l_i)
            return count
        M = mpmath.nsum(get_count, [0, N - 1])
        return M

    @memoize
    def get_G(self, f, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the functions of arity
        one for the binary tree mapped from the integer `i`.  Use get_G from
        `EnumeratorFullBinaryTree` instead if the number of functions of arity 
        one permitted is zero.

        Parameters
        ----------
        f: int
            The number of functions of arity one permitted

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        G: int (mpfmath format)
            The number of possible configurations of functions of arity one
        &#34;&#34;&#34;
        l = self.get_l_i(i)
        G = mempower(f, l)
        return G

    def get_A(self, n, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the functions of arity
        two for the binary tree mapped from the integer `i`.  Use get_A from
        `EnumeratorFullBinaryTree` instead if the number of functions of arity 
        one permitted is zero.

        Parameters
        ----------
        n: int
            The number of functions of arity two permitted

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        A: int (mpfmath format)
            The number of possible configurations of functions of arity two
        &#34;&#34;&#34;
        k = self.get_k_i(i)
        A = mempower(n, k)
        return A

    @memoize
    def get_B(self, m, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the terminals for the
        binary tree mapped from the integer `i`.  Use get_B from
        `EnumeratorFullBinaryTree` instead if the number of functions of arity 
        one permitted is zero.

        Parameters
        ----------
        m: int
            The number of terminals including variables and fitting parameters

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        B: int (mpfmath format)
            The number of possible configurations of terminals
        &#34;&#34;&#34;
        j = self.get_j_i(i)
        B = mempower(m, j)
        return B

    def get_q(self, f, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `G` - 1, inclusive &#39;&#39;&#39;
        G = self.get_G(f, i)
        try:
            q = randgen.randint(0, G - 1, dtype=np.int64)
        except ValueError as e:
            if G == 1:
                q = 0
            else:
                print(e)
                raise ValueError
        return q

    def get_r(self, n, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `A` - 1, inclusive &#39;&#39;&#39;
        A = self.get_A(n, i)
        try:
            r = randgen.randint(0, A - 1, dtype=np.int64)
        except ValueError as e:
            if A == 1:
                r = 0
            else:
                print(e)
                raise ValueError
        return r

    def get_s(self, m, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `B` - 1, inclusive &#39;&#39;&#39;
        B = self.get_B(m, i)
        try:
            s = randgen.randint(0, B - 1, dtype=np.int64)
        except ValueError as e:
            if B == 1:
                s = 0
            else:
                print(e)
                raise ValueError
        return s

    @memoize
    def get_l_i(self, i):
        &#39;&#39;&#39;
            from `f` functions of arity one, pick `l_i `
            `l_i` is the number of non-leaf nodes of arity one
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            l_i = 0
        elif i == 1:
            l_i = 0
        elif i == 2:
            l_i = 1
        else:
            left_int, right_int = get_left_right_bits(i)
            left_l_i = self.get_l_i(left_int)
            right_l_i = self.get_l_i(right_int)
            l_i = left_l_i + right_l_i + 1
        return l_i

    @memoize
    def get_k_i(self, i):
        &#39;&#39;&#39;
            from `n` functions of arity two, pick `k_i`
            `k_i` is the number of non-leaf nodes
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            k_i = 0
        elif i == 1:
            k_i = 1
        elif i == 2:
            k_i = 0
        else:
            left_int, right_int = get_left_right_bits(i)
            left_k_i = self.get_k_i(left_int)
            right_k_i = self.get_k_i(right_int)
            k_i = left_k_i + right_k_i + 1
        return k_i

    @memoize
    def get_j_i(self, i):
        &#39;&#39;&#39;
            from `m` terminals, pick `j_i`
            `j_i` is the number of leafs in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            j_i = 1
        elif i == 1:
            j_i = 2
        elif i == 2:
            j_i = 1
        else:
            left_int, right_int = get_left_right_bits(i)
            left_j_i = self.get_j_i(left_int)
            right_j_i = self.get_j_i(right_int)
            j_i = left_j_i + right_j_i
        return j_i</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pySRURGS.EnumeratorBinaryTree.get_A"><code class="name flex">
<span>def <span class="ident">get_A</span></span>(<span>self, n, i)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculate the total number of configurations of the functions of arity
two for the binary tree mapped from the integer <code>i</code>.
Use get_A from
<a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree"><code>EnumeratorFullBinaryTree</code></a> instead if the number of functions of arity
one permitted is zero.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>n</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of functions of arity two permitted</dd>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code></dt>
<dd>The <code>i</code>^th binary tree in the integer to tree mapping</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>A</code></strong> :&ensp;<code>int</code> (<code>mpfmath</code> <code>format</code>)</dt>
<dd>The number of possible configurations of functions of arity two</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_A(self, n, i):
    &#34;&#34;&#34;
    Calculate the total number of configurations of the functions of arity
    two for the binary tree mapped from the integer `i`.  Use get_A from
    `EnumeratorFullBinaryTree` instead if the number of functions of arity 
    one permitted is zero.

    Parameters
    ----------
    n: int
        The number of functions of arity two permitted

    i: int
        The `i`^th binary tree in the integer to tree mapping

    Returns
    -------
    A: int (mpfmath format)
        The number of possible configurations of functions of arity two
    &#34;&#34;&#34;
    k = self.get_k_i(i)
    A = mempower(n, k)
    return A</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_B"><code class="name flex">
<span>def <span class="ident">get_B</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_G"><code class="name flex">
<span>def <span class="ident">get_G</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_M"><code class="name flex">
<span>def <span class="ident">get_M</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_j_i"><code class="name flex">
<span>def <span class="ident">get_j_i</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_k_i"><code class="name flex">
<span>def <span class="ident">get_k_i</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_l_i"><code class="name flex">
<span>def <span class="ident">get_l_i</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_q"><code class="name flex">
<span>def <span class="ident">get_q</span></span>(<span>self, f, i)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random integer between 0 and <code>G</code> - 1, inclusive</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_q(self, f, i):
    &#39;&#39;&#39; Generates a random integer between 0 and `G` - 1, inclusive &#39;&#39;&#39;
    G = self.get_G(f, i)
    try:
        q = randgen.randint(0, G - 1, dtype=np.int64)
    except ValueError as e:
        if G == 1:
            q = 0
        else:
            print(e)
            raise ValueError
    return q</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_r"><code class="name flex">
<span>def <span class="ident">get_r</span></span>(<span>self, n, i)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random integer between 0 and <code>A</code> - 1, inclusive</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_r(self, n, i):
    &#39;&#39;&#39; Generates a random integer between 0 and `A` - 1, inclusive &#39;&#39;&#39;
    A = self.get_A(n, i)
    try:
        r = randgen.randint(0, A - 1, dtype=np.int64)
    except ValueError as e:
        if A == 1:
            r = 0
        else:
            print(e)
            raise ValueError
    return r</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorBinaryTree.get_s"><code class="name flex">
<span>def <span class="ident">get_s</span></span>(<span>self, m, i)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random integer between 0 and <code>B</code> - 1, inclusive</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_s(self, m, i):
    &#39;&#39;&#39; Generates a random integer between 0 and `B` - 1, inclusive &#39;&#39;&#39;
    B = self.get_B(m, i)
    try:
        s = randgen.randint(0, B - 1, dtype=np.int64)
    except ValueError as e:
        if B == 1:
            s = 0
        else:
            print(e)
            raise ValueError
    return s</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree"><code class="flex name class">
<span>class <span class="ident">EnumeratorFullBinaryTree</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<section class="desc"><p>An object housing methods for enumeration of the symbolic regression
problem. Use <a title="pySRURGS.EnumeratorBinaryTree" href="#pySRURGS.EnumeratorBinaryTree"><code>EnumeratorBinaryTree</code></a> instead when functions of arity one are permitted.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Enumerator</code></dt>
<dd>A pySRURGS.EnumeratorFullBinaryTree object which houses various methods for the
enumeration of the problem space for case where only functions of arity
two are permitted.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code>&gt;&gt;&gt; import pySRURGS
&gt;&gt;&gt; en = pySRURGS.EnumeratorFullBinaryTree()
&gt;&gt;&gt; en.get_M(1000, 5, 5)
</code></pre></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EnumeratorFullBinaryTree(object):
    &#34;&#34;&#34;
    An object housing methods for enumeration of the symbolic regression
    problem. Use `EnumeratorBinaryTree` instead when functions of arity one are permitted.

    Returns
    -------
    Enumerator
        A pySRURGS.EnumeratorFullBinaryTree object which houses various methods for the
        enumeration of the problem space for case where only functions of arity
        two are permitted.

    Example
    --------

    &gt;&gt;&gt; import pySRURGS
    &gt;&gt;&gt; en = pySRURGS.EnumeratorFullBinaryTree()
    &gt;&gt;&gt; en.get_M(1000, 5, 5)
    &#34;&#34;&#34;

    @memoize
    def get_M(self, N, n, m):
        &#34;&#34;&#34;
        Calculate the total number of equations for this symbolic regression
        problem. Use get_M from `EnumeratorBinaryTree` instead if any functions
        of arity one are permitted.

        Parameters
        ----------
        N: int
            Specifies the number of unique binary trees permitted in our search.
            We consider trees mapping from the integer domain [0 ... `N`-1].

        n: int
            The number of functions of arity two permitted

        m: int
            The number of terminals in the problem (includes variables and
            fitting parameters)

        Returns
        -------
        M: int (mpfmath format)
            The number of possible equations in this symbolic regression problem
        &#34;&#34;&#34;
        def get_count(i):
            k_i = self.get_k_i(i)
            j_i = self.get_j_i(i)
            count = mempower(n, k_i) * mempower(m, j_i)
            return count
        M = mpmath.nsum(get_count, [0, N - 1])
        return M

    @memoize
    def get_A(self, n, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the functions of arity
        two for the binary tree mapped from the integer `i`.  Use get_A from
        `EnumeratorBinaryTree` instead if the number of functions of arity one permitted
        is not zero.

        Parameters
        ----------
        n: int
            The number of functions of arity two permitted

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        A: int (mpfmath format)
            The number of possible configurations of functions of arity two
        &#34;&#34;&#34;
        k = self.get_k_i(i)
        A = mempower(n, k)
        return A

    @memoize
    def get_B(self, m, i):
        &#34;&#34;&#34;
        Calculate the total number of configurations of the terminals for the
        binary tree mapped from the integer `i`.  Use get_B from
        `EnumeratorBinaryTree` instead if the number of functions of arity one permitted
        is not zero.

        Parameters
        ----------
        m: int
            The number of terminals including variables and fitting parameters

        i: int
            The `i`^th binary tree in the integer to tree mapping

        Returns
        -------
        B: int (mpfmath format)
            The number of possible configurations of terminals
        &#34;&#34;&#34;
        j = self.get_j_i(i)
        B = mempower(m, j)
        return B

    def get_r(self, n, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `A` - 1, inclusive &#39;&#39;&#39;
        A = self.get_A(n, i)
        try:
            r = randgen.randint(0, A - 1, dtype=np.int64)
        except ValueError as e:
            if A == 1:
                r = 0
            else:
                print(e)
                raise ValueError
        return r

    def get_s(self, m, i):
        &#39;&#39;&#39; Generates a random integer between 0 and `B` - 1, inclusive &#39;&#39;&#39;        
        B = self.get_B(m, i)
        try:
            s = randgen.randint(0, B - 1, dtype=np.int64)
        except ValueError as e:
            if B == 1:
                s = 0
            else:
                print(e)
                raise ValueError
        return s

    @memoize
    def get_k_i(self, i):
        &#39;&#39;&#39;
            from `n` functions of arity two, pick `k_i`
            `k_i` is the number of non-leaf nodes
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            k_i = 0
        elif i == 1:
            k_i = 1
        else:
            left_int, right_int = get_left_right_bits(i - 1)
            left_k_i = self.get_k_i(left_int)
            right_k_i = self.get_k_i(right_int)
            k_i = left_k_i + right_k_i + 1
        return k_i

    @memoize
    def get_j_i(self, i):
        &#39;&#39;&#39;
            from `m` terminals, pick `j_i`
            `j_i` is the number of leafs
            in the tree corresponding to `i`
        &#39;&#39;&#39;
        i = int(i)
        if i == 0:
            j_i = 1
        elif i == 1:
            j_i = 2
        else:
            left_int, right_int = get_left_right_bits(i - 1)
            left_j_i = self.get_j_i(left_int)
            right_j_i = self.get_j_i(right_int)
            j_i = left_j_i + right_j_i
        return j_i</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_A"><code class="name flex">
<span>def <span class="ident">get_A</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_B"><code class="name flex">
<span>def <span class="ident">get_B</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_M"><code class="name flex">
<span>def <span class="ident">get_M</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_j_i"><code class="name flex">
<span>def <span class="ident">get_j_i</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_k_i"><code class="name flex">
<span>def <span class="ident">get_k_i</span></span>(<span>*args)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def memoized_func(*args):
    if args in cache and memoize_funcs:
        return cache[args]
    result = func(*args)
    cache[args] = result
    return result</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_r"><code class="name flex">
<span>def <span class="ident">get_r</span></span>(<span>self, n, i)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random integer between 0 and <code>A</code> - 1, inclusive</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_r(self, n, i):
    &#39;&#39;&#39; Generates a random integer between 0 and `A` - 1, inclusive &#39;&#39;&#39;
    A = self.get_A(n, i)
    try:
        r = randgen.randint(0, A - 1, dtype=np.int64)
    except ValueError as e:
        if A == 1:
            r = 0
        else:
            print(e)
            raise ValueError
    return r</code></pre>
</details>
</dd>
<dt id="pySRURGS.EnumeratorFullBinaryTree.get_s"><code class="name flex">
<span>def <span class="ident">get_s</span></span>(<span>self, m, i)</span>
</code></dt>
<dd>
<section class="desc"><p>Generates a random integer between 0 and <code>B</code> - 1, inclusive</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_s(self, m, i):
    &#39;&#39;&#39; Generates a random integer between 0 and `B` - 1, inclusive &#39;&#39;&#39;        
    B = self.get_B(m, i)
    try:
        s = randgen.randint(0, B - 1, dtype=np.int64)
    except ValueError as e:
        if B == 1:
            s = 0
        else:
            print(e)
            raise ValueError
    return s</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pySRURGS.ResultList"><code class="flex name class">
<span>class <span class="ident">ResultList</span></span>
</code></dt>
<dd>
<section class="desc"><p>Stores multiple results from a pySRURGS run. Typically, is loaded from the
SqliteDict database file. <code>self._results</code> needs to be generated by appending
<code>Result</code> objects to it.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>self</code></strong> :&ensp;<a title="pySRURGS.ResultList" href="#pySRURGS.ResultList"><code>ResultList</code></a></dt>
<dd>&nbsp;</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ResultList(object):
    &#34;&#34;&#34;
    Stores multiple results from a pySRURGS run. Typically, is loaded from the
    SqliteDict database file. `self._results` needs to be generated by appending
    `Result` objects to it.

    Returns
    -------
    self: ResultList
    &#34;&#34;&#34;

    def __init__(self):
        self._results = []

    def sort(self):
        &#34;&#34;&#34;
        Sorts the results in the result list by decreasing value of mean squared
        error.
        &#34;&#34;&#34;
        self._results = sorted(self._results, key=lambda x: x._MSE)

    def print(self, y_data, top=5, mode=&#39;succinct&#39;):
        &#34;&#34;&#34;
        Prints the Normalized Mean Squared Error, R^2, Equation (simplified),
        and Parameters values for the top results_dict. Run `self.sort` prior
        to executing `self.print`.

        Parameters
        ----------
        y_data: array like
            The dependent variable&#39;s data from the pySRURGS.Dataset object

        top: int
            The number of results to display. Will be the best models if
            `self.sort` has been run prior to printing.

        mode: string
            &#39;succinct&#39; or &#39;detailed&#39; depending on whether you want to see
            the difficult to read original equation string

        Returns
        -------
        table_string: string
            A table housing the Normalized Mean Squared Error, R^2,
            Equation (simplified), and Parameters values in the
            tabulate package format.
        &#34;&#34;&#34;
        table = []
        header = [&#34;Normalized Mean Squared Error&#34;, &#34;R^2&#34;,
                  &#34;Equation, simplified&#34;, &#34;Parameters&#34;]
        num_eqn = int(np.min((top, len(self._results))))
        for i in range(0, num_eqn):
            row = self._results[i].summarize(mode)
            row[0] = row[0] / np.std(y_data)
            table.append(row)
        table_string = tabulate.tabulate(table, headers=header)
        print(table_string)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pySRURGS.ResultList.print"><code class="name flex">
<span>def <span class="ident">print</span></span>(<span>self, y_data, top=5, mode='succinct')</span>
</code></dt>
<dd>
<section class="desc"><p>Prints the Normalized Mean Squared Error, R^2, Equation (simplified),
and Parameters values for the top results_dict. Run <code>self.sort</code> prior
to executing <code>self.print</code>.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>y_data</code></strong> :&ensp;<code>array</code> <code>like</code></dt>
<dd>The dependent variable's data from the pySRURGS.Dataset object</dd>
<dt><strong><code>top</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of results to display. Will be the best models if
<code>self.sort</code> has been run prior to printing.</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>string</code></dt>
<dd>'succinct' or 'detailed' depending on whether you want to see
the difficult to read original equation string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>table_string</code></strong> :&ensp;<code>string</code></dt>
<dd>A table housing the Normalized Mean Squared Error, R^2,
Equation (simplified), and Parameters values in the
tabulate package format.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print(self, y_data, top=5, mode=&#39;succinct&#39;):
    &#34;&#34;&#34;
    Prints the Normalized Mean Squared Error, R^2, Equation (simplified),
    and Parameters values for the top results_dict. Run `self.sort` prior
    to executing `self.print`.

    Parameters
    ----------
    y_data: array like
        The dependent variable&#39;s data from the pySRURGS.Dataset object

    top: int
        The number of results to display. Will be the best models if
        `self.sort` has been run prior to printing.

    mode: string
        &#39;succinct&#39; or &#39;detailed&#39; depending on whether you want to see
        the difficult to read original equation string

    Returns
    -------
    table_string: string
        A table housing the Normalized Mean Squared Error, R^2,
        Equation (simplified), and Parameters values in the
        tabulate package format.
    &#34;&#34;&#34;
    table = []
    header = [&#34;Normalized Mean Squared Error&#34;, &#34;R^2&#34;,
              &#34;Equation, simplified&#34;, &#34;Parameters&#34;]
    num_eqn = int(np.min((top, len(self._results))))
    for i in range(0, num_eqn):
        row = self._results[i].summarize(mode)
        row[0] = row[0] / np.std(y_data)
        table.append(row)
    table_string = tabulate.tabulate(table, headers=header)
    print(table_string)</code></pre>
</details>
</dd>
<dt id="pySRURGS.ResultList.sort"><code class="name flex">
<span>def <span class="ident">sort</span></span>(<span>self)</span>
</code></dt>
<dd>
<section class="desc"><p>Sorts the results in the result list by decreasing value of mean squared
error.</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort(self):
    &#34;&#34;&#34;
    Sorts the results in the result list by decreasing value of mean squared
    error.
    &#34;&#34;&#34;
    self._results = sorted(self._results, key=lambda x: x._MSE)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pySRURGS.SymbolicRegressionConfig"><code class="flex name class">
<span>class <span class="ident">SymbolicRegressionConfig</span></span>
<span>(</span><span>path_to_csv, path_to_db, n_functions=['add', 'sub', 'mul', 'div', 'pow'], f_functions=[], max_num_fit_params=3, max_permitted_trees=1000, path_to_weights=None)</span>
</code></dt>
<dd>
<section class="desc"><p>An object used to store the configuration of this symbolic regression
problem.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path_to_csv</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to the dataset CSV file. Usually, this
file ends in a '.csv' extension.</dd>
<dt><strong><code>path_to_db</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to where the code can save an output
database file. Usually, this file ends in a '.db' extension.</dd>
<dt><strong><code>n_functions</code></strong> :&ensp;<code>list</code></dt>
<dd>&nbsp;</dd>
</dl>
<p>A list with elements from the set ['add','sub','mul','div','pow'].
Defines the functions of arity two that are permitted in this symbolic
regression run. Default: ['add','sub','mul','div', 'pow']</p>
<dl>
<dt><strong><code>f_functions</code></strong> :&ensp;<code>list</code></dt>
<dd>A list with elements from the set ['cos','sin','tan','cosh','sinh',
'tanh','exp','log']. Defines the functions of arity one that are
permitted in this symbolic regression run.
Default: []</dd>
<dt><strong><code>max_num_fit_params</code></strong> :&ensp;<code>int</code></dt>
<dd>This specifies the length of the fitting parameters vector. Randomly
generated equations can have up to <code>max_num_fit_params</code> independent
fitting parameters. Default: 3</dd>
<dt><strong><code>max_permitted_trees</code></strong> :&ensp;<code>int</code></dt>
<dd>This specifies the number of permitted unique binary trees, which
determine the structure of random equations. pySRURGS will consider
equations from [0 &hellip; max_permitted_trees] during its search. Increasing
this value increases the size of the search space. Default: 100</dd>
<dt><strong><code>path_to_weights</code></strong> :&ensp;<code>string</code></dt>
<dd>An absolute or relative path to the CSV for weights of the data points
in the CSV found in <code>path_to_csv</code>. If <code>None</code>, will assume all data
points are equally weighted.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<p>Most are simply the parameters which were passed in. Notably, there is the
dataset object, which is not a mere parameter.</p>
<p>self._dataset
A pySRURGS.Dataset object, which houses a variety of attributes
including the numerical data, the sympy namespace, the data dict used in
evaluating the equation string, etc.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>self</code></dt>
<dd>A pySRURGS.SymbolicRegressionConfig object, with attributes
self._path_to_csv,
self._path_to_db,
self._n_functions,
self._f_functions,
self._max_num_fit_params,
self._max_permitted_trees,<br>
self._path_to_weights, and
self._dataset.</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SymbolicRegressionConfig(object):
    &#34;&#34;&#34;
    An object used to store the configuration of this symbolic regression
    problem.

    Parameters
    ----------

    path_to_csv: string
        An absolute or relative path to the dataset CSV file. Usually, this
        file ends in a &#39;.csv&#39; extension.

    path_to_db: string
        An absolute or relative path to where the code can save an output
        database file. Usually, this file ends in a &#39;.db&#39; extension.

    n_functions: list
       A list with elements from the set [&#39;add&#39;,&#39;sub&#39;,&#39;mul&#39;,&#39;div&#39;,&#39;pow&#39;].
       Defines the functions of arity two that are permitted in this symbolic
       regression run. Default: [&#39;add&#39;,&#39;sub&#39;,&#39;mul&#39;,&#39;div&#39;, &#39;pow&#39;]

    f_functions: list
        A list with elements from the set [&#39;cos&#39;,&#39;sin&#39;,&#39;tan&#39;,&#39;cosh&#39;,&#39;sinh&#39;,
        &#39;tanh&#39;,&#39;exp&#39;,&#39;log&#39;]. Defines the functions of arity one that are
        permitted in this symbolic regression run.
        Default: []

    max_num_fit_params: int
        This specifies the length of the fitting parameters vector. Randomly
        generated equations can have up to `max_num_fit_params` independent
        fitting parameters. Default: 3

    max_permitted_trees: int
        This specifies the number of permitted unique binary trees, which
        determine the structure of random equations. pySRURGS will consider
        equations from [0 ... max_permitted_trees] during its search. Increasing
        this value increases the size of the search space. Default: 100

    path_to_weights: string 
        An absolute or relative path to the CSV for weights of the data points 
        in the CSV found in `path_to_csv`. If `None`, will assume all data 
        points are equally weighted.           
    
    Attributes
    ----------
    
    Most are simply the parameters which were passed in. Notably, there is the 
    dataset object, which is not a mere parameter.
    
    self._dataset
        A pySRURGS.Dataset object, which houses a variety of attributes 
        including the numerical data, the sympy namespace, the data dict used in 
        evaluating the equation string, etc.
    
    Returns
    -------
    self
        A pySRURGS.SymbolicRegressionConfig object, with attributes 
        self._path_to_csv, 
        self._path_to_db,
        self._n_functions, 
        self._f_functions, 
        self._max_num_fit_params, 
        self._max_permitted_trees,  
        self._path_to_weights, and 
        self._dataset.
    &#34;&#34;&#34;

    def __init__(self,
                 path_to_csv,
                 path_to_db,
                 n_functions=default_n_funcs,
                 f_functions=default_f_funcs,
                 max_num_fit_params=defaults_dict[&#39;max_num_fit_params&#39;],
                 max_permitted_trees=defaults_dict[&#39;max_permitted_trees&#39;],
                 path_to_weights=None):  
        if path_to_db is None:
            path_to_db = create_db_name(path_to_csv)
        self._n_functions = n_functions
        self._f_functions = f_functions
        self._max_num_fit_params = max_num_fit_params
        self._max_permitted_trees = max_permitted_trees        
        self._path_to_csv = path_to_csv
        self._path_to_db = path_to_db
        is_csv_valid(path_to_csv)
        self._path_to_weights = path_to_weights
        if path_to_weights is not None:
            is_csv_valid(path_to_weights)
        self._dataset = Dataset(path_to_csv, 
                                max_num_fit_params, 
                                path_to_weights)</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="pySRURGS.defaults_dict" href="#pySRURGS.defaults_dict">defaults_dict</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pySRURGS.binary" href="#pySRURGS.binary">binary</a></code></li>
<li><code><a title="pySRURGS.check_equation_at_specified_indices" href="#pySRURGS.check_equation_at_specified_indices">check_equation_at_specified_indices</a></code></li>
<li><code><a title="pySRURGS.check_equation_at_specified_indices_to_db" href="#pySRURGS.check_equation_at_specified_indices_to_db">check_equation_at_specified_indices_to_db</a></code></li>
<li><code><a title="pySRURGS.check_equation_at_specified_indices_to_queue" href="#pySRURGS.check_equation_at_specified_indices_to_queue">check_equation_at_specified_indices_to_queue</a></code></li>
<li><code><a title="pySRURGS.check_for_nans" href="#pySRURGS.check_for_nans">check_for_nans</a></code></li>
<li><code><a title="pySRURGS.check_goodness_of_fit" href="#pySRURGS.check_goodness_of_fit">check_goodness_of_fit</a></code></li>
<li><code><a title="pySRURGS.check_validity_suggested_functions" href="#pySRURGS.check_validity_suggested_functions">check_validity_suggested_functions</a></code></li>
<li><code><a title="pySRURGS.clean_funcstring" href="#pySRURGS.clean_funcstring">clean_funcstring</a></code></li>
<li><code><a title="pySRURGS.clean_funcstring_params" href="#pySRURGS.clean_funcstring_params">clean_funcstring_params</a></code></li>
<li><code><a title="pySRURGS.clean_funcstring_vars" href="#pySRURGS.clean_funcstring_vars">clean_funcstring_vars</a></code></li>
<li><code><a title="pySRURGS.compile_results" href="#pySRURGS.compile_results">compile_results</a></code></li>
<li><code><a title="pySRURGS.count_number_equations" href="#pySRURGS.count_number_equations">count_number_equations</a></code></li>
<li><code><a title="pySRURGS.count_results" href="#pySRURGS.count_results">count_results</a></code></li>
<li><code><a title="pySRURGS.create_db_name" href="#pySRURGS.create_db_name">create_db_name</a></code></li>
<li><code><a title="pySRURGS.create_fitting_parameters" href="#pySRURGS.create_fitting_parameters">create_fitting_parameters</a></code></li>
<li><code><a title="pySRURGS.create_parameter_list" href="#pySRURGS.create_parameter_list">create_parameter_list</a></code></li>
<li><code><a title="pySRURGS.create_variable_list" href="#pySRURGS.create_variable_list">create_variable_list</a></code></li>
<li><code><a title="pySRURGS.equation_generator_binary_tree" href="#pySRURGS.equation_generator_binary_tree">equation_generator_binary_tree</a></code></li>
<li><code><a title="pySRURGS.equation_generator_full_binary_tree" href="#pySRURGS.equation_generator_full_binary_tree">equation_generator_full_binary_tree</a></code></li>
<li><code><a title="pySRURGS.eval_equation" href="#pySRURGS.eval_equation">eval_equation</a></code></li>
<li><code><a title="pySRURGS.exhaustive_search" href="#pySRURGS.exhaustive_search">exhaustive_search</a></code></li>
<li><code><a title="pySRURGS.generate_benchmark" href="#pySRURGS.generate_benchmark">generate_benchmark</a></code></li>
<li><code><a title="pySRURGS.generate_benchmarks" href="#pySRURGS.generate_benchmarks">generate_benchmarks</a></code></li>
<li><code><a title="pySRURGS.generate_benchmarks_SRconfigs" href="#pySRURGS.generate_benchmarks_SRconfigs">generate_benchmarks_SRconfigs</a></code></li>
<li><code><a title="pySRURGS.get_bits" href="#pySRURGS.get_bits">get_bits</a></code></li>
<li><code><a title="pySRURGS.get_cum_weights_binary_tree" href="#pySRURGS.get_cum_weights_binary_tree">get_cum_weights_binary_tree</a></code></li>
<li><code><a title="pySRURGS.get_cum_weights_full_binary_tree" href="#pySRURGS.get_cum_weights_full_binary_tree">get_cum_weights_full_binary_tree</a></code></li>
<li><code><a title="pySRURGS.get_element_of_cartesian_product" href="#pySRURGS.get_element_of_cartesian_product">get_element_of_cartesian_product</a></code></li>
<li><code><a title="pySRURGS.get_left_right_bits" href="#pySRURGS.get_left_right_bits">get_left_right_bits</a></code></li>
<li><code><a title="pySRURGS.get_properties" href="#pySRURGS.get_properties">get_properties</a></code></li>
<li><code><a title="pySRURGS.get_resultlist" href="#pySRURGS.get_resultlist">get_resultlist</a></code></li>
<li><code><a title="pySRURGS.has_nans" href="#pySRURGS.has_nans">has_nans</a></code></li>
<li><code><a title="pySRURGS.initialize_db" href="#pySRURGS.initialize_db">initialize_db</a></code></li>
<li><code><a title="pySRURGS.is_csv_valid" href="#pySRURGS.is_csv_valid">is_csv_valid</a></code></li>
<li><code><a title="pySRURGS.ith_binary_tree" href="#pySRURGS.ith_binary_tree">ith_binary_tree</a></code></li>
<li><code><a title="pySRURGS.ith_full_binary_tree" href="#pySRURGS.ith_full_binary_tree">ith_full_binary_tree</a></code></li>
<li><code><a title="pySRURGS.make_parameter_name" href="#pySRURGS.make_parameter_name">make_parameter_name</a></code></li>
<li><code><a title="pySRURGS.make_variable_name" href="#pySRURGS.make_variable_name">make_variable_name</a></code></li>
<li><code><a title="pySRURGS.memoize" href="#pySRURGS.memoize">memoize</a></code></li>
<li><code><a title="pySRURGS.mempower" href="#pySRURGS.mempower">mempower</a></code></li>
<li><code><a title="pySRURGS.plot_results" href="#pySRURGS.plot_results">plot_results</a></code></li>
<li><code><a title="pySRURGS.random_equation_binary_tree" href="#pySRURGS.random_equation_binary_tree">random_equation_binary_tree</a></code></li>
<li><code><a title="pySRURGS.random_equation_full_binary_tree" href="#pySRURGS.random_equation_full_binary_tree">random_equation_full_binary_tree</a></code></li>
<li><code><a title="pySRURGS.read_benchmarks" href="#pySRURGS.read_benchmarks">read_benchmarks</a></code></li>
<li><code><a title="pySRURGS.remove_dict_tags" href="#pySRURGS.remove_dict_tags">remove_dict_tags</a></code></li>
<li><code><a title="pySRURGS.remove_parameter_tags" href="#pySRURGS.remove_parameter_tags">remove_parameter_tags</a></code></li>
<li><code><a title="pySRURGS.remove_tags" href="#pySRURGS.remove_tags">remove_tags</a></code></li>
<li><code><a title="pySRURGS.remove_variable_tags" href="#pySRURGS.remove_variable_tags">remove_variable_tags</a></code></li>
<li><code><a title="pySRURGS.setup" href="#pySRURGS.setup">setup</a></code></li>
<li><code><a title="pySRURGS.simplify_equation_string" href="#pySRURGS.simplify_equation_string">simplify_equation_string</a></code></li>
<li><code><a title="pySRURGS.solution_saving_worker" href="#pySRURGS.solution_saving_worker">solution_saving_worker</a></code></li>
<li><code><a title="pySRURGS.uniform_random_global_search_once" href="#pySRURGS.uniform_random_global_search_once">uniform_random_global_search_once</a></code></li>
<li><code><a title="pySRURGS.uniform_random_global_search_once_to_db" href="#pySRURGS.uniform_random_global_search_once_to_db">uniform_random_global_search_once_to_db</a></code></li>
<li><code><a title="pySRURGS.uniform_random_global_search_once_to_queue" href="#pySRURGS.uniform_random_global_search_once_to_queue">uniform_random_global_search_once_to_queue</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pySRURGS.Dataset" href="#pySRURGS.Dataset">Dataset</a></code></h4>
<ul class="">
<li><code><a title="pySRURGS.Dataset.get_data_dict" href="#pySRURGS.Dataset.get_data_dict">get_data_dict</a></code></li>
<li><code><a title="pySRURGS.Dataset.get_dependent_data" href="#pySRURGS.Dataset.get_dependent_data">get_dependent_data</a></code></li>
<li><code><a title="pySRURGS.Dataset.get_independent_data" href="#pySRURGS.Dataset.get_independent_data">get_independent_data</a></code></li>
<li><code><a title="pySRURGS.Dataset.load_csv_data" href="#pySRURGS.Dataset.load_csv_data">load_csv_data</a></code></li>
<li><code><a title="pySRURGS.Dataset.make_sympy_namespace" href="#pySRURGS.Dataset.make_sympy_namespace">make_sympy_namespace</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pySRURGS.EnumeratorBinaryTree" href="#pySRURGS.EnumeratorBinaryTree">EnumeratorBinaryTree</a></code></h4>
<ul class="two-column">
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_A" href="#pySRURGS.EnumeratorBinaryTree.get_A">get_A</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_B" href="#pySRURGS.EnumeratorBinaryTree.get_B">get_B</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_G" href="#pySRURGS.EnumeratorBinaryTree.get_G">get_G</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_M" href="#pySRURGS.EnumeratorBinaryTree.get_M">get_M</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_j_i" href="#pySRURGS.EnumeratorBinaryTree.get_j_i">get_j_i</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_k_i" href="#pySRURGS.EnumeratorBinaryTree.get_k_i">get_k_i</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_l_i" href="#pySRURGS.EnumeratorBinaryTree.get_l_i">get_l_i</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_q" href="#pySRURGS.EnumeratorBinaryTree.get_q">get_q</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_r" href="#pySRURGS.EnumeratorBinaryTree.get_r">get_r</a></code></li>
<li><code><a title="pySRURGS.EnumeratorBinaryTree.get_s" href="#pySRURGS.EnumeratorBinaryTree.get_s">get_s</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pySRURGS.EnumeratorFullBinaryTree" href="#pySRURGS.EnumeratorFullBinaryTree">EnumeratorFullBinaryTree</a></code></h4>
<ul class="two-column">
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_A" href="#pySRURGS.EnumeratorFullBinaryTree.get_A">get_A</a></code></li>
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_B" href="#pySRURGS.EnumeratorFullBinaryTree.get_B">get_B</a></code></li>
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_M" href="#pySRURGS.EnumeratorFullBinaryTree.get_M">get_M</a></code></li>
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_j_i" href="#pySRURGS.EnumeratorFullBinaryTree.get_j_i">get_j_i</a></code></li>
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_k_i" href="#pySRURGS.EnumeratorFullBinaryTree.get_k_i">get_k_i</a></code></li>
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_r" href="#pySRURGS.EnumeratorFullBinaryTree.get_r">get_r</a></code></li>
<li><code><a title="pySRURGS.EnumeratorFullBinaryTree.get_s" href="#pySRURGS.EnumeratorFullBinaryTree.get_s">get_s</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pySRURGS.ResultList" href="#pySRURGS.ResultList">ResultList</a></code></h4>
<ul class="">
<li><code><a title="pySRURGS.ResultList.print" href="#pySRURGS.ResultList.print">print</a></code></li>
<li><code><a title="pySRURGS.ResultList.sort" href="#pySRURGS.ResultList.sort">sort</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pySRURGS.SymbolicRegressionConfig" href="#pySRURGS.SymbolicRegressionConfig">SymbolicRegressionConfig</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>